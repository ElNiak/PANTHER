{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"reference/SUMMARY.html","title":"SUMMARY","text":"<ul> <li>panther<ul> <li>panther_cli</li> <li>panther_cli_click</li> <li>panther_compose</li> <li>panther_docker</li> <li>panther_scalability<ul> <li>scalability_policy</li> </ul> </li> <li>panther_swarm</li> <li>panther_webapp<ul> <li>app<ul> <li>panther_server</li> <li>utils<ul> <li>cytoscape_generator</li> <li>results_viewer</li> </ul> </li> </ul> </li> </ul> </li> <li>panther_worker<ul> <li>app<ul> <li>argument_parser<ul> <li>ArgumentParserRunner</li> </ul> </li> <li>logger<ul> <li>CustomFormatter</li> </ul> </li> <li>panther</li> <li>panther_client</li> <li>panther_config<ul> <li>panther_config</li> </ul> </li> <li>panther_runner<ul> <li>panther_apt_runner</li> <li>panther_minip_runner</li> <li>panther_quic_runner</li> <li>panther_runner</li> </ul> </li> <li>panther_stats<ul> <li>panther_apt_stats</li> <li>panther_minip_stats</li> <li>panther_quic_stats</li> </ul> </li> <li>panther_tester<ul> <li>panther_apt_tester</li> <li>panther_minip_tester</li> <li>panther_quic_tester</li> <li>panther_tester</li> </ul> </li> <li>panther_utils<ul> <li>panther_constant</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/panther/index.html","title":"Index","text":""},{"location":"reference/panther/panther_cli.html","title":"Panther cli","text":""},{"location":"reference/panther/panther_cli.html#panther.panther_cli.is_tmux_session","title":"<code>is_tmux_session()</code>","text":"<p>Check if running inside a tmux session.</p> Source code in <code>panther/panther_cli.py</code> <pre><code>def is_tmux_session():\n\"\"\"Check if running inside a tmux session.\"\"\"\n    return 'TMUX' in subprocess.run(['env'], capture_output=True, text=True).stdout\n</code></pre>"},{"location":"reference/panther/panther_cli.html#panther.panther_cli.start_bash_container","title":"<code>start_bash_container(implem)</code>","text":"<p>Start a Docker container with the specified parameters.</p> Source code in <code>panther/panther_cli.py</code> <pre><code>def start_bash_container(implem):\n\"\"\"Start a Docker container with the specified parameters.\"\"\"\n    client = docker.from_env()\n    pwd = os.getcwd()\n    def get_nproc():\n\"\"\"Get the number of processors available.\"\"\"\n        try:\n            result = subprocess.run([\"nproc\"], capture_output=True, text=True, check=True)\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            print(f\"Error getting the number of processors: {e}\")\n            return \"1\"\n    nproc = get_nproc()\n    cpus = f\"{nproc}.0\"\n\n    container_name = f\"{implem}-panther\"\n\n    volumes = {\n        f\"{pwd}/tls-keys\": {\"bind\": \"/app/tls-keys\", \"mode\": \"rw\"},\n        f\"{pwd}/tickets\":  {\"bind\": \"/app/tickets\", \"mode\": \"rw\"},\n        f\"{pwd}/qlogs\":    {\"bind\": \"/app/qlogs\", \"mode\": \"rw\"},\n        f\"{pwd}/panther_worker/app/panther-ivy/protocol-testing/\": {\n            \"bind\": \"/app/panther-ivy/protocol-testing/\",\n            \"mode\": \"rw\",\n        },\n        f\"{pwd}/panther_worker/app/panther-ivy/ivy/include/1.7\": {\n            \"bind\": \"/app/panther-ivy/ivy/include/1.7\",\n            \"mode\": \"rw\",\n        },\n    }\n\n    try:\n        container = client.containers.run(\n            image=container_name,\n            command=\"bash\",\n            privileged=True,\n            cpus=cpus,\n            mem_limit=\"10g\",\n            mem_reservation=\"9.5g\",\n            volumes=volumes,\n            tty=True,\n            stdin_open=True,\n            detach=True,\n        )\n        print(f\"Started container {container.id} ({container_name})\")\n    except Exception as e:\n        print(f\"Error starting the container: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html","title":"Panther cli click","text":""},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.append_to_hosts_file","title":"<code>append_to_hosts_file(entry)</code>","text":"<p>Append a new entry to the /etc/hosts file.</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def append_to_hosts_file(entry):\n\"\"\"Append a new entry to the /etc/hosts file.\"\"\"\n    try:\n        command = f\"echo '{entry.strip()}' | sudo tee -a /etc/hosts\"\n        execute_command(command)\n        logging.info(f\"Added entry to /etc/hosts: {entry.strip()}\")\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Error adding entry to /etc/hosts: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.container_exists","title":"<code>container_exists(client, container_name)</code>","text":"<p>Check if the Docker container exists.</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def container_exists(client, container_name):\n\"\"\"Check if the Docker container exists.\"\"\"\n    try:\n        client.containers.get(container_name)\n        return True\n    except docker.errors.NotFound:\n        return False\n    except Exception as e:\n        logging.error(f\"Error checking container existence: {e}\")\n        return False\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.create_network","title":"<code>create_network(client, network_name, gateway, subnet)</code>","text":"<p>Create a Docker network with the specified gateway and subnet.</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def create_network(client, network_name, gateway, subnet):\n\"\"\"Create a Docker network with the specified gateway and subnet.\"\"\"\n    try:\n        client.networks.create(\n            name=network_name,\n            driver=\"bridge\",\n            ipam={\"Config\": [{\"Subnet\": subnet, \"Gateway\": gateway}]},\n        )\n        print(f\"Network '{network_name}' created successfully.\")\n    except Exception as e:\n        print(f\"Error creating network: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.get_container_ip","title":"<code>get_container_ip(client, container_name)</code>","text":"<p>Get the IP address of the Docker container.</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def get_container_ip(client, container_name):\n\"\"\"Get the IP address of the Docker container.\"\"\"\n    try:\n        container = client.containers.get(container_name)\n        ip_address = container.attrs[\"NetworkSettings\"][\"Networks\"].values()\n        return list(ip_address)[0][\"IPAddress\"]\n    except Exception as e:\n        logging.error(f\"Error getting IP address for container '{container_name}': {e}\")\n        return None\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.get_nproc","title":"<code>get_nproc()</code>","text":"<p>Get the number of processors available.</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def get_nproc():\n\"\"\"Get the number of processors available.\"\"\"\n    try:\n        result = subprocess.run([\"nproc\"], capture_output=True, text=True, check=True)\n        return result.stdout.strip()\n    except subprocess.CalledProcessError as e:\n        print(f\"Error getting the number of processors: {e}\")\n        return \"1\"\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.log_docker_output","title":"<code>log_docker_output(generator, task_name='docker command execution')</code>","text":"<p>Log output to console from a generator returned from docker client :param Any generator: The generator to log the output of :param str task_name: A name to give the task, i.e. 'Build database image', used for logging</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def log_docker_output(generator, task_name: str = \"docker command execution\") -&gt; None:\n\"\"\"\n    Log output to console from a generator returned from docker client\n    :param Any generator: The generator to log the output of\n    :param str task_name: A name to give the task, i.e. 'Build database image', used for logging\n    \"\"\"\n    while True:\n        try:\n            output = generator.__next__()\n            if \"stream\" in output:\n                output_str = output[\"stream\"].strip(\"\\r\\n\").strip(\"\\n\")\n                logging.info(f\"{task_name}: {output_str}\")\n            elif \"error\" in output:\n                raise ValueError(f'Error from {task_name}: {output[\"error\"]}')\n        except StopIteration:\n            logging.info(f\"{task_name} complete.\")\n            break\n        except ValueError:\n            logging.error(f\"Error parsing output from {task_name}: {output}\")\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.monitor_docker_usage","title":"<code>monitor_docker_usage(container_name, interval=1.0, duration=10.0)</code>","text":"<p>Monitor the CPU and memory usage of a Docker container.</p> <p>:param container_name: Name or ID of the Docker container to monitor :param interval: Time interval (in seconds) between checks :param duration: Total duration (in seconds) to monitor</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def monitor_docker_usage(container_name, interval=1.0, duration=10.0):\n\"\"\"\n    Monitor the CPU and memory usage of a Docker container.\n\n    :param container_name: Name or ID of the Docker container to monitor\n    :param interval: Time interval (in seconds) between checks\n    :param duration: Total duration (in seconds) to monitor\n    \"\"\"\n    client = docker.from_env()\n\n    try:\n        container = client.containers.get(container_name)\n    except docker.errors.NotFound:\n        logging.info(f\"No container found with name or ID {container_name}\")\n        return\n\n    start_time = time.time()\n    duration_condition = lambda: (\n        (time.time() - start_time) &lt; duration if duration &gt; 0 else True\n    )\n    while duration_condition():\n        try:\n            stats = container.stats(stream=False)\n\n            # Check for missing keys and default to 0 if missing\n            cpu_delta = stats[\"cpu_stats\"][\"cpu_usage\"].get(\"total_usage\", 0) - stats[\n                \"precpu_stats\"\n            ][\"cpu_usage\"].get(\"total_usage\", 0)\n            system_cpu_delta = stats[\"cpu_stats\"].get(\"system_cpu_usage\", 0) - stats[\n                \"precpu_stats\"\n            ].get(\"system_cpu_usage\", 0)\n            number_cpus = len(stats[\"cpu_stats\"][\"cpu_usage\"].get(\"percpu_usage\", []))\n            cpu_usage = (\n                (cpu_delta / system_cpu_delta) * number_cpus * 100.0\n                if system_cpu_delta &gt; 0\n                else 0.0\n            )\n\n            memory_usage = stats[\"memory_stats\"].get(\"usage\", 0) / (\n                1024 * 1024\n            )  # Convert to MB\n            memory_limit = stats[\"memory_stats\"].get(\"limit\", 1) / (\n                1024 * 1024\n            )  # Convert to MB\n            memory_percentage = (\n                (memory_usage / memory_limit) * 100.0 if memory_limit &gt; 0 else 0.0\n            )\n\n            logging.info(\n                f\"Name {container_name} - Time: {time.time() - start_time:.2f}s - CPU Usage: {cpu_usage:.2f}% - Memory Usage: {memory_usage:.2f}MB ({memory_percentage:.2f}%)\"\n            )\n        except docker.errors.APIError as e:\n            logging.error(f\"An error occurred: {e}\")\n            break\n        except KeyError as e:\n            logging.warning(f\"Missing key in stats: {e}\")\n        time.sleep(interval)\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.network_exists","title":"<code>network_exists(client, network_name)</code>","text":"<p>Check if the Docker network exists.</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def network_exists(client, network_name):\n\"\"\"Check if the Docker network exists.\"\"\"\n    try:\n        client.networks.get(network_name)\n        return True\n    except NotFound:\n        return False\n    except Exception as e:\n        print(f\"Error checking network existence: {e}\")\n        return False\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.restore_hosts_file","title":"<code>restore_hosts_file()</code>","text":"<p>Restore the original /etc/hosts file from the backup.</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>def restore_hosts_file():\n\"\"\"Restore the original /etc/hosts file from the backup.\"\"\"\n    try:\n        execute_command(\"sudo cp /etc/hosts.bak /etc/hosts\")\n        logging.info(\"Restored the original /etc/hosts file.\")\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Error restoring /etc/hosts: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_cli_click.html#panther.panther_cli_click.start_bash_container","title":"<code>start_bash_container(implem)</code>","text":"<p>Start a Docker container with the specified parameters.</p> Source code in <code>panther/panther_cli_click.py</code> <pre><code>@click.command()\n@click.pass_context\ndef start_bash_container(implem):\n\"\"\"Start a Docker container with the specified parameters.\"\"\"\n    client = docker.from_env()\n    pwd = os.getcwd()\n    nproc = get_nproc()\n    cpus = f\"{nproc}.0\"\n\n    container_name = f\"{implem}-ivy\"\n\n    volumes = {\n        f\"{pwd}/tls-keys\": {\"bind\": \"/PANTHER/tls-keys\", \"mode\": \"rw\"},\n        f\"{pwd}/tickets\": {\"bind\": \"/PANTHER/tickets\", \"mode\": \"rw\"},\n        f\"{pwd}/qlogs\": {\"bind\": \"/PANTHER/qlogs\", \"mode\": \"rw\"},\n        f\"{pwd}/src/Protocols-Ivy/doc/examples/quic\": {\n            \"bind\": \"/PANTHER/Protocols-Ivy/doc/examples/quic\",\n            \"mode\": \"rw\",\n        },\n        f\"{pwd}/src/Protocols-Ivy/ivy/include/1.7\": {\n            \"bind\": \"/PANTHER/Protocols-Ivy/ivy/include/1.7\",\n            \"mode\": \"rw\",\n        },\n    }\n\n    try:\n        container = client.containers.run(\n            image=container_name,\n            command=\"bash\",\n            privileged=True,\n            cpus=cpus,\n            mem_limit=\"10g\",\n            mem_reservation=\"9.5g\",\n            volumes=volumes,\n            tty=True,\n            stdin_open=True,\n            detach=True,\n        )\n        print(f\"Started container {container.id} ({container_name})\")\n    except Exception as e:\n        print(f\"Error starting the container: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_compose.html","title":"Panther compose","text":""},{"location":"reference/panther/panther_docker.html","title":"Panther docker","text":""},{"location":"reference/panther/panther_docker.html#panther.panther_docker.append_to_hosts_file","title":"<code>append_to_hosts_file(entry)</code>","text":"<p>Append a new entry to the /etc/hosts file.</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def append_to_hosts_file(entry):\n\"\"\"Append a new entry to the /etc/hosts file.\"\"\"\n    try:\n        command = f\"echo '{entry.strip()}' | sudo tee -a /etc/hosts\"\n        execute_command(command)\n        logging.info(f\"Added entry to /etc/hosts: {entry.strip()}\")\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Error adding entry to /etc/hosts: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_docker.html#panther.panther_docker.container_exists","title":"<code>container_exists(client, container_name)</code>","text":"<p>Check if the Docker container exists.</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def container_exists(client, container_name):\n\"\"\"Check if the Docker container exists.\"\"\"\n    try:\n        client.containers.get(container_name)\n        return True\n    except docker.errors.NotFound:\n        return False\n    except Exception as e:\n        logging.error(f\"Error checking container existence: {e}\")\n        return False\n</code></pre>"},{"location":"reference/panther/panther_docker.html#panther.panther_docker.create_network","title":"<code>create_network(client, network_name, gateway, subnet)</code>","text":"<p>Create a Docker network with the specified gateway and subnet.</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def create_network(client, network_name, gateway, subnet):\n\"\"\"Create a Docker network with the specified gateway and subnet.\"\"\"\n    try:\n        client.networks.create(\n            name=network_name,\n            driver=\"bridge\",\n            ipam={\"Config\": [{\"Subnet\": subnet, \"Gateway\": gateway}]},\n        )\n        print(f\"Network '{network_name}' created successfully.\")\n    except Exception as e:\n        print(f\"Error creating network: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_docker.html#panther.panther_docker.get_container_ip","title":"<code>get_container_ip(client, container_name)</code>","text":"<p>Get the IP address of the Docker container.</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def get_container_ip(client, container_name):\n\"\"\"Get the IP address of the Docker container.\"\"\"\n    try:\n        container = client.containers.get(container_name)\n        ip_address = container.attrs[\"NetworkSettings\"][\"Networks\"].values()\n        return list(ip_address)[0][\"IPAddress\"]\n    except Exception as e:\n        logging.error(f\"Error getting IP address for container '{container_name}': {e}\")\n        return None\n</code></pre>"},{"location":"reference/panther/panther_docker.html#panther.panther_docker.log_docker_output","title":"<code>log_docker_output(generator, task_name='docker command execution')</code>","text":"<p>Log output to console from a generator returned from docker client :param Any generator: The generator to log the output of :param str task_name: A name to give the task, i.e. 'Build database image', used for logging</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def log_docker_output(generator, task_name: str = \"docker command execution\") -&gt; None:\n\"\"\"\n    Log output to console from a generator returned from docker client\n    :param Any generator: The generator to log the output of\n    :param str task_name: A name to give the task, i.e. 'Build database image', used for logging\n    \"\"\"\n    while True:\n        try:\n            output = generator.__next__()\n            if \"stream\" in output:\n                output_str = output[\"stream\"].strip(\"\\r\\n\").strip(\"\\n\")\n                logging.info(f\"{task_name}: {output_str}\")\n            elif \"error\" in output:\n                raise ValueError(f'Error from {task_name}: {output[\"error\"]}')\n        except StopIteration:\n            logging.info(f\"{task_name} complete.\")\n            break\n        except ValueError:\n            logging.error(f\"Error parsing output from {task_name}: {output}\")\n</code></pre>"},{"location":"reference/panther/panther_docker.html#panther.panther_docker.monitor_docker_usage","title":"<code>monitor_docker_usage(docker_to_monitor, interval=1.0, duration=10.0)</code>","text":"<p>Monitor the CPU and memory usage of a Docker container.</p> <p>:param container_name: Name or ID of the Docker container to monitor :param interval: Time interval (in seconds) between checks :param duration: Total duration (in seconds) to monitor</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def monitor_docker_usage(docker_to_monitor, interval=1.0, duration=10.0):\n\"\"\"\n    Monitor the CPU and memory usage of a Docker container.\n\n    :param container_name: Name or ID of the Docker container to monitor\n    :param interval: Time interval (in seconds) between checks\n    :param duration: Total duration (in seconds) to monitor\n    \"\"\"\n    client = docker.from_env()\n\n    for container_name in docker_to_monitor:\n        try:\n            container = client.containers.get(container_name)\n        except docker.errors.NotFound:\n            logging.info(f\"No container found with name or ID {container_name}\")\n            return\n\n    start_time = time.time()\n    duration_condition = lambda: (\n        (time.time() - start_time) &lt; duration if duration &gt; 0 else True\n    )\n    while duration_condition():\n        execute_command(\"clear\")\n        for container_name in docker_to_monitor:\n            try:\n                container = client.containers.get(container_name)\n\n                stats = container.stats(stream=False)\n\n                # Check for missing keys and default to 0 if missing\n                cpu_delta = stats[\"cpu_stats\"][\"cpu_usage\"].get(\n                    \"total_usage\", 0\n                ) - stats[\"precpu_stats\"][\"cpu_usage\"].get(\"total_usage\", 0)\n                system_cpu_delta = stats[\"cpu_stats\"].get(\n                    \"system_cpu_usage\", 0\n                ) - stats[\"precpu_stats\"].get(\"system_cpu_usage\", 0)\n                number_cpus = len(\n                    stats[\"cpu_stats\"][\"cpu_usage\"].get(\"percpu_usage\", [])\n                )\n                cpu_usage = (\n                    (cpu_delta / system_cpu_delta) * number_cpus * 100.0\n                    if system_cpu_delta &gt; 0\n                    else 0.0\n                )\n\n                memory_usage = stats[\"memory_stats\"].get(\"usage\", 0) / (\n                    1024 * 1024\n                )  # Convert to MB\n                memory_limit = stats[\"memory_stats\"].get(\"limit\", 1) / (\n                    1024 * 1024\n                )  # Convert to MB\n                memory_percentage = (\n                    (memory_usage / memory_limit) * 100.0 if memory_limit &gt; 0 else 0.0\n                )\n\n                logging.info(\n                    f\"Name {container_name}\\n\\t - Time: {time.time() - start_time:.2f}s\\n\\t - CPU Usage: {cpu_usage:.2f}%\\n\\t - Memory Usage: {memory_usage:.2f}MB ({memory_percentage:.2f}%)\"\n                )\n            except docker.errors.APIError as e:\n                logging.error(f\"An error occurred: {e}\")\n                break\n            except KeyError as e:\n                logging.warning(f\"Missing key in stats: {e}\")\n        time.sleep(interval)\n</code></pre>"},{"location":"reference/panther/panther_docker.html#panther.panther_docker.network_exists","title":"<code>network_exists(client, network_name)</code>","text":"<p>Check if the Docker network exists.</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def network_exists(client, network_name):\n\"\"\"Check if the Docker network exists.\"\"\"\n    try:\n        client.networks.get(network_name)\n        return True\n    except NotFound:\n        return False\n    except Exception as e:\n        print(f\"Error checking network existence: {e}\")\n        return False\n</code></pre>"},{"location":"reference/panther/panther_docker.html#panther.panther_docker.push_image_to_registry","title":"<code>push_image_to_registry(image_name, registry_url='elniak', tag='latest')</code>","text":"<p>Push a Docker image to a registry.</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def push_image_to_registry(image_name, registry_url=\"elniak\", tag=\"latest\"):\n\"\"\"Push a Docker image to a registry.\"\"\"\n    try:\n        command = f\"docker tag {image_name} {registry_url}/{image_name}:{tag}\"\n        execute_command(command)\n        command = f\"docker push {registry_url}/{image_name}:{tag}\"\n        execute_command(command)\n        logging.info(f\"Pushed image '{image_name}' to registry '{registry_url}'.\")\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Error pushing image to registry: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_docker.html#panther.panther_docker.restore_hosts_file","title":"<code>restore_hosts_file()</code>","text":"<p>Restore the original /etc/hosts file from the backup.</p> Source code in <code>panther/panther_docker.py</code> <pre><code>def restore_hosts_file():\n\"\"\"Restore the original /etc/hosts file from the backup.\"\"\"\n    try:\n        execute_command(\"sudo cp /etc/hosts.bak /etc/hosts\")\n        logging.info(\"Restored the original /etc/hosts file.\")\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"Error restoring /etc/hosts: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_swarm.html","title":"Panther swarm","text":""},{"location":"reference/panther/panther_scalability/index.html","title":"Index","text":""},{"location":"reference/panther/panther_scalability/scalability_policy.html","title":"Scalability policy","text":""},{"location":"reference/panther/panther_webapp/index.html","title":"Index","text":""},{"location":"reference/panther/panther_webapp/app/index.html","title":"Index","text":""},{"location":"reference/panther/panther_webapp/app/panther_server.html","title":"Panther server","text":""},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer","title":"<code>PFVServer</code>","text":"Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>class PFVServer:\n    ROOTPATH = os.getcwd()\n    app      = Flask(__name__, static_folder=\"/app/static/\")\n    app.secret_key                  = \"super secret key\"  # TODO\n    app.config[\"SESSION_TYPE\"]      = \"filesystem\"\n    app.config[\"SESSION_PERMANENT\"] = False\n    app.config[\"APPLICATION_ROOT\"]  = ROOTPATH + \"/app/templates/\"\n    app.debug                       = True\n    CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n\n    def __init__(self, dir_path=None):\n        restore_config()\n\n        # Initialize SocketIO\n        PFVServer.socketio = SocketIO(PFVServer.app)\n\n        # Setup configuration\n        PFVServer.app.logger.info(\"Setup configuration ...\")\n        (\n            PFVServer.supported_protocols,\n            PFVServer.current_protocol,\n            PFVServer.tests_enabled,\n            PFVServer.conf_implementation_enable,\n            PFVServer.implementation_enable,\n            PFVServer.protocol_model_path,\n            PFVServer.protocol_results_path,\n            PFVServer.protocol_test_path,\n            PFVServer.config,\n            PFVServer.protocol_conf,\n        ) = get_experiment_config(None, True, True)\n\n        # Count number of directories in PFVServer.protocol_results_path\n        PFVServer.total_exp_in_dir = 0\n        with os.scandir(PFVServer.protocol_results_path) as entries:\n            PFVServer.total_exp_in_dir = sum(1 for entry in entries if entry.is_dir())\n\n        PFVServer.current_exp_path = os.path.join(\n            PFVServer.protocol_results_path, str(PFVServer.total_exp_in_dir)\n        )\n\n        # Experiment parameters\n        PFVServer.tests_requested = []\n        PFVServer.implementation_requested = []\n        PFVServer.experiment_iteration = 0\n        PFVServer.experiment_current_iteration = 0\n        PFVServer.is_experiment_started = False\n\n        # Automatic GUI\n        PFVServer.choices_args = {}\n\n        PFVServer.get_quic_vizualier()\n\n    def get_quic_vizualier():\n        # Get QUIC visualizer service (TODO move)\n        try:\n            hostname = socket.gethostname()\n            local_ip = socket.gethostbyname(hostname)\n            PFVServer.local_ip = local_ip\n            vizualiser_ip = socket.gethostbyname(\"ivy-visualizer\")\n            PFVServer.vizualiser_ip = vizualiser_ip\n        except:\n            PFVServer.local_ip = \"\"\n            PFVServer.vizualiser_ip = \"\"\n            PFVServer.app.logger.info(\"No visualizer found\")\n\n    @app.after_request\n    def add_header(r):\n\"\"\"\n        It sets the cache control headers to prevent caching\n\n        :param r: The response object\n        :return: the response object with the headers added.\n        \"\"\"\n        r.headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\"\n        r.headers[\"Pragma\"] = \"no-cache\"\n        r.headers[\"Expires\"] = \"0\"\n        r.headers[\"Cache-Control\"] = \"public, max-age=0\"\n        r.headers.add(\"Access-Control-Allow-Headers\", \"authorization,content-type\")\n        r.headers.add(\n            \"Access-Control-Allow-Methods\",\n            \"DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT\",\n        )\n        r.headers.add(\"Access-Control-Allow-Origin\", \"*\")\n        return r\n\n    @app.route(\"/\")\n    def redirection():\n\"\"\"\n        It redirects the user to the index.html page\n        :return: a redirect to the index.html page.\n        \"\"\"\n        return redirect(\"index.html\", code=302)\n\n    def reset_experiment_state():\n        PFVServer.is_experiment_started = False\n        PFVServer.experiment_current_iteration = 0\n        PFVServer.experiment_iteration = 0\n        restore_config()\n\n    @app.route(\"/update-count\", methods=[\"GET\"])\n    def update_count():\n        if PFVServer.is_experiment_started:\n            PFVServer.experiment_current_iteration += 1\n            if PFVServer.experiment_current_iteration &gt;= PFVServer.experiment_iteration:\n                PFVServer.emit_progress_update()\n                PFVServer.reset_experiment_state()\n            else:\n                PFVServer.emit_progress_update()\n        return jsonify({\"status\": \"success\"}), 200\n\n    def emit_progress_update():\n        progress = PFVServer.experiment_current_iteration\n        PFVServer.socketio.emit('progress_update', {'progress': progress})\n\n\n    @app.route(\"/errored-experiment\", methods=[\"GET\"])\n    def errored_experiment():\n        if PFVServer.is_experiment_started:\n            PFVServer.emit_progress_update()\n            PFVServer.reset_experiment_state()\n        return jsonify({\"status\": \"success\"}), 200\n\n    @app.route(\"/finish-experiment\", methods=[\"GET\"])\n    def finish_experiment():\n        if PFVServer.is_experiment_started:\n            PFVServer.emit_progress_update()\n            PFVServer.reset_experiment_state()\n        return jsonify({\"status\": \"success\"}), 200\n\n    def get_args():\n\"\"\"_summary_\n        Get list of argument for automatic GUI generation\n        Returns:\n            _type_: _description_\n        \"\"\"\n        # TODO refactor\n        PFVServer.choices_args = {}\n        args_parser = ArgumentParserRunner().parser\n        args_list = [{}]\n        is_mutually_exclusive = True\n        for group_type in [\n            args_parser._mutually_exclusive_groups,\n            args_parser._action_groups,\n        ]:\n            for group in group_type:\n                if group.title == \"positional arguments\":\n                    continue\n                if group.title == \"optional arguments\":\n                    continue\n                if group.title == \"Usage type\":\n                    continue\n\n                cont = False\n                for p in PFVServer.supported_protocols:\n                    if p in group.title.lower():\n                        cont = True\n                if cont:\n                    continue\n\n                if len(args_list[-1]) == 3:\n                    args_list.append({})\n\n                for action in group._group_actions:\n                    group_name = group.title\n                    if group_name not in args_list[-1]:\n                        args_list[-1][group_name] = []\n                    if isinstance(action, argparse._StoreTrueAction):\n                        args_list[-1][group_name].append(\n                            {\n                                \"name\": action.dest,\n                                \"help\": action.help,\n                                \"type\": \"bool\",\n                                \"default\": False,\n                                \"is_mutually_exclusive\": is_mutually_exclusive,\n                                \"description\": action.metavar,\n                            }\n                        )\n                    elif isinstance(action, argparse._StoreFalseAction):\n                        args_list[-1][group_name].append(\n                            {\n                                \"name\": action.dest,\n                                \"help\": action.help,\n                                \"type\": \"bool\",\n                                \"default\": True,\n                                \"is_mutually_exclusive\": is_mutually_exclusive,\n                                \"description\": action.metavar,\n                            }\n                        )\n                    elif not isinstance(action, argparse._HelpAction):\n                        if hasattr(action, \"choices\"):\n                            if action.choices:\n                                PFVServer.choices_args[action.dest] = action.choices\n                            args_list[-1][group_name].append(\n                                {\n                                    \"name\": action.dest,\n                                    \"help\": action.help,\n                                    \"type\": str(action.type),\n                                    \"default\": action.default,\n                                    \"is_mutually_exclusive\": is_mutually_exclusive,\n                                    \"choices\": action.choices,\n                                    \"description\": action.metavar,\n                                }\n                            )\n                        else:\n                            args_list[-1][group_name].append(\n                                {\n                                    \"name\": action.dest,\n                                    \"help\": action.help,\n                                    \"type\": str(action.type),\n                                    \"default\": action.default,\n                                    \"is_mutually_exclusive\": is_mutually_exclusive,\n                                    \"description\": action.metavar,\n                                }\n                            )\n            is_mutually_exclusive = False\n\n        json_arg = args_list\n\n        args_list = [{}]\n        is_mutually_exclusive = True\n        for group_type in [\n            args_parser._mutually_exclusive_groups,\n            args_parser._action_groups,\n        ]:\n            for group in group_type:\n                for p in PFVServer.supported_protocols:\n                    if p in group.title.lower():\n                        if p in PFVServer.current_protocol:\n                            if len(args_list[-1]) == 3:\n                                args_list.append({})\n\n                            for action in group._group_actions:\n                                group_name = group.title\n                                if group_name not in args_list[-1]:\n                                    args_list[-1][group_name] = []\n                                if isinstance(action, argparse._StoreTrueAction):\n                                    args_list[-1][group_name].append(\n                                        {\n                                            \"name\": action.dest,\n                                            \"help\": action.help,\n                                            \"type\": \"bool\",\n                                            \"default\": False,\n                                            \"is_mutually_exclusive\": is_mutually_exclusive,\n                                            \"description\": action.metavar,\n                                        }\n                                    )\n                                elif isinstance(action, argparse._StoreFalseAction):\n                                    args_list[-1][group_name].append(\n                                        {\n                                            \"name\": action.dest,\n                                            \"help\": action.help,\n                                            \"type\": \"bool\",\n                                            \"default\": True,\n                                            \"is_mutually_exclusive\": is_mutually_exclusive,\n                                            \"description\": action.metavar,\n                                        }\n                                    )\n                                elif not isinstance(action, argparse._HelpAction):\n                                    if hasattr(action, \"choices\"):\n                                        if action.choices:\n                                            PFVServer.choices_args[action.dest] = (\n                                                action.choices\n                                            )\n                                        args_list[-1][group_name].append(\n                                            {\n                                                \"name\": action.dest,\n                                                \"help\": action.help,\n                                                \"type\": str(action.type),\n                                                \"default\": action.default,\n                                                \"is_mutually_exclusive\": is_mutually_exclusive,\n                                                \"choices\": action.choices,\n                                                \"description\": action.metavar,\n                                            }\n                                        )\n                                    else:\n                                        args_list[-1][group_name].append(\n                                            {\n                                                \"name\": action.dest,\n                                                \"help\": action.help,\n                                                \"type\": str(action.type),\n                                                \"default\": action.default,\n                                                \"is_mutually_exclusive\": is_mutually_exclusive,\n                                                \"description\": action.metavar,\n                                            }\n                                        )\n                        is_mutually_exclusive = False\n        prot_arg = args_list\n        return json_arg, prot_arg\n\n    def start_exp(experiment_arguments, protocol_arguments, sequencial_test=True):\n        # TODO add paramater to ask if we keep previous config for next run\n\n        if sequencial_test:\n            for impl in PFVServer.implementation_requested:\n                PFVServer.app.logger.info(\n                    \"Starting experiment for implementation \" + impl\n                )\n                req = {\n                    \"args\": experiment_arguments,\n                    \"protocol_arguments\": protocol_arguments,\n                    \"protocol\": PFVServer.current_protocol,\n                    \"implementation\": impl,\n                    \"tests_requested\": PFVServer.tests_requested,\n                }\n                PFVServer.app.logger.info(\"with parameters: \" + str(req))\n                response = None\n                try:\n                    response = requests.get(f\"http://{impl}-ivy:80/run-exp\", json=req)\n                    response.raise_for_status()\n                    PFVServer.app.logger.info(f\"Experiment status: {response.content}\")\n                except requests.RequestException as e:\n                    PFVServer.app.logger.error(f\"Request failed for {impl}: {e} - {response}\")\n                    continue\n\n\n                while (\n                    PFVServer.experiment_current_iteration\n                    &lt; PFVServer.experiment_iteration\n                    / len(PFVServer.implementation_requested)\n                ):\n                    time.sleep(10)\n                    PFVServer.app.logger.info(\"Waiting\")\n                    PFVServer.app.logger.info(\"Waiting\")\n                    PFVServer.app.logger.info(f\"Current iteration: {PFVServer.experiment_current_iteration}\")\n                    PFVServer.app.logger.info(f\"Target iteration: {PFVServer.experiment_iteration / len(PFVServer.implementation_requested)}\")\n                PFVServer.app.logger.info(\n                    \"Ending experiment for implementation \" + impl\n                )\n        else:\n            # TODO multi test\n            # Need to avoid shared configuration file\n            pass\n\n    # To start the experiment in a thread\n    def start_experiment_thread(experiment_arguments, protocol_arguments):\n        thread = threading.Thread(target=PFVServer.start_exp, args=(experiment_arguments, protocol_arguments))\n        thread.daemon = True\n        thread.start()\n\n\n    def change_current_protocol(protocol):\n        PFVServer.app.logger.info(\n            f\"Selected Protocol change ({protocol}) -&gt; change GUI\"\n        )\n\n        PFVServer.current_protocol = protocol\n\n        json_arg, prot_arg = PFVServer.get_args()\n\n        if DEBUG:\n            PFVServer.app.logger.info(\"JSON arguments availables:\")\n            for elem in json_arg:\n                PFVServer.app.logger.info(elem)\n            PFVServer.app.logger.info(\"PROTOCOL arguments availables:\")\n            for elem in prot_arg:\n                PFVServer.app.logger.info(elem)\n\n        return json_arg, prot_arg\n\n    @app.route(\"/index.html\", methods=[\"GET\", \"POST\"])\n    def serve_index():\n\"\"\"\n        It creates a folder for the project, and then calls the upload function\n        :return: the upload function.\n        \"\"\"\n        PFVServer.app.logger.info(\"Protocols under test: \" + PFVServer.current_protocol)\n\n        if DEBUG:\n            json_arg, prot_arg = PFVServer.get_args()\n            PFVServer.app.logger.info(\"JSON arguments availables:\")\n            for elem in json_arg:\n                PFVServer.app.logger.info(elem)\n            PFVServer.app.logger.info(\"PROTOCOL arguments availables:\")\n            for elem in prot_arg:\n                PFVServer.app.logger.info(elem)\n\n        if request.method == \"POST\":\n            # TODO link json_arg and prot_arg to config so we can restore old config\n            # TODO fix problem with alpn &amp; initial version\n            if (\n                request.args.get(\"prot\", \"\")\n                and request.args.get(\"prot\", \"\") in PFVServer.supported_protocols\n            ):\n                # The Selected Protocol change -&gt; change GUI\n                json_arg, prot_arg = PFVServer.change_current_protocol(\n                    request.args.get(\"prot\", \"\")\n                )\n\n                (\n                    PFVServer.supported_protocols,\n                    PFVServer.current_protocol,\n                    PFVServer.tests_enabled,\n                    PFVServer.conf_implementation_enable,\n                    PFVServer.implementation_enable,\n                    PFVServer.protocol_model_path,\n                    PFVServer.protocol_results_path,\n                    PFVServer.protocol_test_path,\n                    PFVServer.config,\n                    PFVServer.protocol_conf,\n                ) = get_experiment_config(PFVServer.current_protocol, True, False)\n\n            # TODO implem progress, avoid to use post if experience already launched\n            # TODO force to select at least one test and one implem\n            PFVServer.app.logger.info(\"Form in POST request:\")\n            PFVServer.app.logger.info(request.form)\n            if DEBUG:\n                for c in request.form:\n                    for elem in request.form.getlist(c):\n                        PFVServer.app.logger.info(elem)\n\n            PFVServer.implementation_requested = []\n            experiment_arguments = {}\n            protocol_arguments = {}\n            PFVServer.tests_requested = []\n\n            arguments = dict(request.form)\n            exp_number = 1\n            for key, value in arguments.items():\n                if (key, value) == (\"boundary\", \"experiment separation\"):\n                    exp_number += 1\n                elif (\n                    key in PFVServer.implementation_enable.keys() and value == \"true\"\n                ):\n                    PFVServer.implementation_requested.append(key)\n                elif \"test\" in key and value == \"true\":\n                    PFVServer.tests_requested.append(key)\n                elif value != \"\":\n                    if key in PFVServer.choices_args:\n                        print(PFVServer.choices_args[key])\n                        value = str(PFVServer.choices_args[key][int(value) - 1])\n                    if exp_number == 1:\n                        experiment_arguments[key] = value\n                    elif exp_number == 2:\n                        protocol_arguments[key] = value\n\n            PFVServer.app.logger.info(\n                \"Experiment arguments: \" + str(experiment_arguments)\n            )\n            PFVServer.app.logger.info(\"Protocol arguments: \" + str(protocol_arguments))\n            PFVServer.app.logger.info(\n                \"Experiment tests requested: \" + str(PFVServer.tests_requested)\n            )\n\n            PFVServer.is_experiment_started = True\n            PFVServer.experiment_iteration = (\n                len(PFVServer.implementation_requested)\n                * len(PFVServer.tests_requested)\n                * int(experiment_arguments[\"iter\"])\n            )\n\n            PFVServer.start_experiment_thread(experiment_arguments, protocol_arguments)\n        else:\n            if (\n                request.args.get(\"prot\", \"\")\n                and request.args.get(\"prot\", \"\") in PFVServer.supported_protocols\n            ):\n                json_arg, prot_arg = PFVServer.change_current_protocol(\n                    request.args.get(\"prot\", \"\")\n                )\n                (\n                    PFVServer.supported_protocols,\n                    PFVServer.current_protocol,\n                    PFVServer.tests_enabled,\n                    PFVServer.conf_implementation_enable,\n                    PFVServer.implementation_enable,\n                    PFVServer.protocol_model_path,\n                    PFVServer.protocol_results_path,\n                    PFVServer.protocol_test_path,\n                    PFVServer.config,\n                    PFVServer.protocol_conf,\n                ) = get_experiment_config(PFVServer.current_protocol, True, False)\n\n        return render_template(\n            \"index.html\",\n            json_arg=json_arg,\n            prot_arg=prot_arg,\n\n            base_conf          =PFVServer.config,\n            protocol_conf      =PFVServer.protocol_conf,\n            supported_protocols=PFVServer.supported_protocols,\n            current_protocol   =PFVServer.current_protocol,\n\n            nb_exp                  =PFVServer.total_exp_in_dir,\n            tests_enable            =PFVServer.tests_enabled,\n            implementation_enable   =PFVServer.implementation_enable,\n            implementation_requested=PFVServer.implementation_requested,\n            progress                =PFVServer.experiment_current_iteration,  # PFVServer.experiments.count_1,\n            iteration               =PFVServer.experiment_iteration,\n        )\n\n    @app.route(\"/directory/&lt;int:directory&gt;/file/&lt;path:file&gt;\")\n    def send_file(directory, file):\n        return send_from_directory(\n            PFVServer.protocol_results_path + str(directory), file\n        )\n\n    @app.route(\"/key/&lt;string:implem&gt;\")\n    def send_key(implem):\n        return send_from_directory(PFVServer.key_path, implem)\n\n    # TODO redo\n    @app.route(\"/results.html\", methods=[\"GET\", \"POST\"])\n    def serve_results():\n\"\"\"\n        It creates a folder for the project, and then calls the upload function\n        :return: the upload function.\n        \"\"\"\n        PFVServer.app.logger.info(\n            \"Current Protocol Tests output folder: \" + PFVServer.protocol_results_path\n        )\n        PFVServer.app.logger.info(os.listdir(PFVServer.protocol_results_path))\n\n        with os.scandir(PFVServer.protocol_results_path) as entries:\n            PFVServer.total_exp_in_dir = sum(1 for entry in entries if entry.is_dir())\n\n        default_page = 0\n        page = request.args.get(\"page\", default_page)\n        try:\n            page = page.number\n        except:\n            pass\n        # Get queryset of items to paginate\n        rge = range(PFVServer.total_exp_in_dir, 0, -1)\n        PFVServer.app.logger.info([i for i in rge])\n        PFVServer.app.logger.info(page)\n        items = [i for i in rge]\n\n        # Paginate items\n        items_per_page = 1\n        paginator = Paginator(items, per_page=items_per_page)\n\n        try:\n            items_page = paginator.page(page)\n        except PageNotAnInteger:\n            items_page = paginator.page(default_page)\n        except EmptyPage:\n            items_page = paginator.page(paginator.num_pages)\n\n        df_csv = pd.read_csv(PFVServer.protocol_results_path + \"data.csv\").set_index(\n            \"Run\"\n        )\n        PFVServer.app.logger.info(PFVServer.total_exp_in_dir - int(page))\n\n        result_row = df_csv.iloc[-1]\n        output = \"df_csv_row.html\"\n        # TODO change the label\n        # result_row.to_frame().T\n        # subdf = df_csv.drop(\"ErrorIEV\", axis=1).drop(\"OutputFile\", axis=1).drop(\"date\", axis=1).drop(\"date\", axis=1).drop(\"date\", axis=1) #.reset_index()\n        subdf = df_csv[[\"Implementation\", \"NbPktSend\", \"packet_event\", \"recv_packet\"]]\n        subdf.fillna(0, inplace=True)\n        # subdf[\"isPass\"] = subdf[\"isPass\"].astype(int)\n        subdf[\"NbPktSend\"] = subdf[\"NbPktSend\"].astype(int)\n        # PFVServer.app.logger.info(subdf)\n        # PFVServer.app.logger.info(df_csv.columns)\n        # PFVServer.app.logger.info(subdf.columns)\n        # subdf.columns = df_csv.columns\n        configurationData = [\n            {\n                \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n                \"name\": \"Experiences coverage view\",\n                \"parameters\": [\"Run\"],  # \"Implementation\",\n                \"measurements\": [\n                    \"NbPktSend\"\n                ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n                \"data\": subdf.to_csv(),\n            },\n            {\n                \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n                \"name\": \"Experiences packet view\",\n                \"parameters\": [\"Run\"],  # \"Implementation\"\n                \"measurements\": [\n                    \"packet_event\",\n                    \"recv_packet\",\n                ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n                \"data\": subdf.to_csv(),  # index=False -&gt; need index\n            },\n        ]\n\n        export(configurationData, output)\n\n        # PFVServer.app.logger.info(configurationData)\n\n        with open(output, \"r\") as f:\n            df_csv_content = f.read()\n\n        summary = {}\n        summary[\"nb_pkt\"] = result_row[\"NbPktSend\"]\n        summary[\"initial_version\"] = result_row[\"initial_version\"]\n\n        PFVServer.current_exp_path = PFVServer.protocol_results_path + str(\n            PFVServer.total_exp_in_dir - int(page)\n        )\n        exp_dir = os.listdir(PFVServer.current_exp_path)\n        ivy_stderr = \"No output\"\n        ivy_stdout = \"No output\"\n        implem_err = \"No output\"\n        implem_out = \"No output\"\n        iev_out = \"No output\"\n        qlog_file = \"\"\n        pcap_file = \"\"\n        for file in exp_dir:\n            PFVServer.app.logger.info(file)\n            if \"ivy_stderr.txt\" in file:\n                with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                    content = f.read()\n                    if content == \"\":\n                        pass\n                    else:\n                        ivy_stderr = content\n            elif \"ivy_stdout.txt\" in file:\n                with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                    content = f.read()\n                    if content == \"\":\n                        pass\n                    else:\n                        ivy_stdout = content\n            elif \".err\" in file:\n                with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                    content = f.read()\n                    if content == \"\":\n                        pass\n                    else:\n                        implem_err = content\n            elif \".out\" in file:\n                with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                    content = f.read()\n                    if content == \"\":\n                        pass\n                    else:\n                        implem_out = content\n            elif \".iev\" in file:\n                # TODO use csv file\n                # file creation timestamp in float\n                c_time = os.path.getctime(PFVServer.current_exp_path + \"/\" + file)\n                # convert creation timestamp into DateTime object\n                dt_c = datetime.datetime.fromtimestamp(c_time)\n                PFVServer.app.logger.info(\"Created on:\" + str(dt_c))\n                summary[\"date\"] = dt_c\n                test_name = file.replace(\".iev\", \"\")[0:-1]\n                summary[\"test_name\"] = test_name\n                with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                    content = f.read()\n                    summary[\"test_result\"] = (\n                        \"Pass\" if \"test_completed\" in content else \"Fail\"\n                    )\n\n                try:\n                    plantuml_file = PFVServer.current_exp_path + \"/plantuml.puml\"\n                    generate_graph_input(\n                        PFVServer.current_exp_path + \"/\" + file, plantuml_file\n                    )\n                    plantuml_obj = PlantUML(\n                        url=\"http://www.plantuml.com/plantuml/img/\",\n                        basic_auth={},\n                        form_auth={},\n                        http_opts={},\n                        request_opts={},\n                    )\n\n                    plantuml_file_png = plantuml_file.replace(\n                        \".puml\", \".png\"\n                    )  # \"media/\" + str(nb_exp) + \"_plantuml.png\"\n                    plantuml_obj.processes_file(plantuml_file, plantuml_file_png)\n\n                    with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                        content = f.read()\n                        if content == \"\":\n                            pass\n                        else:\n                            iev_out = content\n                except:\n                    pass\n            elif \".pcap\" in file:\n                pcap_file = file\n                # Now we need qlogs and pcap informations\n                summary[\"implementation\"] = file.split(\"_\")[0]\n                summary[\"test_type\"] = file.split(\"_\")[2]\n\n            elif \".qlog\" in file:\n                qlog_file = file\n\n        # Get page number from request,\n        # default to first page\n        try:\n            binary_fc = open(plantuml_file_png, \"rb\").read()  # fc aka file_content\n            base64_utf8_str = b64encode(binary_fc).decode(\"utf-8\")\n\n            ext = plantuml_file_png.split(\".\")[-1]\n        except:\n            base64_utf8_str = \"\"\n            ext = \"png\"\n        dataurl = f\"data:image/{ext};base64,{base64_utf8_str}\"\n        PFVServer.app.logger.info(items_page)\n        PFVServer.app.logger.info(paginator)\n\n        return render_template(\n            \"results.html\",\n            items_page=items_page,\n            nb_exp=PFVServer.total_exp_in_dir,\n            page=int(page),\n            current_exp=PFVServer.current_exp_path,\n            ivy_stderr=ivy_stderr,\n            ivy_stdout=ivy_stdout,\n            implem_err=implem_err,\n            implem_out=implem_out,\n            iev_out=iev_out,\n            plantuml_file_png=dataurl,\n            summary=summary,  # \"http://\"+PFVServer.vizualiser_ip+\":80/?file=http://\"\n            pcap_frame_link=(\n                \"http://ivy-visualizer:80/?file=http://ivy-standalone:80/directory/\"\n                + str(PFVServer.total_exp_in_dir - int(page))\n                + \"/file/\"\n                + pcap_file\n                + \"&amp;secrets=http://ivy-standalone:80/key/\"\n                + summary[\"implementation\"]\n                + \"_key.log\"\n                if pcap_file != \"\"\n                else None\n            ),\n            qlog_frame_link=(\n                \"http://ivy-visualizer:80/?file=http://ivy-standalone:80/directory/\"\n                + str(PFVServer.total_exp_in_dir - int(page))\n                + \"/file/\"\n                + qlog_file\n                if qlog_file != \"\"\n                else None\n            ),\n            df_csv_content=df_csv_content,\n        )\n\n    # TODO redo\n    @app.route(\"/results-global.html\", methods=[\"GET\", \"POST\"])\n    def serve_results_global():\n\"\"\"\n        It creates a folder for the project, and then calls the upload function\n        :return: the upload function.\n        \"\"\"\n        PFVServer.total_exp_in_dir = (\n            len(os.listdir(PFVServer.protocol_results_path)) - 2\n        )\n\n        PFVServer.app.logger.info(request.form)\n\n        summary = {}\n        df_csv = pd.read_csv(\n            PFVServer.protocol_results_path + \"data.csv\", parse_dates=[\"date\"]\n        )\n\n        df_simplify_date = df_csv\n        df_simplify_date[\"date\"] = df_csv[\"date\"].dt.strftime(\"%d/%m/%Y\")\n        df_date_min_max = df_simplify_date[\"date\"].agg([\"min\", \"max\"])\n        df_nb_date = df_simplify_date[\"date\"].nunique()\n        df_dates = df_simplify_date[\"date\"].unique()\n        PFVServer.app.logger.info(list(df_dates))\n        PFVServer.app.logger.info(df_date_min_max)\n        PFVServer.app.logger.info(df_nb_date)\n        minimum_date = df_date_min_max[\"min\"]\n        maximum_date = df_date_min_max[\"max\"]\n\n        subdf = None\n        # if len(request.form) &gt;= 0:\n        for key in request.form:\n            if key == \"date_range\":\n                minimum = df_dates[int(request.form.get(\"date_range\").split(\",\")[0])]\n                maximum = df_dates[int(request.form.get(\"date_range\").split(\",\")[1])]\n                if subdf is None:\n                    subdf = df_csv.query(\"date &gt;= @minimum and date &lt;= @maximum\")\n                else:\n                    subdf = subdf.query(\"date &gt;= @minimum and date &lt;= @maximum\")\n            elif key == \"iter_range\":\n                minimum = request.form.get(\"iter_range\").split(\",\")[0]\n                maximum = request.form.get(\"iter_range\").split(\",\")[1]\n                if subdf is None:  # TOODO\n                    subdf = df_csv.loc[df_csv[\"Run\"] &gt;= int(minimum)]\n                    subdf = subdf.loc[subdf[\"Run\"] &lt;= int(maximum)]\n                else:\n                    subdf = subdf.loc[subdf[\"Run\"] &gt;= int(minimum)]\n                    subdf = subdf.loc[subdf[\"Run\"] &lt;= int(maximum)]\n            elif key == \"version\":\n                if request.form.get(\"version\") != \"all\":\n                    if subdf is None:  # TOODO\n                        subdf = df_csv.loc[\n                            df_csv[\"initial_version\"] == request.form.get(\"version\")\n                        ]\n                    else:\n                        subdf = subdf.loc[\n                            subdf[\"initial_version\"] == request.form.get(\"version\")\n                        ]\n            elif key == \"ALPN\":\n                if request.form.get(\"ALPN\") != \"all\":\n                    if subdf is None:  # TOODO\n                        subdf = df_csv.loc[\n                            df_csv[\"Mode\"] == request.form.get(\"test_type\")\n                        ]\n                    else:\n                        subdf = subdf.loc[\n                            subdf[\"Mode\"] == request.form.get(\"test_type\")\n                        ]\n            elif key == \"test_type\":\n                if request.form.get(\"test_type\") != \"all\":\n                    if subdf is None:\n                        subdf = df_csv.loc[\n                            df_csv[\"Mode\"] == request.form.get(\"test_type\")\n                        ]\n                    else:\n                        subdf = subdf.loc[\n                            subdf[\"Mode\"] == request.form.get(\"test_type\")\n                        ]\n            elif key == \"isPass\":\n                ispass = True if \"True\" in request.form.get(\"isPass\") else False\n                if request.form.get(\"isPass\") != \"all\":\n                    if subdf is None:\n                        subdf = df_csv.loc[df_csv[\"isPass\"] == ispass]\n                    else:\n                        subdf = subdf.loc[subdf[\"isPass\"] == ispass]\n            elif key == \"implem\":\n                for i in request.form.getlist(\"implem\"):\n                    PFVServer.app.logger.info(i)\n                    if subdf is None:\n                        subdf = df_csv.loc[df_csv[\"Implementation\"] == i]\n                    else:\n                        subdf = subdf.loc[subdf[\"Implementation\"] == i]\n            elif key == \"server_test\":\n                for i in request.form.getlist(\"server_test\"):\n                    if subdf is None:\n                        subdf = df_csv.loc[df_csv[\"TestName\"] == i]\n                    else:\n                        subdf = subdf.loc[subdf[\"TestName\"] == i]\n            elif key == \"client_test\":\n                for i in request.form.getlist(\"client_test\"):\n                    if subdf is None:\n                        subdf = df_csv.loc[df_csv[\"TestName\"] == i]\n                    else:\n                        subdf = subdf.loc[subdf[\"TestName\"] == i]\n\n        if subdf is not None:\n            df_csv = subdf\n\n        csv_text = df_csv.to_csv()\n\n        output = \"df_csv.html\"\n        # TODO change the label\n        configurationData = [\n            {\n                \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n                \"name\": \"Experiences coverage view\",\n                \"parameters\": [\"Implementation\", \"Mode\", \"TestName\"],\n                \"measurements\": [\n                    \"isPass\",\n                    \"ErrorIEV\",\n                    \"packet_event\",\n                    \"packet_event_retry\",\n                    \"packet_event_vn\",\n                    \"packet_event_0rtt\",\n                    \"packet_event_coal_0rtt\",\n                    \"recv_packet\",\n                    \"recv_packet_retry\",\n                    \"handshake_done\",\n                    \"tls.finished\",\n                    \"recv_packet_vn\",\n                    \"recv_packet_0rtt\",\n                    \"undecryptable_packet_event\",\n                    \"version_not_found_event\",\n                    \"date\",\n                    \"initial_version\",\n                    \"NbPktSend\",\n                    \"version_not_found\",\n                ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n                \"data\": df_csv.to_csv(index=False),\n            },\n            {\n                \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n                \"name\": \"Experiences coverage view\",\n                \"parameters\": [\"Implementation\", \"Mode\", \"TestName\"],\n                \"measurements\": [\n                    \"isPass\",\n                    \"ErrorIEV\",\n                    \"packet_event\",\n                    \"packet_event_retry\",\n                    \"packet_event_vn\",\n                    \"packet_event_0rtt\",\n                    \"packet_event_coal_0rtt\",\n                    \"recv_packet\",\n                    \"recv_packet_retry\",\n                    \"handshake_done\",\n                    \"tls.finished\",\n                    \"recv_packet_vn\",\n                    \"recv_packet_0rtt\",\n                    \"undecryptable_packet_event\",\n                    \"version_not_found_event\",\n                    \"date\",\n                    \"initial_version\",\n                    \"NbPktSend\",\n                    \"version_not_found\",\n                ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n                \"data\": df_csv.to_csv(index=False),\n            },\n            {\n                \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n                \"name\": \"Experiences coverage view\",\n                \"parameters\": [\"Implementation\", \"Mode\", \"TestName\"],\n                \"measurements\": [\n                    \"isPass\",\n                    \"ErrorIEV\",\n                    \"packet_event\",\n                    \"packet_event_retry\",\n                    \"packet_event_vn\",\n                    \"packet_event_0rtt\",\n                    \"packet_event_coal_0rtt\",\n                    \"recv_packet\",\n                    \"recv_packet_retry\",\n                    \"handshake_done\",\n                    \"tls.finished\",\n                    \"recv_packet_vn\",\n                    \"recv_packet_0rtt\",\n                    \"undecryptable_packet_event\",\n                    \"version_not_found_event\",\n                    \"date\",\n                    \"initial_version\",\n                    \"NbPktSend\",\n                    \"version_not_found\",\n                ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n                \"data\": df_csv.to_csv(index=False),\n            },\n        ]\n        # The above code is not valid Python code. It appears to be the beginning of a comment or\n        # documentation string, but it is missing the closing characters.\n\n        export(configurationData, output)\n\n        # PFVServer.app.logger.info(configurationData)\n\n        with open(output, \"r\") as f:\n            df_csv_content = f.read()\n\n        return render_template(\n            \"result-global.html\",\n            nb_exp=PFVServer.total_exp_in_dir,\n            current_exp=PFVServer.current_exp_path,\n            summary=summary,\n            csv_text=csv_text,\n            tests_requested=PFVServer.tests_requested,\n            client_tests=PFVServer.client_tests,\n            implementation_requested=PFVServer.implementation_requested,\n            min_date=None,\n            max_date=None,\n            df_nb_date=df_nb_date,\n            df_dates=list(df_dates),\n            df_csv_content=df_csv_content,\n        )\n\n    def get_attack_model(self, attack_model):\n\"\"\"\n        It returns the attack model\n        :param attack_model: the attack model\n        :return: the attack model\n        \"\"\"\n        return attack_model\n\n    @app.route(\"/kg/graph/json\", methods=[\"GET\"])\n    def get_json_graph():\n\"\"\"\n        It returns the json graph of the knowledge graph\n        :return: the json graph of the knowledge graph\n        \"\"\"\n        with open(\"/tmp/cytoscape_config.json\", \"r\") as json_file:\n            data = json.load(json_file)\n\n        response = PFVServer.app.response_class(\n            response=json.dumps(data), status=200, mimetype=\"application/json\"\n        )\n        return response\n\n    # TODO redo\n    @app.route(\"/creator.html\", methods=[\"GET\", \"POST\"])\n    def serve_attack():\n\"\"\"\n        It creates a folder for the project, and then calls the upload function\n        :return: the upload function.\n        \"\"\"\n        # PFVServer.experiments.update_includes_ptls()\n        # PFVServer.experiments.update_includes()\n        setup_quic_model(PFVServer.protocol_test_path)\n        setup_cytoscape()\n        return render_template(\"creator.html\")\n\n    def run(self):\n        PFVServer.app.run(\n            host=\"0.0.0.0\", port=80, use_reloader=True, threaded=True\n        )  # , processes=4\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.add_header","title":"<code>add_header(r)</code>","text":"<p>It sets the cache control headers to prevent caching</p> <p>:param r: The response object :return: the response object with the headers added.</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>@app.after_request\ndef add_header(r):\n\"\"\"\n    It sets the cache control headers to prevent caching\n\n    :param r: The response object\n    :return: the response object with the headers added.\n    \"\"\"\n    r.headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\"\n    r.headers[\"Pragma\"] = \"no-cache\"\n    r.headers[\"Expires\"] = \"0\"\n    r.headers[\"Cache-Control\"] = \"public, max-age=0\"\n    r.headers.add(\"Access-Control-Allow-Headers\", \"authorization,content-type\")\n    r.headers.add(\n        \"Access-Control-Allow-Methods\",\n        \"DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT\",\n    )\n    r.headers.add(\"Access-Control-Allow-Origin\", \"*\")\n    return r\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.get_args","title":"<code>get_args()</code>","text":"<p>summary Get list of argument for automatic GUI generation Returns:     type: description</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>def get_args():\n\"\"\"_summary_\n    Get list of argument for automatic GUI generation\n    Returns:\n        _type_: _description_\n    \"\"\"\n    # TODO refactor\n    PFVServer.choices_args = {}\n    args_parser = ArgumentParserRunner().parser\n    args_list = [{}]\n    is_mutually_exclusive = True\n    for group_type in [\n        args_parser._mutually_exclusive_groups,\n        args_parser._action_groups,\n    ]:\n        for group in group_type:\n            if group.title == \"positional arguments\":\n                continue\n            if group.title == \"optional arguments\":\n                continue\n            if group.title == \"Usage type\":\n                continue\n\n            cont = False\n            for p in PFVServer.supported_protocols:\n                if p in group.title.lower():\n                    cont = True\n            if cont:\n                continue\n\n            if len(args_list[-1]) == 3:\n                args_list.append({})\n\n            for action in group._group_actions:\n                group_name = group.title\n                if group_name not in args_list[-1]:\n                    args_list[-1][group_name] = []\n                if isinstance(action, argparse._StoreTrueAction):\n                    args_list[-1][group_name].append(\n                        {\n                            \"name\": action.dest,\n                            \"help\": action.help,\n                            \"type\": \"bool\",\n                            \"default\": False,\n                            \"is_mutually_exclusive\": is_mutually_exclusive,\n                            \"description\": action.metavar,\n                        }\n                    )\n                elif isinstance(action, argparse._StoreFalseAction):\n                    args_list[-1][group_name].append(\n                        {\n                            \"name\": action.dest,\n                            \"help\": action.help,\n                            \"type\": \"bool\",\n                            \"default\": True,\n                            \"is_mutually_exclusive\": is_mutually_exclusive,\n                            \"description\": action.metavar,\n                        }\n                    )\n                elif not isinstance(action, argparse._HelpAction):\n                    if hasattr(action, \"choices\"):\n                        if action.choices:\n                            PFVServer.choices_args[action.dest] = action.choices\n                        args_list[-1][group_name].append(\n                            {\n                                \"name\": action.dest,\n                                \"help\": action.help,\n                                \"type\": str(action.type),\n                                \"default\": action.default,\n                                \"is_mutually_exclusive\": is_mutually_exclusive,\n                                \"choices\": action.choices,\n                                \"description\": action.metavar,\n                            }\n                        )\n                    else:\n                        args_list[-1][group_name].append(\n                            {\n                                \"name\": action.dest,\n                                \"help\": action.help,\n                                \"type\": str(action.type),\n                                \"default\": action.default,\n                                \"is_mutually_exclusive\": is_mutually_exclusive,\n                                \"description\": action.metavar,\n                            }\n                        )\n        is_mutually_exclusive = False\n\n    json_arg = args_list\n\n    args_list = [{}]\n    is_mutually_exclusive = True\n    for group_type in [\n        args_parser._mutually_exclusive_groups,\n        args_parser._action_groups,\n    ]:\n        for group in group_type:\n            for p in PFVServer.supported_protocols:\n                if p in group.title.lower():\n                    if p in PFVServer.current_protocol:\n                        if len(args_list[-1]) == 3:\n                            args_list.append({})\n\n                        for action in group._group_actions:\n                            group_name = group.title\n                            if group_name not in args_list[-1]:\n                                args_list[-1][group_name] = []\n                            if isinstance(action, argparse._StoreTrueAction):\n                                args_list[-1][group_name].append(\n                                    {\n                                        \"name\": action.dest,\n                                        \"help\": action.help,\n                                        \"type\": \"bool\",\n                                        \"default\": False,\n                                        \"is_mutually_exclusive\": is_mutually_exclusive,\n                                        \"description\": action.metavar,\n                                    }\n                                )\n                            elif isinstance(action, argparse._StoreFalseAction):\n                                args_list[-1][group_name].append(\n                                    {\n                                        \"name\": action.dest,\n                                        \"help\": action.help,\n                                        \"type\": \"bool\",\n                                        \"default\": True,\n                                        \"is_mutually_exclusive\": is_mutually_exclusive,\n                                        \"description\": action.metavar,\n                                    }\n                                )\n                            elif not isinstance(action, argparse._HelpAction):\n                                if hasattr(action, \"choices\"):\n                                    if action.choices:\n                                        PFVServer.choices_args[action.dest] = (\n                                            action.choices\n                                        )\n                                    args_list[-1][group_name].append(\n                                        {\n                                            \"name\": action.dest,\n                                            \"help\": action.help,\n                                            \"type\": str(action.type),\n                                            \"default\": action.default,\n                                            \"is_mutually_exclusive\": is_mutually_exclusive,\n                                            \"choices\": action.choices,\n                                            \"description\": action.metavar,\n                                        }\n                                    )\n                                else:\n                                    args_list[-1][group_name].append(\n                                        {\n                                            \"name\": action.dest,\n                                            \"help\": action.help,\n                                            \"type\": str(action.type),\n                                            \"default\": action.default,\n                                            \"is_mutually_exclusive\": is_mutually_exclusive,\n                                            \"description\": action.metavar,\n                                        }\n                                    )\n                    is_mutually_exclusive = False\n    prot_arg = args_list\n    return json_arg, prot_arg\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.get_attack_model","title":"<code>get_attack_model(attack_model)</code>","text":"<p>It returns the attack model :param attack_model: the attack model :return: the attack model</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>def get_attack_model(self, attack_model):\n\"\"\"\n    It returns the attack model\n    :param attack_model: the attack model\n    :return: the attack model\n    \"\"\"\n    return attack_model\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.get_json_graph","title":"<code>get_json_graph()</code>","text":"<p>It returns the json graph of the knowledge graph :return: the json graph of the knowledge graph</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>@app.route(\"/kg/graph/json\", methods=[\"GET\"])\ndef get_json_graph():\n\"\"\"\n    It returns the json graph of the knowledge graph\n    :return: the json graph of the knowledge graph\n    \"\"\"\n    with open(\"/tmp/cytoscape_config.json\", \"r\") as json_file:\n        data = json.load(json_file)\n\n    response = PFVServer.app.response_class(\n        response=json.dumps(data), status=200, mimetype=\"application/json\"\n    )\n    return response\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.redirection","title":"<code>redirection()</code>","text":"<p>It redirects the user to the index.html page :return: a redirect to the index.html page.</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>@app.route(\"/\")\ndef redirection():\n\"\"\"\n    It redirects the user to the index.html page\n    :return: a redirect to the index.html page.\n    \"\"\"\n    return redirect(\"index.html\", code=302)\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.serve_attack","title":"<code>serve_attack()</code>","text":"<p>It creates a folder for the project, and then calls the upload function :return: the upload function.</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>@app.route(\"/creator.html\", methods=[\"GET\", \"POST\"])\ndef serve_attack():\n\"\"\"\n    It creates a folder for the project, and then calls the upload function\n    :return: the upload function.\n    \"\"\"\n    # PFVServer.experiments.update_includes_ptls()\n    # PFVServer.experiments.update_includes()\n    setup_quic_model(PFVServer.protocol_test_path)\n    setup_cytoscape()\n    return render_template(\"creator.html\")\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.serve_index","title":"<code>serve_index()</code>","text":"<p>It creates a folder for the project, and then calls the upload function :return: the upload function.</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>@app.route(\"/index.html\", methods=[\"GET\", \"POST\"])\ndef serve_index():\n\"\"\"\n    It creates a folder for the project, and then calls the upload function\n    :return: the upload function.\n    \"\"\"\n    PFVServer.app.logger.info(\"Protocols under test: \" + PFVServer.current_protocol)\n\n    if DEBUG:\n        json_arg, prot_arg = PFVServer.get_args()\n        PFVServer.app.logger.info(\"JSON arguments availables:\")\n        for elem in json_arg:\n            PFVServer.app.logger.info(elem)\n        PFVServer.app.logger.info(\"PROTOCOL arguments availables:\")\n        for elem in prot_arg:\n            PFVServer.app.logger.info(elem)\n\n    if request.method == \"POST\":\n        # TODO link json_arg and prot_arg to config so we can restore old config\n        # TODO fix problem with alpn &amp; initial version\n        if (\n            request.args.get(\"prot\", \"\")\n            and request.args.get(\"prot\", \"\") in PFVServer.supported_protocols\n        ):\n            # The Selected Protocol change -&gt; change GUI\n            json_arg, prot_arg = PFVServer.change_current_protocol(\n                request.args.get(\"prot\", \"\")\n            )\n\n            (\n                PFVServer.supported_protocols,\n                PFVServer.current_protocol,\n                PFVServer.tests_enabled,\n                PFVServer.conf_implementation_enable,\n                PFVServer.implementation_enable,\n                PFVServer.protocol_model_path,\n                PFVServer.protocol_results_path,\n                PFVServer.protocol_test_path,\n                PFVServer.config,\n                PFVServer.protocol_conf,\n            ) = get_experiment_config(PFVServer.current_protocol, True, False)\n\n        # TODO implem progress, avoid to use post if experience already launched\n        # TODO force to select at least one test and one implem\n        PFVServer.app.logger.info(\"Form in POST request:\")\n        PFVServer.app.logger.info(request.form)\n        if DEBUG:\n            for c in request.form:\n                for elem in request.form.getlist(c):\n                    PFVServer.app.logger.info(elem)\n\n        PFVServer.implementation_requested = []\n        experiment_arguments = {}\n        protocol_arguments = {}\n        PFVServer.tests_requested = []\n\n        arguments = dict(request.form)\n        exp_number = 1\n        for key, value in arguments.items():\n            if (key, value) == (\"boundary\", \"experiment separation\"):\n                exp_number += 1\n            elif (\n                key in PFVServer.implementation_enable.keys() and value == \"true\"\n            ):\n                PFVServer.implementation_requested.append(key)\n            elif \"test\" in key and value == \"true\":\n                PFVServer.tests_requested.append(key)\n            elif value != \"\":\n                if key in PFVServer.choices_args:\n                    print(PFVServer.choices_args[key])\n                    value = str(PFVServer.choices_args[key][int(value) - 1])\n                if exp_number == 1:\n                    experiment_arguments[key] = value\n                elif exp_number == 2:\n                    protocol_arguments[key] = value\n\n        PFVServer.app.logger.info(\n            \"Experiment arguments: \" + str(experiment_arguments)\n        )\n        PFVServer.app.logger.info(\"Protocol arguments: \" + str(protocol_arguments))\n        PFVServer.app.logger.info(\n            \"Experiment tests requested: \" + str(PFVServer.tests_requested)\n        )\n\n        PFVServer.is_experiment_started = True\n        PFVServer.experiment_iteration = (\n            len(PFVServer.implementation_requested)\n            * len(PFVServer.tests_requested)\n            * int(experiment_arguments[\"iter\"])\n        )\n\n        PFVServer.start_experiment_thread(experiment_arguments, protocol_arguments)\n    else:\n        if (\n            request.args.get(\"prot\", \"\")\n            and request.args.get(\"prot\", \"\") in PFVServer.supported_protocols\n        ):\n            json_arg, prot_arg = PFVServer.change_current_protocol(\n                request.args.get(\"prot\", \"\")\n            )\n            (\n                PFVServer.supported_protocols,\n                PFVServer.current_protocol,\n                PFVServer.tests_enabled,\n                PFVServer.conf_implementation_enable,\n                PFVServer.implementation_enable,\n                PFVServer.protocol_model_path,\n                PFVServer.protocol_results_path,\n                PFVServer.protocol_test_path,\n                PFVServer.config,\n                PFVServer.protocol_conf,\n            ) = get_experiment_config(PFVServer.current_protocol, True, False)\n\n    return render_template(\n        \"index.html\",\n        json_arg=json_arg,\n        prot_arg=prot_arg,\n\n        base_conf          =PFVServer.config,\n        protocol_conf      =PFVServer.protocol_conf,\n        supported_protocols=PFVServer.supported_protocols,\n        current_protocol   =PFVServer.current_protocol,\n\n        nb_exp                  =PFVServer.total_exp_in_dir,\n        tests_enable            =PFVServer.tests_enabled,\n        implementation_enable   =PFVServer.implementation_enable,\n        implementation_requested=PFVServer.implementation_requested,\n        progress                =PFVServer.experiment_current_iteration,  # PFVServer.experiments.count_1,\n        iteration               =PFVServer.experiment_iteration,\n    )\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.serve_results","title":"<code>serve_results()</code>","text":"<p>It creates a folder for the project, and then calls the upload function :return: the upload function.</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>@app.route(\"/results.html\", methods=[\"GET\", \"POST\"])\ndef serve_results():\n\"\"\"\n    It creates a folder for the project, and then calls the upload function\n    :return: the upload function.\n    \"\"\"\n    PFVServer.app.logger.info(\n        \"Current Protocol Tests output folder: \" + PFVServer.protocol_results_path\n    )\n    PFVServer.app.logger.info(os.listdir(PFVServer.protocol_results_path))\n\n    with os.scandir(PFVServer.protocol_results_path) as entries:\n        PFVServer.total_exp_in_dir = sum(1 for entry in entries if entry.is_dir())\n\n    default_page = 0\n    page = request.args.get(\"page\", default_page)\n    try:\n        page = page.number\n    except:\n        pass\n    # Get queryset of items to paginate\n    rge = range(PFVServer.total_exp_in_dir, 0, -1)\n    PFVServer.app.logger.info([i for i in rge])\n    PFVServer.app.logger.info(page)\n    items = [i for i in rge]\n\n    # Paginate items\n    items_per_page = 1\n    paginator = Paginator(items, per_page=items_per_page)\n\n    try:\n        items_page = paginator.page(page)\n    except PageNotAnInteger:\n        items_page = paginator.page(default_page)\n    except EmptyPage:\n        items_page = paginator.page(paginator.num_pages)\n\n    df_csv = pd.read_csv(PFVServer.protocol_results_path + \"data.csv\").set_index(\n        \"Run\"\n    )\n    PFVServer.app.logger.info(PFVServer.total_exp_in_dir - int(page))\n\n    result_row = df_csv.iloc[-1]\n    output = \"df_csv_row.html\"\n    # TODO change the label\n    # result_row.to_frame().T\n    # subdf = df_csv.drop(\"ErrorIEV\", axis=1).drop(\"OutputFile\", axis=1).drop(\"date\", axis=1).drop(\"date\", axis=1).drop(\"date\", axis=1) #.reset_index()\n    subdf = df_csv[[\"Implementation\", \"NbPktSend\", \"packet_event\", \"recv_packet\"]]\n    subdf.fillna(0, inplace=True)\n    # subdf[\"isPass\"] = subdf[\"isPass\"].astype(int)\n    subdf[\"NbPktSend\"] = subdf[\"NbPktSend\"].astype(int)\n    # PFVServer.app.logger.info(subdf)\n    # PFVServer.app.logger.info(df_csv.columns)\n    # PFVServer.app.logger.info(subdf.columns)\n    # subdf.columns = df_csv.columns\n    configurationData = [\n        {\n            \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n            \"name\": \"Experiences coverage view\",\n            \"parameters\": [\"Run\"],  # \"Implementation\",\n            \"measurements\": [\n                \"NbPktSend\"\n            ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n            \"data\": subdf.to_csv(),\n        },\n        {\n            \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n            \"name\": \"Experiences packet view\",\n            \"parameters\": [\"Run\"],  # \"Implementation\"\n            \"measurements\": [\n                \"packet_event\",\n                \"recv_packet\",\n            ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n            \"data\": subdf.to_csv(),  # index=False -&gt; need index\n        },\n    ]\n\n    export(configurationData, output)\n\n    # PFVServer.app.logger.info(configurationData)\n\n    with open(output, \"r\") as f:\n        df_csv_content = f.read()\n\n    summary = {}\n    summary[\"nb_pkt\"] = result_row[\"NbPktSend\"]\n    summary[\"initial_version\"] = result_row[\"initial_version\"]\n\n    PFVServer.current_exp_path = PFVServer.protocol_results_path + str(\n        PFVServer.total_exp_in_dir - int(page)\n    )\n    exp_dir = os.listdir(PFVServer.current_exp_path)\n    ivy_stderr = \"No output\"\n    ivy_stdout = \"No output\"\n    implem_err = \"No output\"\n    implem_out = \"No output\"\n    iev_out = \"No output\"\n    qlog_file = \"\"\n    pcap_file = \"\"\n    for file in exp_dir:\n        PFVServer.app.logger.info(file)\n        if \"ivy_stderr.txt\" in file:\n            with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                content = f.read()\n                if content == \"\":\n                    pass\n                else:\n                    ivy_stderr = content\n        elif \"ivy_stdout.txt\" in file:\n            with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                content = f.read()\n                if content == \"\":\n                    pass\n                else:\n                    ivy_stdout = content\n        elif \".err\" in file:\n            with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                content = f.read()\n                if content == \"\":\n                    pass\n                else:\n                    implem_err = content\n        elif \".out\" in file:\n            with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                content = f.read()\n                if content == \"\":\n                    pass\n                else:\n                    implem_out = content\n        elif \".iev\" in file:\n            # TODO use csv file\n            # file creation timestamp in float\n            c_time = os.path.getctime(PFVServer.current_exp_path + \"/\" + file)\n            # convert creation timestamp into DateTime object\n            dt_c = datetime.datetime.fromtimestamp(c_time)\n            PFVServer.app.logger.info(\"Created on:\" + str(dt_c))\n            summary[\"date\"] = dt_c\n            test_name = file.replace(\".iev\", \"\")[0:-1]\n            summary[\"test_name\"] = test_name\n            with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                content = f.read()\n                summary[\"test_result\"] = (\n                    \"Pass\" if \"test_completed\" in content else \"Fail\"\n                )\n\n            try:\n                plantuml_file = PFVServer.current_exp_path + \"/plantuml.puml\"\n                generate_graph_input(\n                    PFVServer.current_exp_path + \"/\" + file, plantuml_file\n                )\n                plantuml_obj = PlantUML(\n                    url=\"http://www.plantuml.com/plantuml/img/\",\n                    basic_auth={},\n                    form_auth={},\n                    http_opts={},\n                    request_opts={},\n                )\n\n                plantuml_file_png = plantuml_file.replace(\n                    \".puml\", \".png\"\n                )  # \"media/\" + str(nb_exp) + \"_plantuml.png\"\n                plantuml_obj.processes_file(plantuml_file, plantuml_file_png)\n\n                with open(PFVServer.current_exp_path + \"/\" + file, \"r\") as f:\n                    content = f.read()\n                    if content == \"\":\n                        pass\n                    else:\n                        iev_out = content\n            except:\n                pass\n        elif \".pcap\" in file:\n            pcap_file = file\n            # Now we need qlogs and pcap informations\n            summary[\"implementation\"] = file.split(\"_\")[0]\n            summary[\"test_type\"] = file.split(\"_\")[2]\n\n        elif \".qlog\" in file:\n            qlog_file = file\n\n    # Get page number from request,\n    # default to first page\n    try:\n        binary_fc = open(plantuml_file_png, \"rb\").read()  # fc aka file_content\n        base64_utf8_str = b64encode(binary_fc).decode(\"utf-8\")\n\n        ext = plantuml_file_png.split(\".\")[-1]\n    except:\n        base64_utf8_str = \"\"\n        ext = \"png\"\n    dataurl = f\"data:image/{ext};base64,{base64_utf8_str}\"\n    PFVServer.app.logger.info(items_page)\n    PFVServer.app.logger.info(paginator)\n\n    return render_template(\n        \"results.html\",\n        items_page=items_page,\n        nb_exp=PFVServer.total_exp_in_dir,\n        page=int(page),\n        current_exp=PFVServer.current_exp_path,\n        ivy_stderr=ivy_stderr,\n        ivy_stdout=ivy_stdout,\n        implem_err=implem_err,\n        implem_out=implem_out,\n        iev_out=iev_out,\n        plantuml_file_png=dataurl,\n        summary=summary,  # \"http://\"+PFVServer.vizualiser_ip+\":80/?file=http://\"\n        pcap_frame_link=(\n            \"http://ivy-visualizer:80/?file=http://ivy-standalone:80/directory/\"\n            + str(PFVServer.total_exp_in_dir - int(page))\n            + \"/file/\"\n            + pcap_file\n            + \"&amp;secrets=http://ivy-standalone:80/key/\"\n            + summary[\"implementation\"]\n            + \"_key.log\"\n            if pcap_file != \"\"\n            else None\n        ),\n        qlog_frame_link=(\n            \"http://ivy-visualizer:80/?file=http://ivy-standalone:80/directory/\"\n            + str(PFVServer.total_exp_in_dir - int(page))\n            + \"/file/\"\n            + qlog_file\n            if qlog_file != \"\"\n            else None\n        ),\n        df_csv_content=df_csv_content,\n    )\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/panther_server.html#panther.panther_webapp.app.panther_server.PFVServer.serve_results_global","title":"<code>serve_results_global()</code>","text":"<p>It creates a folder for the project, and then calls the upload function :return: the upload function.</p> Source code in <code>panther/panther_webapp/app/panther_server.py</code> <pre><code>@app.route(\"/results-global.html\", methods=[\"GET\", \"POST\"])\ndef serve_results_global():\n\"\"\"\n    It creates a folder for the project, and then calls the upload function\n    :return: the upload function.\n    \"\"\"\n    PFVServer.total_exp_in_dir = (\n        len(os.listdir(PFVServer.protocol_results_path)) - 2\n    )\n\n    PFVServer.app.logger.info(request.form)\n\n    summary = {}\n    df_csv = pd.read_csv(\n        PFVServer.protocol_results_path + \"data.csv\", parse_dates=[\"date\"]\n    )\n\n    df_simplify_date = df_csv\n    df_simplify_date[\"date\"] = df_csv[\"date\"].dt.strftime(\"%d/%m/%Y\")\n    df_date_min_max = df_simplify_date[\"date\"].agg([\"min\", \"max\"])\n    df_nb_date = df_simplify_date[\"date\"].nunique()\n    df_dates = df_simplify_date[\"date\"].unique()\n    PFVServer.app.logger.info(list(df_dates))\n    PFVServer.app.logger.info(df_date_min_max)\n    PFVServer.app.logger.info(df_nb_date)\n    minimum_date = df_date_min_max[\"min\"]\n    maximum_date = df_date_min_max[\"max\"]\n\n    subdf = None\n    # if len(request.form) &gt;= 0:\n    for key in request.form:\n        if key == \"date_range\":\n            minimum = df_dates[int(request.form.get(\"date_range\").split(\",\")[0])]\n            maximum = df_dates[int(request.form.get(\"date_range\").split(\",\")[1])]\n            if subdf is None:\n                subdf = df_csv.query(\"date &gt;= @minimum and date &lt;= @maximum\")\n            else:\n                subdf = subdf.query(\"date &gt;= @minimum and date &lt;= @maximum\")\n        elif key == \"iter_range\":\n            minimum = request.form.get(\"iter_range\").split(\",\")[0]\n            maximum = request.form.get(\"iter_range\").split(\",\")[1]\n            if subdf is None:  # TOODO\n                subdf = df_csv.loc[df_csv[\"Run\"] &gt;= int(minimum)]\n                subdf = subdf.loc[subdf[\"Run\"] &lt;= int(maximum)]\n            else:\n                subdf = subdf.loc[subdf[\"Run\"] &gt;= int(minimum)]\n                subdf = subdf.loc[subdf[\"Run\"] &lt;= int(maximum)]\n        elif key == \"version\":\n            if request.form.get(\"version\") != \"all\":\n                if subdf is None:  # TOODO\n                    subdf = df_csv.loc[\n                        df_csv[\"initial_version\"] == request.form.get(\"version\")\n                    ]\n                else:\n                    subdf = subdf.loc[\n                        subdf[\"initial_version\"] == request.form.get(\"version\")\n                    ]\n        elif key == \"ALPN\":\n            if request.form.get(\"ALPN\") != \"all\":\n                if subdf is None:  # TOODO\n                    subdf = df_csv.loc[\n                        df_csv[\"Mode\"] == request.form.get(\"test_type\")\n                    ]\n                else:\n                    subdf = subdf.loc[\n                        subdf[\"Mode\"] == request.form.get(\"test_type\")\n                    ]\n        elif key == \"test_type\":\n            if request.form.get(\"test_type\") != \"all\":\n                if subdf is None:\n                    subdf = df_csv.loc[\n                        df_csv[\"Mode\"] == request.form.get(\"test_type\")\n                    ]\n                else:\n                    subdf = subdf.loc[\n                        subdf[\"Mode\"] == request.form.get(\"test_type\")\n                    ]\n        elif key == \"isPass\":\n            ispass = True if \"True\" in request.form.get(\"isPass\") else False\n            if request.form.get(\"isPass\") != \"all\":\n                if subdf is None:\n                    subdf = df_csv.loc[df_csv[\"isPass\"] == ispass]\n                else:\n                    subdf = subdf.loc[subdf[\"isPass\"] == ispass]\n        elif key == \"implem\":\n            for i in request.form.getlist(\"implem\"):\n                PFVServer.app.logger.info(i)\n                if subdf is None:\n                    subdf = df_csv.loc[df_csv[\"Implementation\"] == i]\n                else:\n                    subdf = subdf.loc[subdf[\"Implementation\"] == i]\n        elif key == \"server_test\":\n            for i in request.form.getlist(\"server_test\"):\n                if subdf is None:\n                    subdf = df_csv.loc[df_csv[\"TestName\"] == i]\n                else:\n                    subdf = subdf.loc[subdf[\"TestName\"] == i]\n        elif key == \"client_test\":\n            for i in request.form.getlist(\"client_test\"):\n                if subdf is None:\n                    subdf = df_csv.loc[df_csv[\"TestName\"] == i]\n                else:\n                    subdf = subdf.loc[subdf[\"TestName\"] == i]\n\n    if subdf is not None:\n        df_csv = subdf\n\n    csv_text = df_csv.to_csv()\n\n    output = \"df_csv.html\"\n    # TODO change the label\n    configurationData = [\n        {\n            \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n            \"name\": \"Experiences coverage view\",\n            \"parameters\": [\"Implementation\", \"Mode\", \"TestName\"],\n            \"measurements\": [\n                \"isPass\",\n                \"ErrorIEV\",\n                \"packet_event\",\n                \"packet_event_retry\",\n                \"packet_event_vn\",\n                \"packet_event_0rtt\",\n                \"packet_event_coal_0rtt\",\n                \"recv_packet\",\n                \"recv_packet_retry\",\n                \"handshake_done\",\n                \"tls.finished\",\n                \"recv_packet_vn\",\n                \"recv_packet_0rtt\",\n                \"undecryptable_packet_event\",\n                \"version_not_found_event\",\n                \"date\",\n                \"initial_version\",\n                \"NbPktSend\",\n                \"version_not_found\",\n            ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n            \"data\": df_csv.to_csv(index=False),\n        },\n        {\n            \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n            \"name\": \"Experiences coverage view\",\n            \"parameters\": [\"Implementation\", \"Mode\", \"TestName\"],\n            \"measurements\": [\n                \"isPass\",\n                \"ErrorIEV\",\n                \"packet_event\",\n                \"packet_event_retry\",\n                \"packet_event_vn\",\n                \"packet_event_0rtt\",\n                \"packet_event_coal_0rtt\",\n                \"recv_packet\",\n                \"recv_packet_retry\",\n                \"handshake_done\",\n                \"tls.finished\",\n                \"recv_packet_vn\",\n                \"recv_packet_0rtt\",\n                \"undecryptable_packet_event\",\n                \"version_not_found_event\",\n                \"date\",\n                \"initial_version\",\n                \"NbPktSend\",\n                \"version_not_found\",\n            ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n            \"data\": df_csv.to_csv(index=False),\n        },\n        {\n            \"id\": str(uuid.uuid4()),  # Must be unique TODO df_csv_scdg['filename']\n            \"name\": \"Experiences coverage view\",\n            \"parameters\": [\"Implementation\", \"Mode\", \"TestName\"],\n            \"measurements\": [\n                \"isPass\",\n                \"ErrorIEV\",\n                \"packet_event\",\n                \"packet_event_retry\",\n                \"packet_event_vn\",\n                \"packet_event_0rtt\",\n                \"packet_event_coal_0rtt\",\n                \"recv_packet\",\n                \"recv_packet_retry\",\n                \"handshake_done\",\n                \"tls.finished\",\n                \"recv_packet_vn\",\n                \"recv_packet_0rtt\",\n                \"undecryptable_packet_event\",\n                \"version_not_found_event\",\n                \"date\",\n                \"initial_version\",\n                \"NbPktSend\",\n                \"version_not_found\",\n            ],  # , \"Total number of blocks\",'Number Syscall found' , 'Number Address found', 'Number of blocks visited', \"Total number of blocks\",\"time\"\n            \"data\": df_csv.to_csv(index=False),\n        },\n    ]\n    # The above code is not valid Python code. It appears to be the beginning of a comment or\n    # documentation string, but it is missing the closing characters.\n\n    export(configurationData, output)\n\n    # PFVServer.app.logger.info(configurationData)\n\n    with open(output, \"r\") as f:\n        df_csv_content = f.read()\n\n    return render_template(\n        \"result-global.html\",\n        nb_exp=PFVServer.total_exp_in_dir,\n        current_exp=PFVServer.current_exp_path,\n        summary=summary,\n        csv_text=csv_text,\n        tests_requested=PFVServer.tests_requested,\n        client_tests=PFVServer.client_tests,\n        implementation_requested=PFVServer.implementation_requested,\n        min_date=None,\n        max_date=None,\n        df_nb_date=df_nb_date,\n        df_dates=list(df_dates),\n        df_csv_content=df_csv_content,\n    )\n</code></pre>"},{"location":"reference/panther/panther_webapp/app/utils/index.html","title":"Index","text":""},{"location":"reference/panther/panther_webapp/app/utils/cytoscape_generator.html","title":"Cytoscape generator","text":""},{"location":"reference/panther/panther_webapp/app/utils/results_viewer.html","title":"Results viewer","text":""},{"location":"reference/panther/panther_worker/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/panther.html","title":"Panther","text":""},{"location":"reference/panther/panther_worker/app/panther.html#panther.panther_worker.app.panther.Panther","title":"<code>Panther</code>","text":"Source code in <code>panther/panther_worker/app/panther.py</code> <pre><code>class Panther:\n    def __init__(self):\n        # Setup cargo\n        subprocess.Popen(\"\", shell=True, executable=\"/bin/bash\").wait()  # TODO source\n\n        # Setup logger\n        self.log = logging.getLogger(\"panther\")\n        self.log.setLevel(logging.INFO)\n        if self.log.hasHandlers():\n            self.log.handlers.clear()\n        self.log.addHandler(ch)\n        self.log.propagate = False\n\n        # Setup argument parser\n        self.args = ArgumentParserRunner().parse_arguments()\n\n        # Setup environment variables\n        for env_var in ENV_VAR:\n            os.environ[env_var] = str(ENV_VAR[env_var])\n            if DEBUG:\n                self.log.info(\"ENV_VAR=\" + env_var)\n                self.log.info(\"ENV_VAL=\" + str(ENV_VAR[env_var]))\n\n        # Setup configuration\n        self.log.info(\"Getting Experiment configuration:\")\n        (\n            self.supported_protocols,\n            self.current_protocol,\n            self.tests_enabled,\n            self.conf_implementation_enable,\n            self.implementation_enable,\n            self.protocol_model_path,\n            self.protocol_results_path,\n            self.protocol_test_path,\n            self.config,\n            self.protocol_conf,\n        ) = get_experiment_config(None, False, False)\n\n        self.log.info(\"Selected protocol: \" + self.current_protocol)\n\n        with os.scandir(self.protocol_results_path) as entries:\n            self.total_exp_in_dir = sum(1 for entry in entries if entry.is_dir())\n        self.current_exp_path = os.path.join(\n            self.protocol_results_path, str(self.total_exp_in_dir)\n        )\n\n        self.available_test_modes = []\n        self.included_files = list()\n\n        if self.config[\"debug_parameters\"].getboolean(\"memprof\"):\n            self.memory_snapshots = []\n\n    def find_ivy_files(self):\n\"\"\"\n        Recursively find all .ivy files in the specified folder and its subfolders, excluding those with 'test' in the filename.\n\n        :param root_folder: The root folder to start the search from.\n        :return: A list of paths to the found .ivy files.\n        \"\"\"\n        ivy_files = []\n        for dirpath, _, filenames in os.walk(self.protocol_model_path):\n            for f in filenames:\n                if f.endswith(\".ivy\") and \"test\" not in f:\n                    ivy_files.append(os.path.join(dirpath, f))\n        return ivy_files\n\n\n    def update_ivy_tool(self):\n        # Note we use subprocess in order to get sudo rights\n        os.chdir(SOURCE_DIR + \"/panther-ivy/\")\n        execute_command(\"sudo python2.7 setup.py install\")\n        execute_command(\"sudo cp lib/libz3.so submodules/z3/build/python/z3\")\n\n        # TODO extract variable for path -&gt; put in module path\n        self.log.info(\n            'Update \"include\" path of python with updated version of the TLS project from \\n\\t'\n            + IVY_INCLUDE_PATH\n        )\n        files = [\n            os.path.join(IVY_INCLUDE_PATH, f)\n            for f in os.listdir(IVY_INCLUDE_PATH)\n            if os.path.isfile(os.path.join(IVY_INCLUDE_PATH, f)) and f.endswith(\".ivy\")\n        ]\n\n        self.log.info(\n            \"Copying file to /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/include/1.7/\"\n        )\n        for file in files:\n            self.log.info(\"* \" + file)\n            execute_command(\n                \"sudo /bin/cp \"\n                + file\n                + \" /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/include/1.7/\"\n            )\n\n        os.chdir(\n            \"/usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/\"\n        )\n        execute_command(\n            \"sudo /bin/cp -f -a \"\n            + \"/app/panther-ivy/lib/*.a /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/lib\",\n            must_pass=False\n        )\n\n        if self.config[\"verified_protocol\"].getboolean(\"quic\"):\n            self.log.info(\"Copying QUIC libraries\")\n            # TODO picotls add submodule\n            execute_command(\n                \"sudo /bin/cp -f -a \"\n                + \"/app/implementations/quic-implementations/picotls/*.a /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/lib\"\n            )\n            execute_command(\n                \"sudo /bin/cp -f -a \"\n                + \"/app/implementations/quic-implementations/picotls/*.a \"\n                + \"/app/panther-ivy/ivy/lib\"\n            )\n            execute_command(\n                \"sudo /bin/cp -f \"\n                + \"/app/implementations/quic-implementations/picotls/include/picotls.h /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/include\"\n            )\n            execute_command(\n                \"sudo /bin/cp -f \"\n                + \"/app/implementations/quic-implementations/picotls/include/picotls.h \"\n                + \"/app/panther-ivy/ivy/include\"\n            )\n            execute_command(\n                \"sudo /bin/cp -r -f \"\n                + \"/app/implementations/quic-implementations/picotls/include/picotls/. /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/include/picotls\"\n            )\n\n        os.chdir(SOURCE_DIR)\n\n    def setup_ivy_model(self):\n        self.log.info(\n            'Update \"include\" path of python with updated version of the project from \\n\\t'\n            + self.protocol_model_path\n        )\n\n        files = self.find_ivy_files()\n        for file in files:\n            self.log.info(\"* \" + file)\n            self.included_files.append(file)\n            execute_command(\n                \"sudo /bin/cp \"\n                + file\n                + \" /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/include/1.7/\"\n            )\n\n        if self.config[\"verified_protocol\"].getboolean(\"quic\"):\n            execute_command(\n                \"sudo /bin/cp \"\n                + self.protocol_model_path \n                + \"/quic_utils/quic_ser_deser.h\"\n                + \" /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/include/1.7/\",\n            )\n\n    def remove_includes(self):\n        self.log.info('Reset \"include\" path of python')\n        for file in self.included_files:\n            self.log.info(\"* \" + file)\n            nameFileShort = file.split(\"/\")[-1]\n            execute_command(\n                \"sudo /bin/rm /usr/local/lib/python2.7/dist-packages/ms_ivy-1.8.24-py2.7.egg/ivy/include/1.7/\"\n                + nameFileShort\n            )\n        self.included_files = list()\n\n    def build_tests(self, test_to_do={}):\n        self.log.info(\"Number of test to compile: \" + str(len(test_to_do)))\n        self.log.info(test_to_do)\n        assert len(test_to_do) &gt; 0\n\n        self.available_test_modes = test_to_do.keys()\n        self.log.info(self.available_test_modes)\n        for mode in self.available_test_modes:\n            for file in test_to_do[mode]:\n                if mode in file:  # TODO more beautiful\n                    self.log.info(\n                        \"chdir in \"\n                        + str(os.path.join(self.config[\"global_parameters\"][\"tests_dir\"],  mode + \"s\"))\n                    )\n                    os.chdir(\n                        os.path.join(self.config[\"global_parameters\"][\"tests_dir\"],  mode + \"s\")\n                    )  \n                    file = (\n                        os.path.join(\n                            self.config[\"global_parameters\"][\"tests_dir\"], file\n                        )\n                        + \".ivy\"\n                    )\n                    self.log.info(\"* \" + file)\n                    nameFileShort = file.split(\"/\")[-1]\n                    self.build_file(nameFileShort)\n        os.chdir(SOURCE_DIR)\n\n    def pair_compile_file(self, file, replacements):\n        for old_name, new_name in replacements.items():\n            if old_name in file:\n                file = file.replace(old_name, new_name)\n                self.compile_file(file)\n\n    def build_file(self, file):\n        self.compile_file(file)\n        if self.config[\"verified_protocol\"].getboolean(\"quic\"):\n            # TODO add in config file, test that should be build and run in pair\n            replacements = {\n                \"quic_server_test_0rtt\": \"quic_server_test_0rtt_stream\",\n                \"quic_server_test_0rtt_stream\": \"quic_server_test_0rtt_stream_co_close\",\n                \"quic_server_test_0rtt_stream_co_close\": \"quic_server_test_0rtt_stream_app_close\",\n                \"quic_client_test_0rtt_invalid\": \"quic_client_test_0rtt_max\",\n                \"quic_client_test_0rtt_add_val\": \"quic_client_test_0rtt_max_add_val\",\n                \"quic_client_test_0rtt_mim_replay\": \"quic_client_test_0rtt_max\",\n                \"quic_client_test_0rtt\": \"quic_client_test_0rtt_max\",\n                \"quic_client_test_0rtt_max\": \"quic_client_test_0rtt_max_co_close\",\n                \"quic_client_test_0rtt_max_co_close\": \"quic_client_test_0rtt_max_app_close\",\n                \"quic_server_test_retry_reuse_key\": \"quic_server_test_retry\",\n            }\n\n            self.pair_compile_file(file, replacements)\n\n    def compile_file(self, file):\n        if self.config[\"global_parameters\"].getboolean(\"compile\"):\n            self.log.info(\"Building/Compiling file:\")\n            child = subprocess.Popen(\n                \"ivyc trace=false show_compiled=false target=test test_iters=\"\n                + str(self.config[\"global_parameters\"][\"internal_iteration\"])\n                + \"  \"\n                + file,\n                shell=True,\n                executable=\"/bin/bash\",\n            ).wait()\n            rc = child\n            self.log.info(rc)\n            if rc != 0:\n                try:\n                    x = requests.get('http://panther-webapp/errored-experiment')\n                    self.log.info(x)\n                except:\n                    pass\n                exit(1)\n\n            self.log.info(\"Moving built file in correct folder:\")\n            execute_command(\"/usr/bin/chmod +x \" + file.replace(\".ivy\", \"\"))\n            execute_command(\n                \"/bin/cp \"\n                + file.replace(\".ivy\", \"\")\n                + \" \"\n                + self.config[\"global_parameters\"][\"build_dir\"]\n            )\n            execute_command(\n                \"/bin/cp \"\n                + file.replace(\".ivy\", \".cpp\")\n                + \" \"\n                + self.config[\"global_parameters\"][\"build_dir\"]\n            )\n            execute_command(\n                \"/bin/cp \"\n                + file.replace(\".ivy\", \".h\")\n                + \" \"\n                + self.config[\"global_parameters\"][\"build_dir\"]\n            )\n            execute_command(\"/bin/rm \" + file.replace(\".ivy\", \"\"))\n            execute_command(\"/bin/rm \" + file.replace(\".ivy\", \".cpp\"))\n            execute_command(\"/bin/rm \" + file.replace(\".ivy\", \".h\"))\n\n    def launch_experiments(self, implementations=None):\n        try:\n            build_dir = os.path.join(MODEL_DIR, self.current_protocol, \"build/\")\n            if not os.path.isdir(build_dir):\n                self.log.info(f\"Creating directory: {build_dir}\")\n                os.mkdir(build_dir)\n            if self.config[\"debug_parameters\"].getboolean(\"memprof\"):\n                tracemalloc.start()\n\n            if self.config[\"global_parameters\"].getboolean(\"update_ivy\"):\n                self.update_ivy_tool()\n            self.setup_ivy_model()\n\n            # Set environement-specific env var\n            if not self.config[\"global_parameters\"].getboolean(\"docker\"):\n                os.environ[\"IS_NOT_DOCKER\"] = \"true\"\n                ENV_VAR[\"IS_NOT_DOCKER\"] = \"true\"\n            else:\n                if \"IS_NOT_DOCKER\" in os.environ:\n                    del os.environ[\"IS_NOT_DOCKER\"]\n                if \"IS_NOT_DOCKER\" in ENV_VAR:\n                    del ENV_VAR[\"IS_NOT_DOCKER\"]\n\n            # Set network-specific env var\n            if self.config[\"net_parameters\"].getboolean(\"shadow\"):\n                ENV_VAR[\"LOSS\"] = float(self.config[\"shadow_parameters\"][\"loss\"])\n                ENV_VAR[\"LATENCY\"] = int(self.config[\"shadow_parameters\"][\"latency\"])\n                ENV_VAR[\"JITTER\"] = int(self.config[\"shadow_parameters\"][\"jitter\"])\n                if DEBUG:\n                    self.log.info(ENV_VAR[\"LOSS\"])\n                    self.log.info(ENV_VAR[\"LATENCY\"])\n                    self.log.info(ENV_VAR[\"JITTER\"])\n\n            if not self.config[\"global_parameters\"].getboolean(\"docker\"):\n                execute_command(\n                    \"sudo sysctl -w net.core.rmem_max=2500000\"\n                )\n\n            self.build_tests(test_to_do=self.tests_enabled)\n\n            if implementations == None or implementations == []:\n                self.log.error(\n                    \"TODO implement in local mode, for now only with docker (ERROR)\"\n                )\n                # exit(0)\n                # TODO implement in local mode, for now only with docker\n\n            for implem in implementations:\n                self.log.info(implem)\n                self.log.info(self.implementation_enable.keys())\n                if implem not in self.implementation_enable.keys():\n                    self.log.info(\"Unknown implementation\")\n                    sys.stderr.write(\"nknown implementation: {}\\n\".format(implem))\n                    # exit(1)\n\n            if self.config[\"verified_protocol\"].getboolean(\"apt\"):\n                self.log.info(self.config)\n                self.log.info(self.protocol_conf)\n                self.log.info(self.current_protocol)\n                self.log.info(self.conf_implementation_enable)\n                self.log.info(self.tests_enabled)\n                # exit()\n                runner = APTRunner(\n                    self.config,\n                    self.protocol_conf,\n                    self.current_protocol,\n                    self.conf_implementation_enable,\n                    self.tests_enabled,\n                )\n            elif self.config[\"verified_protocol\"].getboolean(\"quic\"):\n                runner = QUICRunner(\n                    self.config,\n                    self.protocol_conf,\n                    self.current_protocol,\n                    self.conf_implementation_enable,\n                    self.tests_enabled,\n                )\n            elif self.config[\"verified_protocol\"].getboolean(\"minip\"):\n                runner = MiniPRunner(\n                    self.config,\n                    self.protocol_conf,\n                    self.current_protocol,\n                    self.conf_implementation_enable,\n                    self.tests_enabled,\n                )\n            else:\n                self.log.info(\"No protocols selected\")\n                # exit(0)\n\n            self.log.info(\"Starting experiments:\")\n            for implementation in implementations:\n                self.log.info(\"- Starting tests for implementation: \" + implementation)\n                os.environ[\"TEST_IMPL\"] = implementation\n                ENV_VAR[\"TEST_IMPL\"]    = implementation\n                try:\n                    runner.run_exp(implementation)\n                    self.log.info(\"Experiments finished\")\n                except Exception as e:\n                    print(e)\n                    restore_config()\n                    try:\n                        x = requests.get('http://panther-webapp/errored-experiment')\n                        self.log.info(x)\n                    except:\n                        pass\n                finally:  # In Runner.py\n                    if self.config[\"net_parameters\"].getboolean(\"vnet\"):\n                        self.log.info(\"Reset vnet\")\n                        subprocess.Popen(\n                            \"bash  /app/scripts/vnet/vnet_reset.sh\",\n                            shell=True,\n                            executable=\"/bin/bash\",\n                        ).wait()\n\n            self.log.info(\"Experiments finished\")\n\n            if self.config[\"debug_parameters\"].getboolean(\"memprof\"):\n                self.log.info(\"Memory profiling\")\n                snapshot = tracemalloc.take_snapshot()\n                top_stats = snapshot.statistics(\"lineno\")\n                self.log.info(\"[ Top 50 ]\")\n                for stat in top_stats[:50]:\n                    self.log.info(stat)\n\n            if self.config[\"debug_parameters\"].getboolean(\"ivy_process_tracer\"):\n                try:\n                    self.generate_uml_trace()\n                except Exception as e:\n                    print(e)\n\n            self.log.info(\"END 1\")\n            try:\n                x = requests.get('http://panther-webapp/finish-experiment')\n                self.log.info(x)\n                # exit(0)\n            except:\n                pass\n            # exit(0)\n        except Exception as e: \n            print(e)\n            try:\n                x = requests.get('http://panther-webapp/errored-experiment')\n                self.log.info(x)\n            except:\n                pass\n            self.log.error(\"END 2\")\n            # exit(1)\n\n    def generate_uml_trace(self):\n        self.log.info(\"Generating PlantUML trace from ivy trace\")\n        plantuml_file = \"/ivy_trace.txt\"\n        plantuml_obj = PlantUML(\n            url=\"http://www.plantuml.com/plantuml/img/\",\n            basic_auth={},\n            form_auth={},\n            http_opts={},\n            request_opts={},\n        )\n        plantuml_file_png = plantuml_file.replace(\n            \".puml\", \".png\"\n        )  # \"media/\" + str(nb_exp) + \"_plantuml.png\"\n        plantuml_obj.processes_file(plantuml_file, plantuml_file_png)\n\n    def stop_stdout(self):\n        sys.stdout.close()\n        sys.stderr.close()\n        sys.stdout = sys.__stdout__\n        sys.stderr = sys.__stderr__\n</code></pre>"},{"location":"reference/panther/panther_worker/app/panther.html#panther.panther_worker.app.panther.Panther.find_ivy_files","title":"<code>find_ivy_files()</code>","text":"<p>Recursively find all .ivy files in the specified folder and its subfolders, excluding those with 'test' in the filename.</p> <p>:param root_folder: The root folder to start the search from. :return: A list of paths to the found .ivy files.</p> Source code in <code>panther/panther_worker/app/panther.py</code> <pre><code>def find_ivy_files(self):\n\"\"\"\n    Recursively find all .ivy files in the specified folder and its subfolders, excluding those with 'test' in the filename.\n\n    :param root_folder: The root folder to start the search from.\n    :return: A list of paths to the found .ivy files.\n    \"\"\"\n    ivy_files = []\n    for dirpath, _, filenames in os.walk(self.protocol_model_path):\n        for f in filenames:\n            if f.endswith(\".ivy\") and \"test\" not in f:\n                ivy_files.append(os.path.join(dirpath, f))\n    return ivy_files\n</code></pre>"},{"location":"reference/panther/panther_worker/app/panther_client.html","title":"Panther client","text":""},{"location":"reference/panther/panther_worker/app/panther_client.html#panther.panther_worker.app.panther_client.PFVClient","title":"<code>PFVClient</code>","text":"Source code in <code>panther/panther_worker/app/panther_client.py</code> <pre><code>class PFVClient:\n    app = Flask(__name__)\n    app.debug = True\n    thread = None\n\n    def __init__(self, dir_path=None):\n        pass\n\n    # Parse the parameters received in the request and launch the SCDG\n    @app.route(\"/run-exp\", methods=[\"GET\"])\n    def run_experiment():\n        # Modify config file with the args provided in web app\n        user_data = request.json\n        os.chdir(SOURCE_DIR)\n        PFVClient.app.logger.info(\"Request to start experiment with parameters:\")\n        PFVClient.app.logger.info(user_data)\n\n        current_protocol = user_data[\"protocol\"]\n        exp_args = user_data[\"args\"]\n        net_args = \"\"\n\n        update_config(exp_args, current_protocol)\n\n        current_tests = user_data[\"tests_requested\"]\n        protocol_arguments = user_data[\"protocol_arguments\"]\n\n        update_protocol_config(protocol_arguments, current_protocol, current_tests)\n\n        tool = Panther()\n        try:\n            PFVClient.start_experiment_in_thread(user_data,tool)\n            return jsonify({\"message\": \"Request successful\"}), 200\n        except Exception as e:\n            PFVClient.app.logger.info(\"Error handling request: %s\", e)\n            return jsonify({\"message\": \"Something went wrong\", \"error\": str(e)}), 500\n\n    def start_experiment_in_thread(user_data, tool):\n        if PFVClient.thread is None or not PFVClient.thread.is_alive():\n            PFVClient.thread = threading.Thread(\n                    target=tool.launch_experiments, args=([[user_data[\"implementation\"]]])\n                )\n            # PFVClient.thread.daemon = True\n            PFVClient.thread.start()\n            PFVClient.app.logger.info(\"Thread started\")\n            # Wait for the thread to complete\n            if PFVClient.thread is not None:\n                PFVClient.thread.join()\n                PFVClient.app.logger.info(\"Thread finished\")\n                PFVClient.thread = None\n        else:\n            PFVClient.app.logger.info(\"Thread already running\")\n\n    @app.route(\"/get-protocols\", methods=[\"GET\"])\n    def get_protocols():\n        return jsonify(PROTOCOLS)\n\n\n    @app.route(\"/stop-client\", methods=[\"GET\"])\n    def stop_client(): \n        # TODO: hack because connection aborted i dont know why\n        sys.exit(0)\n\n    @app.after_request\n    def add_header(r):\n\"\"\"\n        It sets the cache control headers to prevent caching\n\n        :param r: The response object\n        :return: the response object with the headers added.\n        \"\"\"\n        r.headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\"\n        r.headers[\"Pragma\"] = \"no-cache\"\n        r.headers[\"Expires\"] = \"0\"\n        r.headers[\"Cache-Control\"] = \"public, max-age=0\"\n        return r\n\n    def run(self):\n        PFVClient.app.run(host=\"0.0.0.0\", port=80, use_reloader=True)\n</code></pre>"},{"location":"reference/panther/panther_worker/app/panther_client.html#panther.panther_worker.app.panther_client.PFVClient.add_header","title":"<code>add_header(r)</code>","text":"<p>It sets the cache control headers to prevent caching</p> <p>:param r: The response object :return: the response object with the headers added.</p> Source code in <code>panther/panther_worker/app/panther_client.py</code> <pre><code>@app.after_request\ndef add_header(r):\n\"\"\"\n    It sets the cache control headers to prevent caching\n\n    :param r: The response object\n    :return: the response object with the headers added.\n    \"\"\"\n    r.headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\"\n    r.headers[\"Pragma\"] = \"no-cache\"\n    r.headers[\"Expires\"] = \"0\"\n    r.headers[\"Cache-Control\"] = \"public, max-age=0\"\n    return r\n</code></pre>"},{"location":"reference/panther/panther_worker/app/argument_parser/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/argument_parser/ArgumentParserRunner.html","title":"ArgumentParserRunner","text":""},{"location":"reference/panther/panther_worker/app/logger/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/logger/CustomFormatter.html","title":"CustomFormatter","text":""},{"location":"reference/panther/panther_worker/app/panther_config/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/panther_config/panther_config.html","title":"Panther config","text":""},{"location":"reference/panther/panther_worker/app/panther_runner/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/panther_runner/panther_apt_runner.html","title":"Panther apt runner","text":""},{"location":"reference/panther/panther_worker/app/panther_runner/panther_minip_runner.html","title":"Panther minip runner","text":""},{"location":"reference/panther/panther_worker/app/panther_runner/panther_quic_runner.html","title":"Panther quic runner","text":""},{"location":"reference/panther/panther_worker/app/panther_runner/panther_runner.html","title":"Panther runner","text":""},{"location":"reference/panther/panther_worker/app/panther_runner/panther_runner.html#panther.panther_worker.app.panther_runner.panther_runner.Runner","title":"<code>Runner</code>","text":"Source code in <code>panther/panther_worker/app/panther_runner/panther_runner.py</code> <pre><code>class Runner:\n    def __init__(\n        self, config, protocol_config, current_protocol, implems, executed_test=[]\n    ):\n        # Setup logger\n        self.log = logging.getLogger(\"panther-runner\")\n        self.log.setLevel(logging.INFO)\n        # if (self.log.hasHandlers()):\n        #     self.log.handlers.clear()\n        self.log.addHandler(ch)\n        self.log.propagate = False\n\n        # Setup configuration\n        self.log.info(\"START SETUP CONFIGURATION\")\n        self.current_protocol = current_protocol\n        self.config = config\n        self.log.info(\"SELECTED PROTOCOL: \" + self.current_protocol)\n        self.protocol_conf = protocol_config\n        self.log.info(\"END SETUP PROTOCOL PARAMETERS\")\n\n        # TODO refactor\n        self.iters = self.config[\"global_parameters\"].getint(\n            \"iter\"\n        )  # Number of iteration per test           # TODO enforce in this file\n        self.test_pattern = \"*\"  # Test to launch regex, * match all test # TODO\n\n        self.extra_args = []  # TODO\n        self.executed_tests = executed_test\n        self.nb_test_to_execute = 0\n        for mode in self.executed_tests.keys():\n            self.nb_test_to_execute += len(self.executed_tests[mode])\n        self.current_executed_test_count = 0\n\n        self.implems = implems\n\n        self.webapp_ip = socket.gethostbyname(\"panther-webapp\")\n        print(self.webapp_ip)\n        print(self.nb_test_to_execute)\n        print(self.nb_test_to_execute * self.config[\"global_parameters\"].getint(\"iter\"))\n        # TODO make less general\n        if (\n            \"quic_server_test_0rtt\" in executed_test\n            or \"quic_client_test_0rtt\" in executed_test\n        ):\n            self.bar_total_test = progressbar.ProgressBar(\n                max_value=(self.nb_test_to_execute + 2)\n                * self.config[\"global_parameters\"].getint(\"iter\")\n            )\n        else:\n            self.bar_total_test = progressbar.ProgressBar(\n                max_value=self.nb_test_to_execute\n                * self.config[\"global_parameters\"].getint(\"iter\")\n            )\n\n    def save_shadow_binaries(self, implem, test, run_id):\n\"\"\"\n        Save shadow binaries for the given implementation and test.\n\n        Parameters:\n        implem (str): Implementation name.\n        test (object): Test object containing test details.\n        run_id (int): Unique run identifier.\n        \"\"\"\n        if not self.config[\"net_parameters\"].getboolean(\"shadow\"):\n            return\n\n        self.log.info(\"Save shadow binaries:\")\n\n        try:\n            binary_path, binary_name = self.get_binary_details(implem, test.mode)\n            self.copy_file(binary_path, os.path.join(self.config[\"global_parameters\"][\"dir\"], str(run_id), binary_name))\n\n            test_path = os.path.join(self.config[\"global_parameters\"][\"build_dir\"], test.name)\n            dest_test_path = os.path.join(self.config[\"global_parameters\"][\"dir\"], str(run_id), test.name)\n            self.copy_file(test_path, dest_test_path)\n\n        except Exception as e:\n            self.log.error(f\"Failed to save shadow binaries: {e}\")\n\n    def get_binary_details(self, implem, mode):\n\"\"\"\n        Get binary path and name for the given implementation and mode.\n\n        Parameters:\n        implem (str): Implementation name.\n        mode (str): Mode of the test (client/server).\n\n        Returns:\n        tuple: (binary_path, binary_name)\n        \"\"\"\n        index = 0 if mode == \"client\" else 1\n        binary_dir = self.implems[implem][index][implem][\"binary-dir\"]\n        binary_name = self.implems[implem][index][implem][\"binary-name\"]\n\n        binary_path = (\n            binary_dir.replace(\"$IMPLEM_DIR\", IMPLEM_DIR.replace(\"$PROT\", self.current_protocol))\n            .replace(\"$MODEL_DIR\", MODEL_DIR)\n            + \"/\"\n            + binary_name.replace(\"$IMPLEM_DIR\", IMPLEM_DIR.replace(\"$PROT\", self.current_protocol))\n            .replace(\"$MODEL_DIR\", MODEL_DIR)\n            .split(\" \")[-1]\n        )\n\n        binary_name = binary_name.split(\"/\")[-1].split(\" \")[-1]\n        return binary_path, binary_name\n\n    def copy_file(self, src, dst):\n\"\"\"\n        Copy a file from source to destination.\n\n        Parameters:\n        src (str): Source file path.\n        dst (str): Destination file path.\n        \"\"\"\n        self.log.info(f\"Copy file: {src} to {dst}\")\n        shutil.copyfile(src, dst)\n\n    # Return dictionnary of paths according to possible location\n    # TODO make more robust\n    def get_implementation_dir(self, implem):\n        return self.implems[implem][0][implem][\"binary-dir\"].replace(\n            \"$IMPLEM_DIR\", IMPLEM_DIR.replace(\"$PROT\", self.current_protocol)\n        ), self.implems[implem][1][implem][\"binary-dir\"].replace(\n            \"$IMPLEM_DIR\", IMPLEM_DIR.replace(\"$PROT\", self.current_protocol)\n        )\n\n    def record_pcap(self, pcap_name):\n        self.log.info(\"Start thsark\")\n        # time.sleep(10) # for server test\n        # TODO kill entual old quic implem\n        if self.config[\"net_parameters\"].getboolean(\"vnet\"):\n            interface = \"lo\"\n            p = subprocess.Popen(\n                [\n                    \"ip\",\n                    \"netns\",\n                    \"exec\",\n                    \"ivy\",\n                    \"tshark\",\n                    \"-w\",\n                    pcap_name,\n                    \"-i\",\n                    interface,\n                    \"-f\",\n                    self.protocol_conf[self.current_protocol + \"_parameters\"][\n                        \"protocol\"\n                    ],\n                ],\n                stdout=sys.stdout,\n            )\n            p = subprocess.Popen(\n                [\n                    \"ip\",\n                    \"netns\",\n                    \"exec\",\n                    \"implem\",\n                    \"tshark\",\n                    \"-w\",\n                    pcap_name.replace(\"ivy_lo_\", \"implem_lo_\"),\n                    \"-i\",\n                    interface,\n                    \"-f\",\n                    self.protocol_conf[self.current_protocol + \"_parameters\"][\n                        \"protocol\"\n                    ],\n                ],\n                stdout=sys.stdout,\n            )\n            interface = \"ivy\"\n            p = subprocess.Popen(\n                [\n                    \"ip\",\n                    \"netns\",\n                    \"exec\",\n                    \"ivy\",\n                    \"tshark\",\n                    \"-w\",\n                    pcap_name.replace(\"ivy_lo_\", \"ivy_ivy_\"),\n                    \"-i\",\n                    interface,\n                    \"-f\",\n                    self.protocol_conf[self.current_protocol + \"_parameters\"][\n                        \"protocol\"\n                    ],\n                ],\n                stdout=sys.stdout,\n            )\n            interface = \"implem\"\n            p = subprocess.Popen(\n                [\n                    \"ip\",\n                    \"netns\",\n                    \"exec\",\n                    \"implem\",\n                    \"tshark\",\n                    \"-w\",\n                    pcap_name.replace(\"ivy_lo_\", \"implem_\"),\n                    \"-i\",\n                    interface,\n                    \"-f\",\n                    self.protocol_conf[self.current_protocol + \"_parameters\"][\n                        \"protocol\"\n                    ],\n                ],\n                stdout=sys.stdout,\n            )\n        elif self.config[\"net_parameters\"].getboolean(\"shadow\"):\n            p = None\n        else:\n            interface = \"lo\"\n            p = subprocess.Popen(\n                [\n                    \"sudo\",\n                    \"tshark\",\n                    \"-w\",\n                    pcap_name,\n                    \"-i\",\n                    interface,\n                    \"-f\",\n                    self.protocol_conf[self.current_protocol + \"_parameters\"][\n                        \"protocol\"\n                    ],\n                ],\n                stdout=sys.stdout,\n            )\n        time.sleep(3)  # TODO\n        return p\n\n    def config_pcap(self, ivy_dir, implem, test):\n        if self.config[\"net_parameters\"].getboolean(\"vnet\"):\n            pcap_name = (\n                ivy_dir + \"/ivy_lo_\" + implem + \"_\" + test.replace(\".ivy\", \"\") + \".pcap\"\n            )\n            open(pcap_name, mode=\"w\").close()\n            subprocess.Popen(\n                \"sudo /bin/chmod o=xw \" + pcap_name, shell=True, executable=\"/bin/bash\"\n            ).wait()\n            open(pcap_name.replace(\"ivy_lo_\", \"ivy_ivy_\"), mode=\"w\").close()\n            open(pcap_name.replace(\"ivy_lo_\", \"implem_lo_\"), mode=\"w\").close()\n            subprocess.Popen(\n                \"sudo /bin/chmod o=xw \" + pcap_name.replace(\"ivy_lo_\", \"ivy_ivy_\"),\n                shell=True,\n                executable=\"/bin/bash\",\n            ).wait()\n            subprocess.Popen(\n                \"sudo /bin/chmod o=xw \" + pcap_name.replace(\"ivy_lo_\", \"implem_lo_\"),\n                shell=True,\n                executable=\"/bin/bash\",\n            ).wait()\n            open(pcap_name.replace(\"ivy_lo_\", \"implem_\"), mode=\"w\").close()\n            subprocess.Popen(\n                \"sudo /bin/chmod o=xw \" + pcap_name.replace(\"ivy_lo_\", \"implem_\"),\n                shell=True,\n                executable=\"/bin/bash\",\n            ).wait()\n        else:\n            pcap_name = ivy_dir + \"/\" + implem + \"_\" + test + \".pcap\"\n            open(pcap_name, mode=\"w\").close()\n            subprocess.Popen(\n                \"sudo /bin/chmod o=xw \" + pcap_name, shell=True, executable=\"/bin/bash\"\n            ).wait()\n        return pcap_name\n\n    def create_exp_folder(self):\n        folders = [\n            os.path.join(self.config[\"global_parameters\"][\"dir\"], f)\n            for f in os.listdir(self.config[\"global_parameters\"][\"dir\"])\n            if os.path.isdir(os.path.join(self.config[\"global_parameters\"][\"dir\"], f))\n        ]\n        pcap_i = len(folders) + 1\n        self.log.info(pcap_i)\n        ivy_dir = os.path.join(self.config[\"global_parameters\"][\"dir\"], str(pcap_i))\n        os.mkdir(ivy_dir)\n        return ivy_dir, pcap_i\n\n    def setup_exp(self, implem):\n        if self.config[\"global_parameters\"][\"dir\"] is None:\n            self.log.info(\"ERROR\")\n            exit(0)\n\n        # test, run_id, pcap_name,iteration,j\n        # Put an array of eventual extra argument for the test (TODO)\n        # self.extra_args = [opt_name+'='+opt_val for opt_name,opt_val in self.ivy_options.items() if opt_val is not None]\n        self.log.info(\"Get implementation directory:\")\n        implem_dir_server, implem_dir_client = self.get_implementation_dir(implem)\n\n        self.log.info(\"Server implementation directory: {}\".format(implem_dir_server))\n        self.log.info(\"Client implementation directory: {}\".format(implem_dir_client))\n        return implem_dir_server, implem_dir_client\n\n    def get_exp_stats(self, implem, test, run_id, pcap_name, i):\n        raise NotImplementedError\n\n    def save_shadow_res(self, test, i, pcap_name, run_id):\n        if self.config[\"net_parameters\"].getboolean(\"shadow\"):\n            self.log.info(\"Save shadow res:\")\n            shadow_data_src = \"/app/shadow.data\"\n            shadow_data_dst = os.path.join(self.config[\"global_parameters\"][\"dir\"], str(run_id), \"shadow.data\")\n            self.log.info(f\"Copying entire folder: {shadow_data_src} to {shadow_data_dst}\")\n            shutil.copytree(shadow_data_src, shadow_data_dst)\n            shutil.copyfile(\"/app/shadow.log\", os.path.join(self.config[\"global_parameters\"][\"dir\"], str(run_id), \"shadow.log\"))\n            shutil.rmtree(shadow_data_src)\n            os.remove(\"/app/shadow.log\")\n            shadow_data_dir = os.path.join(self.config[\"global_parameters\"][\"dir\"], str(run_id), \"shadow.data\")\n            host_dirs = {\n                \"client\": os.path.join(shadow_data_dir, \"hosts/client\"),\n                \"server\": os.path.join(shadow_data_dir, \"hosts/server\"),\n            }\n            dest_dir = os.path.join(self.config[\"global_parameters\"][\"dir\"], str(run_id))\n\n            if \"client\" in test.mode:\n                patterns = [\n                    (\"client\", \"*.stdout\", test.name + str(i) + \".out\"),\n                    (\"client\", \"*.stderr\", test.name + str(i) + \".err\"),\n                    (\"server\", \"*.stdout\", test.name + str(i) + \".iev\"),\n                    (\"server\", \"*.stderr\", \"ivy_stderr.txt\"),\n                ]\n            else:\n                 patterns = [\n                    (\"server\", \"*.stdout\", test.name + str(i) + \".out\"),\n                    (\"server\", \"*.stderr\", test.name + str(i) + \".err\"),\n                    (\"client\", \"*.stdout\", test.name + str(i) + \".iev\"),\n                    (\"client\", \"*.stderr\", \"ivy_stderr.txt\"),\n                ]\n\n            for mode, pattern, dest_filename in patterns:\n                self.log.info(f\"Matching pattern {pattern} in {host_dirs[mode]}\")\n                for file_path in glob.glob(os.path.join(host_dirs[mode], pattern)):\n                    self.log.info(f\"Copy {file_path} to {os.path.join(dest_dir, dest_filename)}\")\n                    shutil.copy(file_path, os.path.join(dest_dir, dest_filename))\n\n            if \"client\" in test.mode:\n                self.log.info(f\"Copy eth0.pcap to {pcap_name}\")\n                shutil.copy(os.path.join(shadow_data_dir, \"hosts/server/eth0.pcap\"), pcap_name)\n            elif \"server\" in test.mode:\n                self.log.info(f\"Copy eth0.pcap to {pcap_name}\")\n                shutil.copy(os.path.join(shadow_data_dir, \"hosts/client/eth0.pcap\"), pcap_name)\n\n    def run_exp(self, implem):\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/panther/panther_worker/app/panther_runner/panther_runner.html#panther.panther_worker.app.panther_runner.panther_runner.Runner.copy_file","title":"<code>copy_file(src, dst)</code>","text":"<p>Copy a file from source to destination.</p> <p>Parameters: src (str): Source file path. dst (str): Destination file path.</p> Source code in <code>panther/panther_worker/app/panther_runner/panther_runner.py</code> <pre><code>def copy_file(self, src, dst):\n\"\"\"\n    Copy a file from source to destination.\n\n    Parameters:\n    src (str): Source file path.\n    dst (str): Destination file path.\n    \"\"\"\n    self.log.info(f\"Copy file: {src} to {dst}\")\n    shutil.copyfile(src, dst)\n</code></pre>"},{"location":"reference/panther/panther_worker/app/panther_runner/panther_runner.html#panther.panther_worker.app.panther_runner.panther_runner.Runner.get_binary_details","title":"<code>get_binary_details(implem, mode)</code>","text":"<p>Get binary path and name for the given implementation and mode.</p> <p>Parameters: implem (str): Implementation name. mode (str): Mode of the test (client/server).</p> <p>Returns: tuple: (binary_path, binary_name)</p> Source code in <code>panther/panther_worker/app/panther_runner/panther_runner.py</code> <pre><code>def get_binary_details(self, implem, mode):\n\"\"\"\n    Get binary path and name for the given implementation and mode.\n\n    Parameters:\n    implem (str): Implementation name.\n    mode (str): Mode of the test (client/server).\n\n    Returns:\n    tuple: (binary_path, binary_name)\n    \"\"\"\n    index = 0 if mode == \"client\" else 1\n    binary_dir = self.implems[implem][index][implem][\"binary-dir\"]\n    binary_name = self.implems[implem][index][implem][\"binary-name\"]\n\n    binary_path = (\n        binary_dir.replace(\"$IMPLEM_DIR\", IMPLEM_DIR.replace(\"$PROT\", self.current_protocol))\n        .replace(\"$MODEL_DIR\", MODEL_DIR)\n        + \"/\"\n        + binary_name.replace(\"$IMPLEM_DIR\", IMPLEM_DIR.replace(\"$PROT\", self.current_protocol))\n        .replace(\"$MODEL_DIR\", MODEL_DIR)\n        .split(\" \")[-1]\n    )\n\n    binary_name = binary_name.split(\"/\")[-1].split(\" \")[-1]\n    return binary_path, binary_name\n</code></pre>"},{"location":"reference/panther/panther_worker/app/panther_runner/panther_runner.html#panther.panther_worker.app.panther_runner.panther_runner.Runner.save_shadow_binaries","title":"<code>save_shadow_binaries(implem, test, run_id)</code>","text":"<p>Save shadow binaries for the given implementation and test.</p> <p>Parameters: implem (str): Implementation name. test (object): Test object containing test details. run_id (int): Unique run identifier.</p> Source code in <code>panther/panther_worker/app/panther_runner/panther_runner.py</code> <pre><code>def save_shadow_binaries(self, implem, test, run_id):\n\"\"\"\n    Save shadow binaries for the given implementation and test.\n\n    Parameters:\n    implem (str): Implementation name.\n    test (object): Test object containing test details.\n    run_id (int): Unique run identifier.\n    \"\"\"\n    if not self.config[\"net_parameters\"].getboolean(\"shadow\"):\n        return\n\n    self.log.info(\"Save shadow binaries:\")\n\n    try:\n        binary_path, binary_name = self.get_binary_details(implem, test.mode)\n        self.copy_file(binary_path, os.path.join(self.config[\"global_parameters\"][\"dir\"], str(run_id), binary_name))\n\n        test_path = os.path.join(self.config[\"global_parameters\"][\"build_dir\"], test.name)\n        dest_test_path = os.path.join(self.config[\"global_parameters\"][\"dir\"], str(run_id), test.name)\n        self.copy_file(test_path, dest_test_path)\n\n    except Exception as e:\n        self.log.error(f\"Failed to save shadow binaries: {e}\")\n</code></pre>"},{"location":"reference/panther/panther_worker/app/panther_stats/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/panther_stats/panther_apt_stats.html","title":"Panther apt stats","text":""},{"location":"reference/panther/panther_worker/app/panther_stats/panther_minip_stats.html","title":"Panther minip stats","text":""},{"location":"reference/panther/panther_worker/app/panther_stats/panther_quic_stats.html","title":"Panther quic stats","text":""},{"location":"reference/panther/panther_worker/app/panther_tester/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/panther_tester/panther_apt_tester.html","title":"Panther apt tester","text":""},{"location":"reference/panther/panther_worker/app/panther_tester/panther_minip_tester.html","title":"Panther minip tester","text":""},{"location":"reference/panther/panther_worker/app/panther_tester/panther_quic_tester.html","title":"Panther quic tester","text":""},{"location":"reference/panther/panther_worker/app/panther_tester/panther_tester.html","title":"Panther tester","text":""},{"location":"reference/panther/panther_worker/app/panther_utils/index.html","title":"Index","text":""},{"location":"reference/panther/panther_worker/app/panther_utils/panther_constant.html","title":"Panther constant","text":""}]}