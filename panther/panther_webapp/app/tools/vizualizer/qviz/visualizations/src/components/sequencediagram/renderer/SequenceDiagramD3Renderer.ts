import QlogConnection from '@/data/Connection';
import * as d3 from 'd3';
import * as qlog from '@/data/QlogSchema';
import SequenceDiagramConfig, { SequenceDiagramConnection } from '../data/SequenceDiagramConfig';
import { VantagePointType, IEventConnectionStateUpdated, QUICFrameTypeName } from '@/data/QlogSchema';
import { IQlogRawEvent, IQlogEventParser, TimeTrackingMethod } from '@/data/QlogEventParser';

interface VerticalRange {
    svgGroup:HTMLOrSVGElement | undefined,
    rendered: boolean,
    yMin: number
};

interface ExtentInfo {
    rangeIndex: number,
    start: number,
    stop: number
};


interface CoordinateTracker {
    timestamp: number,
    y: number
}

interface Interval {
    yMin: number,
    yMax: number,
    timeSkipped: number
}

export interface EventPointer {
    connectionIndex: number,
    eventIndex?: number,
    packetNumber?: number
};

enum arrowTargetProperty {
    left = "leftTarget",
    right = "rightTarget",
    lost = "packetLost",
};


export class SequenceDiagramD3Renderer {

    public containerID:string;
    public svgID:string;
    public rendering:boolean = false;

    private svg!:d3.Selection<d3.BaseType, unknown, HTMLElement, any>;

    private selectedTraces!:Array<SequenceDiagramConnection>; // traces we get from our parent originally, e.g., used for coupling with Vue
    private traces!:Array<SequenceDiagramConnection>; // traces we actually work on, e.g., filtered, added with custom generated traces, etc.

    private scrollHandler:((e:any) => void) | undefined = undefined;

    private absoluteAggregatedStartTime!:number;
    private renderedRanges!:Array<VerticalRange>;
    private rangeHeight!:number;
    private shortenedIntervals:Array<Interval> = new Array<Interval>();

    private timeResolution = 1;

    private dimensions:any = {};
    
    private bandWidth:number = 0; // width of an individual vertical trace timeline on screen

    private frameTypeToColorLUT:Map<string, Array<string>> = new Map<string, Array<string>>();

    private onEventClicked: (rawEvt: any, connection:QlogConnection, focusInfo:EventPointer) => void;

    private ignoreEventName = "ignoreseq"; // needs to be lowercase!!

    constructor(containerID:string, svgID:string, onEventClicked: (packet: any, extra: any) => void) {
        this.containerID = containerID;
        this.svgID = svgID;

        this.onEventClicked = (rawEvt:any, connection:QlogConnection, focusInfo:EventPointer ) => { 

            const allEvents = connection.getEvents();
            let evt:IQlogEventParser|undefined = connection.parseEvent( rawEvt );

            if ( connection.wasAutoGenerated &&
                 evt.name === qlog.TransportEventType.packet_sent || 
                 evt.name === qlog.TransportEventType.packet_received ) {
                
                    // clicked event was auto-generated (happens if user uploaded a server-side trace, since we default to the client-side trace to show the popup)
                    // so we want to show the accompanying event on the other trace instead (which is the non-auto-generated one)

                    let currentMetadata = (rawEvt as any).qvis;
                    if ( currentMetadata ) {
                        currentMetadata = currentMetadata.sequencediagram;

                        if ( currentMetadata ) {
                            const otherSide = currentMetadata[ arrowTargetProperty.right ]; // assume client is always on the left
                            if ( otherSide ) {
                                console.log("SequenceDiagramD3Renderer:onEventClicked : switched event from auto-generated to original", rawEvt, otherSide);
                                rawEvt = otherSide;
                            }
                        }
                    }
            }

            const metrics:Map<string, any> = new Map<string, any>();

            if ( focusInfo ) {
                this.createPrivateNamespace( rawEvt );
                (rawEvt as any).qvis.sequencediagram.focusInfo = focusInfo;
            }
            
            if ( evt.name === qlog.RecoveryEventType.metrics_updated ) {
                // if we have metrics updated, we want to be able to show the state of -all- recovery metrics at that time, not just the updated ones
                // for this, we start from the start of the events and aggregate all into a dictionary of values to show them 
                evt = undefined; // to make sure we're not tempted to re-use this here, as we shouldn't, because of how .parseEvent() works

                for ( const candidateRaw of allEvents ) {

                    const candidate = connection.parseEvent( candidateRaw );

                    if ( candidate.name === qlog.RecoveryEventType.metrics_updated ) {
                        for ( const metricName of Object.keys(candidate.data) ) {
                            metrics.set( metricName, candidate.data[metricName] );
                        }
                    }

                    if ( candidateRaw === rawEvt ) {
                        break; // don't want to go further than the current metrics_updated
                    }
                }

                onEventClicked( rawEvt, Object.fromEntries( metrics ) );
            }
            else {
                onEventClicked(rawEvt, undefined);
            }
        }
    }

    public getTraces():Array<SequenceDiagramConnection> {
        return this.traces;
    }
   
    public async render(traces:Array<SequenceDiagramConnection>, timeResolution:number, focusOn:EventPointer|null = null ):Promise<boolean> {
        if ( this.rendering ) {
            return false;
        }

        console.log("SequenceDiagramD3Renderer:render", traces.length, traces);

        this.timeResolution = timeResolution;
        this.selectedTraces = traces;
        this.rendering = true;

        // To make things performant enough, we don't render the full diagram at once
        // We always render just parts of it at the same time
        // this.setup prepares everything, calculates coordinates and relations between events etc.
        // this.renderPartialExtents can then be called on scroll updates. It figures out which part of the SVG is visible and makes sure that part of the diagram is drawn.
        const canContinue:boolean = this.setup(traces);

        if ( !canContinue ) {
            this.rendering = false;

            return false;
        }

        await this.renderPartialExtents( focusOn );
        this.rendering = false;

        return true;
    }

    // runs once before each render. Used to bootstrap everything.
    protected setup(tracesInput:Array<SequenceDiagramConnection>):boolean {

        // 0. make sure the containers exist
        // 1. make sure we have at least 2 traces to draw (sequence diagram doesn't make much sense with just one)
        // 2. calculate the y coordinates for each event on the timelines. This can be done once and stored for future use
        // 3. setup the SVG container and draw things like timelines
        // 4. prepare data structures to keep scrolling state (what we've drawn already and what not yet)
        // 5. setup event listeners so we can update the rendering when needed

        // 0.
        if ( document.getElementById(this.containerID) === undefined ){
            console.error("SequenceDiagramD3Renderer:setup : container element not found, cannot render!", this.containerID);

            return false;
        }

        if ( document.getElementById(this.svgID) === undefined ){
            console.error("SequenceDiagramD3Renderer:setup : svg element not found, cannot render!", this.svgID);

            return false;
        }

        // 1.
        this.traces = new Array<SequenceDiagramConnection>();
        // new array, because a) we might want to add a trace if there's only 1 and b) we might have invalid traces in there
        for (const trace of tracesInput) {
            if ( trace.connection.getEvents().length > 0 ){
                this.traces.push( trace );
            }
        }

        if ( this.traces.length === 0 ){
            console.error("SequenceDiagramD3Renderer:setup : None of the selected traces have events in them, cannot render");

            return false;
        }

        // TODO: potentially do this outside? In SequenceDiagramRenderer? or maybe ConnectionConfigurator itself?
        const timeBeforeCloning:number = performance.now();
        this.ensureMoreThanOneTrace();

        for ( const trace of this.traces ){
            trace.connection.setupLookupTable();
        }

        // 2. 
        this.dimensions = {
            margin: {
                top: 60,
                bottom: 100,
                left: 0,
                right: 0,
            },
            width: 0, // total width, including margins
            height: 0, // total height, including margin.top and margin.bottom

            pixelsPerMillisecond: 20,
            shortenIntervalsLongerThan: 120,
        };

        this.calculateTimeOffsets( this.traces );
        this.dimensions.height = this.calculateCoordinates( this.traces );
        this.calculateConnections();

        // TODO: verify traces are left-to-right : i.e., arrows do not go UP!

        // 3. 
        const container:HTMLElement = document.getElementById(this.containerID)!;

        this.svg = d3.select("body").select( "#" + this.svgID );
        this.svg.selectAll("*").remove();
       
        this.svg.attr("height", this.dimensions.height);
        // this is impacted by whether we have scrollbars or not, so we set height first before fetching this
        this.dimensions.width = container.clientWidth;
        this.svg.attr("width", this.dimensions.width);
        this.svg.attr("viewbox", `0 0 ${this.dimensions.width} ${this.dimensions.height}`);
        
        // draw the vertical timelines 
        // we have multiple timelines next to each other in horizontal "bands"
        this.bandWidth = (this.dimensions.width / this.traces.length);
        for ( let i = 0; i < this.traces.length; ++i ){
            const currentX =  this.bandWidth * i + (this.bandWidth * 0.5); // get center of the band
            const trace = this.traces[i].connection;

            this.svg.append('rect').attr("x", currentX - 1).attr("y", this.dimensions.margin.top).attr("width", 2).attr("height", this.dimensions.height).attr("fill", "black");


            let text = undefined;
            if ( !trace.wasAutoGenerated && trace.parent.URL ) {

                const link = document.createElementNS("http://www.w3.org/2000/svg", "a");
                // link.setAttribute('x', "" + currentX);
                // link.setAttribute('y', "" + 20);
                link.setAttribute("href", "" + trace.parent.URL);
                link.setAttribute("target", "_blank");
                link.style.textDecoration = "underline";
    
                (this.svg.node()! as HTMLElement).appendChild( link );
    
                
                text = document.createElementNS("http://www.w3.org/2000/svg", "text");
                text.setAttribute('x', "" + currentX);
                text.setAttribute('y', "" + 20);
                text.setAttribute('dominant-baseline', "middle");
                text.setAttribute('text-anchor', "middle");
                text.textContent = "" + trace.parent.URLshort;
                link.appendChild( text );
            }
            else {
                text = document.createElementNS("http://www.w3.org/2000/svg", "text");
                text.setAttribute('x', "" + currentX);
                text.setAttribute('y', "" + 20);
                text.setAttribute('dominant-baseline', "middle");
                text.setAttribute('text-anchor', "middle");
                text.textContent = "" + ((trace.wasAutoGenerated) ?  "GENERATED: " : "" ) + trace.parent.filename;
                (this.svg.node()! as HTMLElement).appendChild( text );
            }


            // (this.svg.node()! as HTMLElement).appendChild( text );
            


            let vantagePoint:VantagePointType | string = trace.vantagePoint.type;
            if ( vantagePoint === qlog.VantagePointType.network ){
                vantagePoint = "" + vantagePoint + " : from " + trace.vantagePoint.flow + "'s viewpoint";
            }

            text = document.createElementNS("http://www.w3.org/2000/svg", "text");
            text.setAttribute('x', "" + currentX);
            text.setAttribute('y', "" + 40);
            text.setAttribute('dominant-baseline', "middle");
            text.setAttribute('text-anchor', "middle");
            text.textContent = "" + vantagePoint;
            (this.svg.node()! as HTMLElement).appendChild( text );
        }

        for ( const interval of this.shortenedIntervals ){
            for ( let i = 0; i < this.traces.length; ++i ){
                let currentX =  this.bandWidth * i + (this.bandWidth * 0.5); // get center of the band
    
                // the outside of the trace
                // dashed array doesn't have a background color, so make sure we draw it ourselves
                this.svg.append('line') .attr("x1", currentX).attr("x2", currentX)
                                        .attr("y1", interval.yMin + this.dimensions.pixelsPerMillisecond).attr("y2", interval.yMax - this.dimensions.pixelsPerMillisecond)
                                        .attr("stroke", "white").attr("stroke-width", 4);
                this.svg.append('line') .attr("x1", currentX).attr("x2", currentX)
                                        .attr("y1", interval.yMin + this.dimensions.pixelsPerMillisecond).attr("y2", interval.yMax - this.dimensions.pixelsPerMillisecond)
                                        .attr("stroke", "black").attr("stroke-width", 4).attr("stroke-dasharray", 4);

                // in between the two traces
                if ( i !== this.traces.length - 1) {
                    currentX = this.bandWidth * (i + 1);
                    this.svg.append('line') .attr("x1", currentX).attr("x2", currentX)
                                            .attr("y1", interval.yMin + this.dimensions.pixelsPerMillisecond).attr("y2", interval.yMax - this.dimensions.pixelsPerMillisecond)
                                            .attr("stroke", "white").attr("stroke-width", 4);
                    this.svg.append('line') .attr("x1", currentX).attr("x2", currentX)
                                            .attr("y1", interval.yMin + this.dimensions.pixelsPerMillisecond).attr("y2", interval.yMax - this.dimensions.pixelsPerMillisecond)
                                            .attr("stroke", "black").attr("stroke-width", 4).attr("stroke-dasharray", 4);

                    
                    const text = document.createElementNS("http://www.w3.org/2000/svg", "text");
                    text.setAttribute('class', "timestamp");
                    text.setAttribute('x', "" + (currentX + (this.dimensions.pixelsPerMillisecond) ));
                    text.setAttribute('y', "" + (interval.yMin + (interval.yMax - interval.yMin) / 2));
                    text.setAttribute('dominant-baseline', "middle");
                    text.textContent = `${(interval.timeSkipped / this.timeResolution).toFixed(2)}ms of inactivity`;
                    (this.svg.node()! as HTMLElement).appendChild( text );   
                }                                     

            }
        }

        // 4.

        // we want to keep track of which areas of the SVG we've drawn already (since we don't want to draw all at once and want to clear some afterwards)
        // we divide the entire SVG in vertical "ranges" that are 1 screen height large, then for example make sure there are always at least 3 or 4 of them drawn
        // In the scroll handler, we can use the rangeHeight to determine which of the ranges is currently "in view"
        // Here, we just prepare the range structs for later use
        this.rangeHeight = screen.height;
        this.renderedRanges = new Array<VerticalRange>();

        let currentRangeY = 0;
        let currentRangeIndex = 0;
        while ( currentRangeY < this.dimensions.height ){
            this.renderedRanges[currentRangeIndex] = {
                rendered: false,
                svgGroup: undefined,
                yMin: currentRangeY,
            }

            currentRangeY += this.rangeHeight;
            ++currentRangeIndex;
        }

        // 5.
        if ( this.scrollHandler !== undefined ){
            window.removeEventListener("scroll", this.scrollHandler);
            this.scrollHandler = undefined;
        }

        // scroll events are fired very quickly sometimes, don't want to try and render for each of them
        // we only fire on each 5th event but also add a timeout (typical "debounce"-alike) to make sure the final event gets used
        let scrollEventCount:number = 0;
        let scrollTimer:any | undefined = undefined;
        this.scrollHandler = (e) => {
           
           const execute = () => {
               scrollTimer = undefined;
               this.renderPartialExtents();
           };

           clearTimeout( scrollTimer );
           scrollTimer = setTimeout( execute, 250 ); // 250 ms

           ++scrollEventCount;
           if ( scrollEventCount % 5 === 0 ){ // 5 = magic number, from experimental experience in chrome, very scientific
               scrollEventCount = 0;
               clearTimeout( scrollTimer );
               execute();
           } 
       }

        window.addEventListener('scroll', this.scrollHandler);

        // TODO: also couple to window resize events? That should possibly trigger a full re-render, since the SVG can have changed width

        return true;
    }

    protected ensureMoreThanOneTrace() {

        if ( this.traces.length > 1 ){

            const originalCount = this.traces.length;

            // there can be several traces, but they might be the same, which we can't really handle
            // so: filter duplicates first
            this.traces = this.traces.filter((v,i) => this.traces.indexOf(v) === i); // keeps the first occurence, since indexOf always returns first index

            if ( this.traces.length !== originalCount ) {

                // Vue reactivity is a weird beast
                // setting this.selectedTraces = this.traces will NOT work, so we have to manually pop and push everything
                // TODO: simpler to just pass the config around... let's just do that, shall we? 
                while ( this.selectedTraces.length > 0 ) {
                    this.selectedTraces.pop();
                }

                for ( const trace of this.traces ){
                    this.selectedTraces.push( trace );
                }
                // this.selectedTraces = this.traces.slice(); // update selection UI
            }

            if ( this.traces.length  > 1 ) {
                return;
            }
        }

        // if ( this.traces[0].connection.parent.getConnections().length > 1 ){
        //     // traces.length is currently just 1, so we need see if we can add its next sibling automatically as trace here 
        //     const nextSibling = this.traces[0].connection.parent.getConnections()[1];

        //     // e.g., if we load a list of all tests for a single domain from quic-tracker, they will all have the client perspective and we want to generate servers for them
        //     if ( nextSibling.getVantagePointPerspective() !== this.traces[0].connection.getVantagePointPerspective() ){
        //         this.traces.push( SequenceDiagramConfig.createConnectionWithTimeoffset(nextSibling) );
        //         this.selectedTraces.push( SequenceDiagramConfig.createConnectionWithTimeoffset(nextSibling) );

        //         return;
        //     }
        // }

        console.log("Considering reusing a previously generated sibling", this.traces[0].connection);

        // at this point, there is only 1 trace in the list
        const originalTrace = this.traces[0].connection;

        // we've already generated a trace for this one, so re-use it (otherwise, we might end up creating it again, e.g., in a quic-tracker list use case)
        if ( (originalTrace as any).qvis && (originalTrace as any).qvis.sequencediagram.generatedSibling ) {

            const sibling = (originalTrace as any).qvis.sequencediagram.generatedSibling;

            this.traces.push( SequenceDiagramConfig.createConnectionWithTimeoffset(sibling) );
            this.selectedTraces.push( SequenceDiagramConfig.createConnectionWithTimeoffset(sibling) );

            return;
        }

        // we cannot just visualize a single trace on a sequence diagram...
        // so we copy the trace and pretend like the copy is one from the other side
        const newTrace = originalTrace.clone();
        newTrace.title = "Simulated, autogenerated trace : " + newTrace.title;
        newTrace.description = "Simulated, autogenerated trace : " + newTrace.description;
        newTrace.vantagePoint.name = "GENERATED";
        newTrace.wasAutoGenerated = true;

        // we have a single trace, we need to copy it so we can simulate client + server
        if ( originalTrace.vantagePoint.type === qlog.VantagePointType.server || 
             originalTrace.vantagePoint.flow === qlog.VantagePointType.server ){
            newTrace.vantagePoint.type = qlog.VantagePointType.client;
            newTrace.vantagePoint.flow = qlog.VantagePointType.unknown;
            this.traces.unshift( SequenceDiagramConfig.createConnectionWithTimeoffset(newTrace) );
        }
        else if ( originalTrace.vantagePoint.type === qlog.VantagePointType.client || 
                  originalTrace.vantagePoint.flow === qlog.VantagePointType.client ){
            newTrace.vantagePoint.type = qlog.VantagePointType.server;
            newTrace.vantagePoint.flow = qlog.VantagePointType.unknown;
            this.traces.push( SequenceDiagramConfig.createConnectionWithTimeoffset(newTrace) );
        }
        else { // the vantagepoint is unknown... 
            
            // it's either client or server
            // we will try to determine this based on heuristics: 
            // server should have an INITIAL packet_received with packet nr. 0 before a packet_sent, client vice versa

            // TODO: move this to the QlogLoader classes? or at least outside the renderer

            originalTrace.setupLookupTable();
            const sentEvents        = originalTrace.lookup( qlog.EventCategory.transport, qlog.TransportEventType.packet_sent );
            const receivedEvents    = originalTrace.lookup( qlog.EventCategory.transport, qlog.TransportEventType.packet_received );

            let firstInitialSent = undefined;
            let firstInitialReceived = undefined;
            for (const rawEvt of sentEvents){
                const evt = originalTrace.parseEvent(rawEvt);
                const data = evt.data as qlog.IEventPacket;

                if ( data.header && data.header.packet_type === qlog.PacketType.initial && 
                     ( "" + data.header.packet_number === "0" ) ) {
                        firstInitialSent = evt;
                        break;
                }
            }

            for (const rawEvt of receivedEvents){
                const evt = originalTrace.parseEvent(rawEvt);
                const data = evt.data as qlog.IEventPacket;
                
                if ( data.header && data.header.packet_type === qlog.PacketType.initial && 
                     ( "" + data.header.packet_number === "0" ) ) {
                        firstInitialReceived = evt;
                        break;
                }
            }

            let guessedPerspective = qlog.VantagePointType.server; // server is a logical default, probably more of those available
            if ( firstInitialSent && firstInitialReceived ) {
                if ( firstInitialSent.absoluteTime < firstInitialReceived.absoluteTime ){
                    guessedPerspective = qlog.VantagePointType.client;
                }
            }

            originalTrace.vantagePoint.name = "vantage point type was unknown, pretending it's " + guessedPerspective;

            newTrace.vantagePoint.type = (guessedPerspective === qlog.VantagePointType.client) ? qlog.VantagePointType.server : qlog.VantagePointType.client;
            newTrace.vantagePoint.name = "vantage point type was unknown, pretending it's " + newTrace.vantagePoint.type;
            newTrace.vantagePoint.flow = qlog.VantagePointType.unknown;

            if ( newTrace.vantagePoint.type === qlog.VantagePointType.server ) {
                this.traces.push( SequenceDiagramConfig.createConnectionWithTimeoffset(newTrace) );
            }
            else{
                this.traces.unshift( SequenceDiagramConfig.createConnectionWithTimeoffset(newTrace) );
            }
        }

        for ( const event of newTrace.getEvents() ){
            const parsedEvt = newTrace.parseEvent(event);
            const type = parsedEvt.name;
            if ( type === qlog.TransportEventType.packet_sent ){
                parsedEvt.name = qlog.TransportEventType.packet_received;
            }
            else if ( type === qlog.TransportEventType.packet_received ){
                parsedEvt.name = qlog.TransportEventType.packet_sent;
            } 
            else {
                // we cannot observe anything from the "other" side besides what we received, so dismantle all of those events
                parsedEvt.name = this.ignoreEventName;
            }
        }

        this.createPrivateNamespace(originalTrace);
        (originalTrace as any).qvis.sequencediagram.generatedSibling = newTrace;
        this.createPrivateNamespace(newTrace);
        (newTrace as any).qvis.sequencediagram.generatedSibling = originalTrace;

        // deal with weird Vue Reactivity, see above
        while ( this.selectedTraces.length > 0 ) {
            this.selectedTraces.pop();
        }
        for ( const trace of this.traces ){
            this.selectedTraces.push( trace );
        }
    }

    protected createPrivateNamespace(obj:any):void {
        if ( obj.qvis === undefined ) {
            Object.defineProperty(obj, "qvis", { enumerable: false, value: {} });
        }

        if ( obj.qvis.sequencediagram === undefined ) {
            obj.qvis.sequencediagram = {};
        }
    }

    protected calculateTimeOffsets(traces:Array<SequenceDiagramConnection>):void {

        // FIXME: add support for more than 2 traces!
        if ( traces.length > 2){
            console.warn("SequenceDiagramD3Renderer:calculateTimeOffsets : no time offsets auto-calculated for more than 2 traces. Use the UI to assign them manually if needed.");

            return;
        }

        // we might need to calculate custom time offsets in latency here
        // however, there are a couple early outs
        const clientConnection = traces[0];
        const serverConnection = traces[1];

        if ( serverConnection.connection.wasAutoGenerated || clientConnection.connection.wasAutoGenerated ){
            return;
        }

        // was already set manually in the qlog file, don't want to override that!
        if ( serverConnection.connection.getEventParser().timeOffset !== 0 ){
            return;
        }

        // was manually overridden while viewing this file
        if ( serverConnection.timeOffset ){
            // make sure that the manual value from the UI is also persisted
            this.createPrivateNamespace(serverConnection.connection);
            (serverConnection.connection as any).qvis.sequencediagram.manualTimeOffset = serverConnection.timeOffset ;

            return;
        }

        // was already calculated or manually overridden in a previous viewing of this file
        if ( (serverConnection.connection as any).qvis && 
             (serverConnection.connection as any).qvis.sequencediagram && 
             (serverConnection.connection as any).qvis.sequencediagram.manualTimeOffset !== undefined ) {

            serverConnection.timeOffset = (serverConnection.connection as any).qvis.sequencediagram.manualTimeOffset;

            return;
        }


        // if one of the traces has relative_time set, but didn't specify a reference_time, we set the reference_time to 0 (because... what else)
        // now, ref_time of 0 in epoch means 1970... so if we then loaded the opposite trace with correct timestamps... 
        // we'd have one end sending packets in 1970, the other in 2020. Highest measured latency yet!
        // So we check for that here and set the reference_time of the "incorrect" trace of the "correct" one
        if ( clientConnection.connection.getEventParser().getAbsoluteStartTime() === 0 && clientConnection.connection.getEventParser().getTimeTrackingMethod() === TimeTrackingMethod.RELATIVE_TIME ) {
            console.error("SequenceDiagramD3Renderer:calculateTimeOffsets : Client had no reference_time set, trying to fix by using the server-side reftime. HERE BE DRAGONS!");

            const refTime = serverConnection.connection.getEventParser().getAbsoluteStartTime();
            clientConnection.connection.getEventParser().setReferenceTime( refTime - 5 ); // -5 because the client should start earlier because it sends the initial
        }
        else if ( serverConnection.connection.getEventParser().getAbsoluteStartTime() === 0 && serverConnection.connection.getEventParser().getTimeTrackingMethod() === TimeTrackingMethod.RELATIVE_TIME ) {
            console.error("SequenceDiagramD3Renderer:calculateTimeOffsets : Server had no reference_time set, trying to fix by using the client-side reftime. HERE BE DRAGONS!");

            const refTime = clientConnection.connection.getEventParser().getAbsoluteStartTime();
            serverConnection.connection.getEventParser().setReferenceTime( refTime + 5 ); // +5 because the server should start later because it receives the client's initial
        }

        // So, concept: we have 1 trace from the client, 1 from the server
        // both run on different, non-synchronized clocks and were started at different moments in time, so even relative time with offset 0 is not the same time. 
        // the only thing we know, is that the client initiates the connection and needs to wait for an answer from the server to continue 
        // (because the client always initiates the QUIC connection)
        // as such, if we take the time between the client sending their INITIAL and receiving the first packet from the server,
        // assuming there was no weird loss or jitter, we have an initial RTT estimate.
        // However, some implementations might also log metric_update events, containing the rtt! so first look for those!
        let latencyOneWay = Number.MIN_SAFE_INTEGER;

        let smoothedBackup = 0; // only to be used if there are no actual latest_rtt's found (since smoothed isn't always correct from initial settingss)
        const clientMetricUpdates = clientConnection.connection.lookup( qlog.EventCategory.recovery, qlog.RecoveryEventType.metrics_updated );
        for ( const evt of clientMetricUpdates ){
            const update = clientConnection.connection.parseEvent(evt).data as qlog.IEventMetricsUpdated;
            if ( update.latest_rtt ){
                latencyOneWay = update.latest_rtt / 2;
            }
            else if ( update.smoothed_rtt ){
                smoothedBackup = update.smoothed_rtt / 2;
            }

            if ( latencyOneWay !== Number.MIN_SAFE_INTEGER ) {
                latencyOneWay = clientConnection.connection.getEventParser().timeToMilliseconds(latencyOneWay); // latencies could be in microseconds in the events, convert them here
                break;
            }
        }

        if ( latencyOneWay === Number.MIN_SAFE_INTEGER && smoothedBackup !== 0 ) {
            latencyOneWay = smoothedBackup;
        }

        if ( latencyOneWay === Number.MIN_SAFE_INTEGER ){

            smoothedBackup = 0;
            const serverMetricUpdates = serverConnection.connection.lookup( qlog.EventCategory.recovery, qlog.RecoveryEventType.metrics_updated );
            for ( const evt of serverMetricUpdates ){ 
                const update = serverConnection.connection.parseEvent(evt).data as qlog.IEventMetricsUpdated;
                if ( update.latest_rtt ){
                    latencyOneWay = update.latest_rtt / 2;
                }
                else if ( update.smoothed_rtt ){
                    smoothedBackup = update.smoothed_rtt / 2;
                }

                if ( latencyOneWay !== Number.MIN_SAFE_INTEGER ) {
                    latencyOneWay = serverConnection.connection.getEventParser().timeToMilliseconds(latencyOneWay); // latencies could be in microseconds in the events, convert them here
                    break;
                }
            }

            if ( latencyOneWay === Number.MIN_SAFE_INTEGER && smoothedBackup !== 0 ) {
                latencyOneWay = smoothedBackup;
            }
        }

        // the metrics-based approach works, but can be flaky if there was loss (e.g., client initial is lost, needs to retransmit but the lost one is in the trace)
        // then the server's initialReceived would be in between client initial 0 and 1 due to that offset, instead of after initial 1
        // so, we also check for the actual initials still here
        // start by looking for the first initial the server got and work backwards from there

        let initialSent:IQlogRawEvent|undefined = undefined;
        let initialReceived:IQlogRawEvent|undefined = undefined;
        let serverInitialReceived:IQlogRawEvent|undefined = undefined;

        let firstInitialReceivedPN = "0";

        for ( const rawEvt of serverConnection.connection.getEvents() ) {
            const evt = serverConnection.connection.parseEvent( rawEvt );

            if ( evt.name === qlog.TransportEventType.packet_received && evt.data.header &&
                evt.data.header.packet_type === qlog.PacketType.initial && evt.data.header.packet_number !== undefined ) {
                    serverInitialReceived = rawEvt;

                    firstInitialReceivedPN = "" + evt.data.header.packet_number; // e.g., if client inital 0 and 1 were lost, this should be 2
            }

            if ( serverInitialReceived ) {
                break;
            }
        }

        for ( const rawEvt of clientConnection.connection.getEvents() ) {
            const evt = clientConnection.connection.parseEvent( rawEvt );

            if ( evt.name === qlog.TransportEventType.packet_sent && evt.data.header &&
                    evt.data.header.packet_type === qlog.PacketType.initial && 
                    ( "" + evt.data.header.packet_number === firstInitialReceivedPN ) ) {
                    initialSent = rawEvt;
                    // continue;
            }

            // the server's initial could also be lost... but then we'd need to look for retransmits of that etc. which is above my level of enthousiasm at the moment
            // so: just use the first one we've received from the server. Could be too high then: bad luck. 
            if ( evt.name === qlog.TransportEventType.packet_received && evt.data.header &&
                 evt.data.header.packet_type === qlog.PacketType.initial ) { // && ( "" + evt.data.header.packet_number === "0" ) ) { 
                    initialReceived = rawEvt;
            }

            if ( initialSent && initialReceived ) {
                break;
            }
        }

        if (initialSent && initialReceived && serverInitialReceived){
            if (latencyOneWay === Number.MIN_SAFE_INTEGER ){
                // only if wasn't derived from metric_updates. We assume those are always correct
                latencyOneWay = (clientConnection.connection.parseEvent(initialReceived).absoluteTime - clientConnection.connection.parseEvent(initialSent).absoluteTime) / 2;
                if (latencyOneWay <= 0 ){
                    console.error("SequenceDiagramD3Renderer:calculateTimeOffset : initial received is earlier than sent! ", latencyOneWay);

                    return;
                }
            }

            // so, we now know at what time we would like the serverInitialReceived to have happened (clientInitialSent + latencyOneWay)
            // so we see where it is right now, then offset by that
            // NOTE: if the two clocks are not in sync globally, this might still be off a bit, but nothing we can do about that automagically
            const serverReceiveTime = serverConnection.connection.parseEvent(serverInitialReceived).absoluteTime;
            const expectedServerReceiveTime = clientConnection.connection.parseEvent(initialSent).absoluteTime + latencyOneWay;
            if ( serverReceiveTime > expectedServerReceiveTime ){
                latencyOneWay = serverReceiveTime - expectedServerReceiveTime;
            }
            else {
                latencyOneWay = expectedServerReceiveTime - serverReceiveTime;
            }
        }
        else if (latencyOneWay !== Number.MIN_SAFE_INTEGER) {
            // we can't accurately calculate the actual offset just from the metric_updates, but it's all we have in the world...
            console.log("SequenceDiagramD3Renderer:calculateTimeOffset: calculating probable RTT from metrics_updated events because initials couldn't be properly correlated (was there loss?)", 
                            latencyOneWay, initialSent, serverInitialReceived, initialReceived );
            // latencyOneWay = Number.MIN_SAFE_INTEGER;
        }

        if (latencyOneWay === Number.MIN_SAFE_INTEGER ) {
            return;
        }

        console.log("SequenceDiagramD3Renderer:calculateTimeOffset : offset determined at ", latencyOneWay);
        // this forces update of the UI, but this value is not persisted when changing connections 
        // (e.g., changing back to this one later resets the .timeOffset value due to the current implementation)
        serverConnection.timeOffset = latencyOneWay;
        // so... we also keep the timeoffset in our local data so we can use that when we come back to it
        this.createPrivateNamespace(serverConnection.connection);
        (serverConnection.connection as any).qvis.sequencediagram.manualTimeOffset = latencyOneWay;
    }

    protected calculateCoordinates(traces:Array<SequenceDiagramConnection>):number {

        const pixelsPerMillisecond = this.dimensions.pixelsPerMillisecond;

        // we have n traces, each with their own timestamped events
        // we want to map these on a single conceptual sequence diagram, so that the same timestamps line up correctly on the y-axis, but still have a single vertical timeline per-trace
        // we also want to cut out long periods of inactivity and prevent overlaps (e.g., for many packets at the same timestamp)
        // To do this, we have to calculate the y-coordinates as we go, accumulting to prevent overlaps, skipping large idle periods and keeping things in-sync between traces
        // the simplest way to do this would be to merge all the traces into 1 big event log, ordered by timestamp
        // However, since the traces can get quite big, we don't want to do this, as it would use -a lot- of memory
        // So instead we perform a naive online k-way merge (so without actually moving to new memory) to process the events in their timestamp order
        // https://en.wikipedia.org/wiki/K-way_merge_algorithm
        const heads:Array<number> = new Array<number>( traces.length ).fill(0); // points to the current index of each trace we're looking at
        const trackers:Array< CoordinateTracker > = new Array<CoordinateTracker>();

        // we need to compare / draw timestamps on a single, absolute timeline (mostly: unix timestamps)
        // However, we don't want to render our times as unix timestamps, as that's not very nice to look at
        // So, we figure out the start of our "relative" timline, which is the time the earliest of our traces starts
        // That is then time "0" and all the rest is shown relative to this. This time "0" is the absoluteAggregatedStartTime
        this.absoluteAggregatedStartTime = Number.MAX_VALUE;

        for ( const trace of traces ){
            // a. initiate trackers
            const tracker:CoordinateTracker = {
                timestamp: 0,
                y: 0,
            }
            trackers.push( tracker );

            // b. calculate absolute starting time
            // separate loop would be cleaner, but less performant ;)
            this.absoluteAggregatedStartTime = Math.min( this.absoluteAggregatedStartTime, trace.connection.getEventParser().getAbsoluteStartTime() );
        }

        let done = false;
        let doneCount = 0;

        let maxY = 0;

        let currentTimestampUnderConsideration:number = -1;
        let currentY:number = this.dimensions.margin.top;
        let inOverlapPreventionMode:boolean = false;
        let previousMinimumTrace:number = 0; // only needed for overlap prevention

        // normally, we do per 1 ms. If we have sub-ms latencies, need more resolution, so up this value. 1000 means microseconds, 1 means milliseconds (default)
        const timeResolution = this.timeResolution;
        this.absoluteAggregatedStartTime *= timeResolution;

        this.shortenedIntervals = new Array<Interval>();

        while ( !done ) {
            let currentMinimumTrace:number = -1;
            let currentMinimumTime:number = Number.MAX_VALUE;
            let currentMinimumEvent:any;

            for ( let t = 0; t < traces.length; ++t ){
                if ( heads[t] === -1 ) { // means that array has been processed completely
                    continue;
                }

                const trace = traces[t].connection;
                const timeOffset = traces[t].timeOffset;

                const evt = trace.getEvents()[ heads[t] ];
                const time = (trace.parseEvent(evt).absoluteTime * timeResolution) - this.absoluteAggregatedStartTime + (timeOffset * timeResolution); // timeWithCustomOffset(timeOffset);

                (evt as any).timeText = "" + time.toFixed(2);

                // < instead of <= so we always favor rendering a single trace as long as possible before switching to the next. 
                // Important for overlap prevention.
                if ( time < currentMinimumTime ){ 
                    currentMinimumTrace = t;
                    currentMinimumTime = time;
                    currentMinimumEvent = evt;
                }
            }

            // goals:
            // 1. prevent long stretches of empty vertical space : replace those with shorter parts
            //  -> need to detect when these happen and adjust accordingly
            //  -> because we look for the minimum across traces each time, this is easy: if there is too large a margin between the new and old, everything is shifted down
            // 2. prevent overlapping of events on the same timeline (can overlap horizontally in different timelines)
            //  -> need to both keep track of overlaps on the same timeline, and make sure all timelines shift down when one of them does 
            //  -> this is more involved and requires separate tracking structs per-timeline ("trackers")

            // need to keep a running total per-timeline: (lastTimestamp + lastActualY)
            //  -> currentTimestamp - lastTimestamp is then what we use for our logic
            //  -> lastActualY + (timestampDiff * pixelsPerMilliSecond) is then what we need
            //  -> if we then skip a range, we need to not just do timeStampDiff * pixelsPerMillisecond, but apply a scaling factor to that
            //  -> if we then have overlap prevention, we keep timestamp the same, update only lastActualY. 
            //          The moment we have a new timestamp, we make all lastActualY's the same (and also timestamps?)

            // we render in milliseconds, so the overlap is on millisecond resolution
            // however, the times are floats, so we need to round them
            const currentTimeBucket = Math.floor( currentMinimumTime );

            // 2. prevent overlaps
            // Example of what can happen:
            // | 105            | 105           |           | 105   
            // | 105            |               |           | 105   
            // | 105            |               |           | 105   
            // | 105            |               |           |       
            // | 105            |               |           |       
            // 4 timelines, of which 3 have events all at timeBucket 105
            // we cannot just render all the 105 events from trace 1, then those of 2, etc.
            // so in this case, we need to keep track when we started the overlaps (tracker.y)
            // then render all events of the 1st trace. When that's done, we render those of trace 2, etc.
            // setting currentY to the currentMinimumTrace's tracked Y ensures that we "reset" to the y where the overlaps began for each trace in turn
            // then, when timestamp > 105 starts, we exit this mode and just use the maximum of the tracked Y's as new currentY 
            // (in this case the one for the 1st trace)
            if ( currentTimeBucket === currentTimestampUnderConsideration ){

                // 2 options:
                //  1) either this is the first and we need to initiate the trackers
                //  2) or we're in a stretch of overlaps and need to continue;
                
                // 1)
                if ( !inOverlapPreventionMode ) {
                    inOverlapPreventionMode = true;


                    // problem: when we get here, it's basically the 2nd event in the same timebucket
                    // we've already drawn the 1st event at currentY
                    // so if we now set all tracks to currentY and then do + pixelsPerMillisecond on all (see below), the 1st track will be "one ahead" of the rest
                    // so, make sure the other lines "undo" that first increment here 
                    // NOTE: I'm sure there's a cleaner way of doing this, but it's not coming to monday-morning-me
                    for ( let t = 0; t < trackers.length; ++t ){
                        if ( t !== previousMinimumTrace ){
                            trackers[t].y = currentY - pixelsPerMillisecond;
                        }
                        else {
                            trackers[t].y = currentY;
                        }
                    }

                    // for (const tracker of trackers) {
                    //     tracker.y = currentY;
                    // }

                }

                // 2)
                // time remains the same, but we can have switched traces, so need to select the correct starting Y
                trackers[currentMinimumTrace].y += pixelsPerMillisecond;
                currentY = trackers[currentMinimumTrace].y;
            }
            else if ( inOverlapPreventionMode ){ 

                // we previously had overlaps, but now we're onto the next Timestamp bucket: need to update everyone + exit mode
                inOverlapPreventionMode = false;

                let maxTrackerY = 0;
                for (const tracker of trackers) {
                    if ( tracker.y > maxTrackerY ){
                        maxTrackerY = tracker.y;
                    }
                }

                currentY = maxTrackerY;
            }

            const timeDifference = (currentTimeBucket - currentTimestampUnderConsideration);

            // 1. check for longer stretches on inactivity and compress them
            // do this after 2., since otherwhise this offset can be overridden by exiting overlapPreventionMode
            if ( timeDifference * pixelsPerMillisecond > this.dimensions.shortenIntervalsLongerThan ) { // max space of 120 pixels allowed
                this.shortenedIntervals.push({
                    yMin: currentY,
                    yMax: currentY + this.dimensions.shortenIntervalsLongerThan,
                    timeSkipped: currentTimeBucket - currentTimestampUnderConsideration,
                });
                
                currentY += this.dimensions.shortenIntervalsLongerThan;
            }
            else {
                // this is the default behaviour, just render the next event directly relative to the previous one
                currentY += timeDifference * pixelsPerMillisecond;
            }

            

            this.createPrivateNamespace(currentMinimumEvent);
            (currentMinimumEvent as any).qvis.sequencediagram.y = currentY; // traces[currentMinimumTrace].parseEvent(currentMinimumEvent).time * pixelsPerMillisecond;

            // console.log("Next event was : ", (currentMinimumEvent as any).qvis.sequencediagram.y, currentMinimumTrace, currentMinimumValue);

            // prepare for next loop
            currentTimestampUnderConsideration = currentTimeBucket;
            previousMinimumTrace = currentMinimumTrace;

            heads[ currentMinimumTrace ] += 1;
            if ( heads[currentMinimumTrace] >= traces[currentMinimumTrace].connection.getEvents().length ) {
                heads[ currentMinimumTrace ] = -1;
                ++doneCount;
            }

            done = doneCount === traces.length;

            maxY = currentY;
        }

        // let DEBUG_penultimateEvent = traces[0].getEvents()[ traces[0].getEvents().length - 1 ];
        // let DEBUG_lastEvent = DEBUG_penultimateEvent.slice();
        // this.createPrivateNamespace( DEBUG_lastEvent );
        // (DEBUG_lastEvent as any).qvis.sequencediagram.y = (DEBUG_penultimateEvent as any).qvis.sequencediagram.y + 1000;
        // traces[0].getEvents().push( DEBUG_lastEvent );
        // maxY += 1000;


        maxY += this.dimensions.margin.bottom; // give a bit of breathing room at the bottom of the diagram

        return maxY;
    }

    protected calculateConnections() {
        // we want to draw arrows between PACKET_* events 
        // arrow starts from PACKET_SENT and goes to PACKET_RECEIVED
        // we do 2 passes: 1 from left to right (client to server), 1 from right to left (server to client)
        // because we can have intermediate network-traces, we need to take into account their individual perspectives
        // as such, we process in the two directions to be able to do that correctly

        const connectEventLists = (metadataTargetProperty:arrowTargetProperty, start:QlogConnection, startEvents:Array<IQlogRawEvent>, end:QlogConnection, endEvents:Array<IQlogRawEvent>) => {

            // start.parseEvent() looks up the eventparser using this.eventParser, which is a Vue ReactiveGetter, which is -slow-...
            // so, create our own references to the parsers here, which is faster
            const startParser = start.getEventParser();
            const endParser   = end.getEventParser();

            let DEBUG_packetLostCount = 0;

            // for each of the events in our starting trace, we need to see if we can find an accompanying event in the ending trace
            // however, the naive way of doing this is O(n * n), which turns out to be too slow for large traces
            // so, we're going to use some domain knowledge and heuristics to speed this up
            // We know all events are ordered by timestamp and that QUIC packet numbers are monotonically increasing
            // So when looking for the counterpart for packet 5000, we -probably- don't need to start all the way from the bottom, or go to packet 15000
            // We keep track of the previously found packet and look in 10% before and 10% after increments 
            // (if it's outside that, there is massive jitter anyway, and the use of this visualization is debatable)
            // this approach allowed us to go from 7s to < 600ms for a 3.5MB trace
            // TODO: speed up even more by skipping packet numbers that have a PACKET_LOST event

            let lastFoundTargetIndex:number = 0;
            const endEventsFraction:number = Math.min(1000, Math.max(200, Math.round(endEvents.length / 10))); // 10% each way, minimum of 200 events, max of 1000

            for ( const rawevt of startEvents ){
                const evt = startParser.load(rawevt).data as qlog.IEventPacketSent;
                const metadata = (rawevt as any).qvis.sequencediagram; 

                if ( evt.header === undefined ) {
                    console.error("SequenceDiagram:calculateConnections : event data does not have the header field, which is required", evt);
                    continue;
                }

                if ( evt.header.packet_number === undefined ){
                    if ( evt.header.packet_type !== qlog.PacketType.version_negotiation && 
                         evt.header.packet_type !== qlog.PacketType.retry && 
                         evt.header.packet_type !== qlog.PacketType.stateless_reset ){
                        console.error("SequenceDiagram:calculateConnections : event data does not have the header.packet_number field, which is required", evt);
                    }
                    continue;
                }

                metadata[arrowTargetProperty.right] = undefined; // could be set from a previous processing, which might no longer be correct now (e.g., new trace in the middle)
                metadata[arrowTargetProperty.left]  = undefined;
                // evt.header!.packet_number = "DEBUG_FORCELOSS";

                const startCandidateIndex:number = Math.max( 0,                    lastFoundTargetIndex - endEventsFraction ); // go back 10% events, but not lower than 0
                const endCandidateIndex:number   = Math.min( endEvents.length - 1, lastFoundTargetIndex + endEventsFraction ); // go forward 10% events, but not beyond the array length


                let counterpartFound = false;
                for ( let c = startCandidateIndex; c <= endCandidateIndex; ++c ) {
                    // note : event can be either sent or received, but interfaces are the same, so doesn't matter atm
                    // TODO: define separate interface for this in the qlog schema!
                    const candidate = endParser.load( endEvents[c] ).data as qlog.IEventPacket;
                    
                    // need to check for .type as well to deal with different packet number spaces
                    // some packets (like stateless resets) don't have a header or packet_number, so need to check for that
                    if (candidate.header && evt.header && candidate.header.packet_type === evt.header.packet_type && ("" + candidate.header!.packet_number) === ("" + evt.header!.packet_number) ){
                        metadata[metadataTargetProperty] = endEvents[c];
                        lastFoundTargetIndex = c;
                        counterpartFound = true;
                        break;
                    }
                }

                if ( !counterpartFound ) {
                    // we suspect the packet is lost... 
                    // we COULD look for an explicit packet_lost event, but most implementations don't log those yet, so we need to be robust against those

                    // NOTE: if we have only a single real trace loaded, we will never see lost events this way
                    // to support that, we'd have to look at ACK gaps and out-of-order offsets in STREAM frames etc.
                    // do-able (see the multiplexing diagram for example) but complex TODO

                    // packet is assumed lost
                    metadata[arrowTargetProperty.lost] = metadataTargetProperty; // store the direction in here, so we know where to draw the lost event to
                }

                if ( metadata[metadataTargetProperty] === undefined ){
                    DEBUG_packetLostCount++;
                }
            }
        };

        const connectTraces = (metadataTargetProperty:arrowTargetProperty, start:QlogConnection, end:QlogConnection) => {

            let startPerspective = start.vantagePoint.type;
            let endPerspective = end.vantagePoint.type;

            if ( startPerspective === qlog.VantagePointType.network ){
                startPerspective = start.vantagePoint.flow as qlog.VantagePointType;
            }
            if ( endPerspective === qlog.VantagePointType.network ){
                endPerspective = end.vantagePoint.flow as qlog.VantagePointType;
            }

            const startEventType = qlog.TransportEventType.packet_sent;
            const endEventType = (startPerspective === endPerspective ) ? qlog.TransportEventType.packet_sent : qlog.TransportEventType.packet_received;

            const startEvents = start.lookup( qlog.EventCategory.transport, startEventType );
            const endEvents = end.lookup( qlog.EventCategory.transport, endEventType );

            if ( startEvents.length === 0 ) { 
                console.error("SequenceDiagram:calculateConnections : trace " + start.parent.filename + ":" + startPerspective + " did not have " + startEventType + " events, which are needed");
            }
            if ( endEvents.length === 0 ) { 
                console.error("SequenceDiagram:calculateConnections : trace " + end.parent.filename + ":" + endPerspective + " did not have " + endEventType + " events, which are needed");
            }

            connectEventLists( metadataTargetProperty, start, startEvents, end, endEvents );
        };

        // packets flowing from client to server (left to right)
        for ( let t = 0; t < this.traces.length - 1; ++t ){ // to -1, because rightmost is handled separately below
            const start = this.traces[t];
            const end   = this.traces[t + 1];

            connectTraces(arrowTargetProperty.right, start.connection, end.connection);
        }

        // packets flowing from server to client (right to left)
        for ( let t = this.traces.length - 1; t > 0; --t ) { // > 0 because leftmost was handled above
            const start = this.traces[t];
            const end   = this.traces[t - 1];

            connectTraces(arrowTargetProperty.left, start.connection, end.connection);
        }
    }

    protected async renderPartialExtents( focusOn:EventPointer|null = null ){

        // About rendering performance:
        // - simply using d3 directly and creating all the svg shapes in 1 big loop is very slow for large files (>10s)
        //      - main bottlenecks are Major GCs (apparently .appendChild and .createElement creates tons of garbage...) but also "recalculate style" and "layout"
        //      - adding elements to an svg element that is already in the DOM tree is slower than adding them to a sepate svg element (via d3.create) but not much
        //      - adding elements in a time-sliced way (e.g., pause 100ms after every 2000 events) works, but we still see very high reflow/layout costs (>200ms per batch)
        //      - using documentFragment does nothing (very similar to adding to an SVG that's not in the DOM tree yet)
        // - doing svg elements without d3: is somewhat faster (say 8s -> 6s) and seems to induce less garbage collection: recommended
        // - doing canvas : just 1s to draw and render everything... there's really no competition

        // HOWEVER: canvas does not allow us to interact with individual elements directly and is not scalable
        // while both these problems can be solved, it would take much time. 
        // As such, we reserve the canvas method for visualizations that really -need- to draw that many objects at once (e.g., the congestion diagram)
        // For diagrams such as the sequence timelines, we will never be showing everything at once, so we can get by with drawing only the visible parts at a time
        // The following implementation only draws the current viewport + the ones above and below it (for smoother scrolling)
        // Next to this, it actively removes/un-renders old data. This is because on eof the main bottlenecks is the "recalculate style" and "layout" steps from the browser
        // These scale super-linearly with the amount of objects in the DOM (not just the newly added ones) so we need to keep the total amount down to remove that bottleneck

        // TODO: add a "save to SVG" option that -does- draw everything at once (at the cost of the user having to wait a while)

        // 0. allow passing in of an even to focus on
        if ( focusOn ) {
            if ( this.traces.length > focusOn.connectionIndex ) {

                const trace = this.traces[ focusOn.connectionIndex ];
                const events = trace.connection.getEvents();

                if ( focusOn.packetNumber ) {
                    // we "abuse" .eventIndex by looking up the event belonging to the packet number and using that event's index
                    let idx = 0;
                    for ( const rawEvt of events ) {
                        const evt = trace.connection.parseEvent(rawEvt);

                        // we only check in the packet_sent event for the given trace
                        // if you want the other trace, need to specify another connectionIndex
                        if ( evt.name === qlog.TransportEventType.packet_sent &&
                             evt.data && evt.data.header && evt.data.header.packet_number ) {
                            if ( "" + evt.data.header.packet_number === "" + focusOn.packetNumber ) {
                                focusOn.eventIndex = idx;
                                console.log("SequenceDiagramD3Renderer:renderPartialExtents: packet number found in event", rawEvt, focusOn);
                                break;
                            }
                        }

                        ++idx;
                    }

                    if ( !focusOn.eventIndex ) {
                        console.error("SequenceDiagramD3Renderer:renderPartialExtents: packet number couldn't be found in the trace...", focusOn, this.traces);
                    }
                }

                if ( focusOn.eventIndex ) {
                    // a. figure out the y offset for the event (stored in the metadata from calculateCoordinates)
                    if ( events.length > focusOn.eventIndex ) {
                        const evt = events[ focusOn.eventIndex ] as any;
                        if ( evt.qvis && evt.qvis.sequencediagram && evt.qvis.sequencediagram.y ) {
                            const targetY = evt.qvis.sequencediagram.y - 50; // - 50 to scroll back up a little bit so we are sure the event is "in view"
                            console.log("SequenceDiagramD3Renderer:renderPartialExtents: focusing on event ", focusOn, targetY);

                            window.scrollTo( 0, targetY ); // this will trigger the scrollHandler, which will again enter this function, so we exit it instead

                            return;
                        }
                        else {
                            console.error("SequenceDiagramD3Renderer:renderPartialExtents: couldn't focus on event, y unknown", focusOn, this.traces);
                        }
                    }
                    else {
                        console.error("SequenceDiagramD3Renderer:renderPartialExtents: couldn't focus on event, eventIndex unknown", focusOn, this.traces);
                    }
                }
                else {
                    console.error("SequenceDiagramD3Renderer:renderPartialExtents: neither eventIndex nor pnIndex was set, one is required to focus!", focusOn, this.traces);
                }
            }
            else {
                console.error("SequenceDiagramD3Renderer:renderPartialExtents: couldn't focus on event, traceIndex unknown", focusOn, this.traces);
            }
        }

        // 1. determine which areas to render and which to un-render
        // 2. un-render the proper ranges
        // 3. render the proper ranges

        const svg = this.svg;

        // 1. 

        // want to calculate to the visible area of our svg
        // this turned out to be quite non-trivial... there is no default API for this
        // - would be easy of we're always filling the screen and our element is the only one: yMin = window.pageYOffset ( = basically scrollTop)
        // - however, our element is in some container, so we need to calculate how far down we are (offsetFromDocumentTop) and take that into account.
        //   -> this becomes interesting, because as we scroll, we scroll fully into view with our svg, 
        //      so that's why we use Math.max: as soon as the offset is negative, means we are fully into the viewport)
        // - then, calculating yMax, we need to again take into account that we don't always fill the entire screen: cannot just do yMin + window.innerHeight
        //   -> we use Math.max again: when svgRect.top becomes negative, we're screen filling, so we default to the full height
        const svgRect = (svg.node()! as Element).getBoundingClientRect();
        const offsetFromDocumentTop = svgRect.top - document.body.getBoundingClientRect().top;
        const yMin = Math.max(0, window.pageYOffset - offsetFromDocumentTop);
        const yMax = yMin + (window.innerHeight - Math.max(0, svgRect.top));


        // 1.b we want to have a hacky override that forces the tool to draw the full SVG at once (e.g., for storage, search)
        // for this, we just never remove extents
        let forceFullRender = false;
        // TODO: FIXME: this is very hacky and should be propagated down from the parent component properly!!!
        if ( window.location.hash && window.location.hash.indexOf("forceFull") >= 0 ){
            forceFullRender = true;
        }

        // see if we need to render ranges at this time
        const currentRangeIndex = Math.floor(yMin / this.rangeHeight);
        let fromRange         = Math.max(0,                              currentRangeIndex - 1);
        let toRange           = Math.min(this.renderedRanges.length - 1, currentRangeIndex + 1);

        if ( forceFullRender ) {
            fromRange = 0;
            toRange = this.renderedRanges.length - 1;

            console.warn("SequenceDiagramD3Renderer:renderPartialExtents: forcing a full render of the entire diagram, this can cause slowdowns!", this.renderedRanges);
        }

        // we need to go from ranges to actual [yMin, yMax] "extents" that we can render
        const extentsToRender:Array< ExtentInfo > = new Array< ExtentInfo >();

        // TODO: do we really need ExtentInfo? why not just store the stop in the range and keep array of ranges?
        for ( let r = fromRange; r <= toRange; ++r ){
            if ( !this.renderedRanges[r].rendered ){
                extentsToRender.push( { rangeIndex: r, start: this.renderedRanges[r].yMin, stop: this.renderedRanges[r].yMin + this.rangeHeight - 1} ); // -1 to prevent overlap with next range
            }
        }

        // see if we need to un-render ranges at this time
        const rangeIndicesToRemove:Array< number > = new Array< number >();

        if ( !forceFullRender ) {

            // first determine the lower indices
            let removeFrom:number = Math.max(0, fromRange - 500);
            let removeTo:number   = Math.max(0, fromRange - 2); // leave 1 extra buffer of rendered range
            if ( !(removeFrom === 0 && removeTo === 0) ){ // don't want to remove range 0 if it's the only one
                for ( let r = removeFrom; r <= removeTo; ++r ){
                    if ( this.renderedRanges[r].rendered ){
                        rangeIndicesToRemove.push( r );
                    }
                }
            }
            // then the higher indices (when scrolling back up)
            removeFrom  = Math.min(this.renderedRanges.length - 1, toRange + 2); // leave 1 extra buffer of rendered range
            removeTo    = Math.min(this.renderedRanges.length - 1, toRange + 500);
            if ( !(removeFrom === this.renderedRanges.length - 1 && removeTo === this.renderedRanges.length - 1) ){ // don't want to remove the last range if it's the only one
                for ( let r = removeFrom; r <= removeTo; ++r ){
                    if ( this.renderedRanges[r].rendered ){
                        rangeIndicesToRemove.push( r );
                    }
                }
            }

        }

        // 2. 
        if ( rangeIndicesToRemove.length >= 1 ){
            // console.log("rangesToRemove", currentRangeIndex, rangeIndicesToRemove);

            // when rendering, we group all elements of a single range/extent together in 1 group (range.svgGroup)
            for ( const rangeIndex of rangeIndicesToRemove ) {
                const rangeSvgGroup = this.renderedRanges[rangeIndex].svgGroup;
                // console.log("Removing", rangeSvgGroup, (rangeSvgGroup as any).parentNode);

                (rangeSvgGroup as any).parentNode.removeChild( rangeSvgGroup );

                this.renderedRanges[rangeIndex].svgGroup = undefined;
                this.renderedRanges[rangeIndex].rendered = false;
            }
        }

        // nothing new to render, so we can stop
        // can happen e.g., if user only scrolls small area
        if ( extentsToRender.length === 0 ){
            return;
        }

        // 3.


        // console.log("Actual coordinates to render", extentsToRender);

        /*
        const svg = d3.create("svg").attr("id", this.svgID);
        svg.attr("xmlns", "http://www.w3.org/2000/svg")
            .attr("xmlns:xlink", "http://www.w3.org/1999/xlink")
            .attr("font-family", "Trebuchet MS");
        */

        const pixelsPerMillisecond = this.dimensions.pixelsPerMillisecond;

        const output = '';

        // to help visualizing lost packets
        // we put these outside of the traces-loop, because otherwise lost packets at the start of each extent would have 0
        // seems like it would be rare enough not to matter, but turns out it isn't...
        let previousYDiffLeft = 0;
        let previousYDiffRight = 0;

        for ( const extent of extentsToRender ){

            const extentContainer = document.createElementNS("http://www.w3.org/2000/svg", "g");
            this.renderedRanges[extent.rangeIndex].svgGroup = extentContainer;
            this.renderedRanges[extent.rangeIndex].rendered = true;

            for ( let i = 0; i < this.traces.length; ++i ){
                const trace = this.traces[i];
                const currentX = this.bandWidth * i + (this.bandWidth * 0.5); // center of the horizontal band

                const events = trace.connection.getEvents();
                
                let currentY = 0;
                let currentMetadata = undefined;
                let currentEventId = 0;
                for ( const rawEvt of events ){
                    const evt = trace.connection.parseEvent(rawEvt);
                    currentMetadata = (rawEvt as any).qvis.sequencediagram;
                    currentY = currentMetadata.y;

                    const focusInfo = { connectionIndex: i, eventIndex: currentEventId };
                    currentEventId += 1;

                    if ( currentY < extent.start ) {
                        continue;
                    }

                    if ( currentY > extent.stop ) {
                        break;
                    }

                    if ( evt.name === this.ignoreEventName ){
                        continue;
                    }

                    // rect for each event on the vertical timelines
                    const rect = document.createElementNS("http://www.w3.org/2000/svg", "rect");
                    const rectSize = pixelsPerMillisecond * 0.6;
                    rect.setAttribute('x', "" + (currentX - rectSize / 2));
                    rect.setAttribute('y', "" + (currentY - rectSize / 2)); // x and y are top left, we want it to be middle
                    rect.setAttribute('width', ""  + (rectSize));
                    rect.setAttribute('height', "" + (rectSize));
                    rect.setAttribute('fill', 'green');
                    rect.onclick = (evt_in) => this.onEventClicked( rawEvt, trace.connection, focusInfo );
                    extentContainer.appendChild( rect );

                    // timestamp for each event next to the rects
                    let timeText:any = "";
                    if ( (rawEvt as any).timeText !== undefined ){
                        timeText = (rawEvt as any).timeText;
                    }
                    else {
                        timeText = evt.absoluteTime - this.absoluteAggregatedStartTime + trace.timeOffset;
                        timeText = timeText.toFixed(2);
                    }

                    const text = document.createElementNS("http://www.w3.org/2000/svg", "text");
                    text.setAttribute('class', "timestamp");
                    text.setAttribute('x', "" + (currentX - (pixelsPerMillisecond / 2) + ((i === 0) ? -pixelsPerMillisecond * 2 : pixelsPerMillisecond * 2)));
                    text.setAttribute('y', "" + (currentY));
                    text.setAttribute('dominant-baseline', "middle");
                    text.setAttribute('text-anchor', (i === 0) ? "end" : "start");
                    text.textContent = "" + timeText;
                    extentContainer.appendChild( text );

                    // TODO: now we're using left and right and client is always left, server always right
                    // could make this more flexible if each event would also store their x-coordinate, rather than only y

                    // full connecting arrows between events
                    let target:any|undefined = undefined;
                    let offsetMultiplier:number|undefined = undefined;
                    let directionText:string|undefined = undefined;
                    let directionColor:string|undefined = undefined;
                    let packetLost:boolean = false;

                    const colorRight = "#0468cc"; // blue
                    const colorLeft = "#a80f3a"; // red

                    if  (currentMetadata[ arrowTargetProperty.right ] ){
                        offsetMultiplier = 1;
                        target = (currentMetadata[ arrowTargetProperty.right ] as any).qvis.sequencediagram;
                        directionText = ">";
                        directionColor = colorRight;

                        previousYDiffRight = target.y - currentY; // top y = 0, so target should be larger than current
                    }
                    else if ( currentMetadata[ arrowTargetProperty.left ] ){
                        offsetMultiplier = -1;
                        target = (currentMetadata[ arrowTargetProperty.left ] as any).qvis.sequencediagram;
                        directionText = "<";
                        directionColor = colorLeft; // red

                        previousYDiffLeft = target.y - currentY; // top y = 0, so target should be larger than current
                    }
                    else if ( currentMetadata[ arrowTargetProperty.lost ] !== undefined ) {
                        // packet is lost: want to draw half an arrow

                        // for this, need to figure out the halfway point, which is... a bit challenging?
                        // we have to extrapolate the slant of the arrow (indicating the latency) from the previously seen latency in this direction
                        // then interpolate along that slant to the middle

                        if ( currentMetadata[ arrowTargetProperty.lost ] === arrowTargetProperty.right ) {
                            // packet on the left was sent to the right
                            offsetMultiplier = 0.5; // halfway arrow
                            target = { y: currentY + (previousYDiffRight / 2) }; // halfway down what we previously went down (not perfect, but best approx. we can make?)

                            directionText = ">";
                            directionColor = colorRight;
                        }
                        else {
                            // packet on the right was sent to the left
                            offsetMultiplier = -0.5; // halfway arrow
                            target = { y: currentY + (previousYDiffLeft / 2) }; // halfway down what we previously went down (not perfect, but best approx. we can make?)

                            directionText = "<";
                            directionColor = colorLeft;
                        }

                        packetLost = true;

                        // console.error("LOST PACKET DRAWN", evt.data, previousYDiffLeft, previousYDiffRight, offsetMultiplier, target, currentX );
                    }

                    if ( offsetMultiplier ) { // if not, the current event does not have a connecting arrow
                        let targetX = currentX + ( offsetMultiplier * this.bandWidth ); // either move 1 band to the right or left, depending on arrow direction
                        targetX = targetX - (offsetMultiplier! * (pixelsPerMillisecond / 2)); // don't overlap with the event rect
                        
                        const line = document.createElementNS("http://www.w3.org/2000/svg", "line");
                        line.setAttribute('x1', "" + (currentX));
                        line.setAttribute('x2', "" + (targetX));
                        line.setAttribute('y1', "" + (currentY)); 
                        line.setAttribute('y2', "" + (target.y));
                        line.setAttribute('stroke-width', '2');
                        line.setAttribute('stroke', directionColor!);
                        extentContainer.appendChild( line );

                        // polyline expects a list of x,y coordinates
                        // we draw the arrow as normal (across the "x-axis" to the right: >), then rotate it along the connecting line

                        const arrowX = targetX; 
                        let points = "";
                        points +=  `${arrowX - 10},${target.y - 10}`; // top point
                        points += ` ${arrowX     },${target.y     }`; // center point
                        points += ` ${arrowX - 10},${target.y + 10}`; // bottom point

                        // https://stackoverflow.com/questions/2676719/calculating-the-angle-between-the-line-defined-by-two-points
                        const deltaY = currentY - target.y;
                        const deltaX = targetX  - currentX;
                        let angle = Math.atan2(deltaY, deltaX) * 180 / Math.PI; 
                        angle = -angle; // svg's rotate has the convention that clockwise rotations are positive angles, counterclockwise are negative. 

                        const arrow = document.createElementNS("http://www.w3.org/2000/svg", "polyline");
                        arrow.setAttribute('points', points);
                        arrow.setAttribute('stroke-width', '4');
                        arrow.setAttribute('stroke', directionColor!);
                        arrow.setAttribute('fill', 'transparent');
                        arrow.setAttribute('transform', `rotate(${angle},${arrowX},${target.y})`);
                        extentContainer.appendChild( arrow );

                        if ( packetLost ) {
                            // draw an X next to the arrow
                            const crossX = targetX + ((offsetMultiplier * 0.02) * this.bandWidth);
                            const crossY = target.y + ((target.y - currentY) * 0.02);  

                            // start top left, draw line. Then move bottom left, draw line
                            let path = "M" + (crossX - 10) + " " + (crossY - 10);
                            path += " L" + (crossX + 10) + " " + (crossY + 10);
                            path += " M" + (crossX - 10) + " " + (crossY + 10);
                            path += " L" + (crossX + 10) + " " + (crossY - 10);

                            const cross = document.createElementNS("http://www.w3.org/2000/svg", "path");
                            cross.setAttribute('d', path );
                            cross.setAttribute('stroke-width', '4');
                            cross.setAttribute('stroke', "red");
                            cross.setAttribute('fill', 'transparent');
                            cross.setAttribute('transform', `rotate(${angle},${crossX},${crossY})`);
                            extentContainer.appendChild( cross );
                        }

                        // make the text 90% of the width of the arrow
                        const textWidth = Math.sqrt( Math.pow( targetX - currentX, 2) + Math.pow( target.y - currentY, 2) ) * 0.9;
                        const textHeight = pixelsPerMillisecond * 0.9; // bit smaller so we have some padding at least
                        let textAngle = angle;
                        // angle for the arrow can go to any value, for text we still want it to be readable (i.e., not upside down)
                        // value of 90 is basically further than -90 on the goniometric circle, aka upside down
                        // so if we go over that, compensate by swivveling to the other side
                        // dito for -90
                        if ( textAngle >= 90 ){
                            textAngle -= 180;
                        }
                        else if ( textAngle <= -90 ){
                            textAngle += 180;
                        }

                        const midwayX = (currentX + targetX ) / 2;
                        const midwayY = (currentY + target.y) / 2;

                        // getting different colored text spans next to each other in SVG requires -manual- positioning (yes, even though it's 2019)
                        // as such, we take the dirty route and use foreignObject so we can use the HTML layouting engine
                        const textForeign = document.createElementNS("http://www.w3.org/2000/svg", "foreignObject");
                        textForeign.setAttribute('x', "" + (midwayX));
                        textForeign.setAttribute('y', "" + (midwayY)); 
                        textForeign.setAttribute('width',  "" + textWidth);
                        textForeign.setAttribute('height', "" + textHeight); 
                        textForeign.style.overflow = "visible";
                        // order of the transformation is important here!
                        // we first rotate the top left corner of the text area around the midway point (which is also where it's positioned) so we get the correct rotation
                        // then we translate the entire rect within this rotated coordinate space (doing it the other way around would translate in worldspace, not what we want)
                        textForeign.setAttribute('transform', `rotate(${textAngle},${midwayX},${midwayY}) translate(${-textWidth / 2},${-textHeight - 3})`);  // 

                        const textContainer = document.createElementNS("http://www.w3.org/1999/xhtml", "div");
                        textContainer.style.width = "" + textWidth + "px";
                        textContainer.style.textAlign = "center";

                        if ( directionText === "<" ){
                            const smallArrowSize = Math.floor(textHeight * 0.30);
                            const directionSpan = document.createElement("span");
                            directionSpan.style.display = "inline-block";
                            directionSpan.style.borderTop = `${smallArrowSize}px solid transparent`;
                            directionSpan.style.borderBottom = `${smallArrowSize}px solid transparent`;
                            directionSpan.style.borderRight = `${smallArrowSize}px solid ${directionColor}`;
                            directionSpan.style.marginRight = "1px";
                            textContainer.appendChild(directionSpan);
                        }

                        const textSpanFront = document.createElement("span");
                        textSpanFront.textContent = "" + ( evt.data.header ? this.packetTypeToString(evt.data.header.packet_type) : "" ) + " : " + ( evt.data.header ? evt.data.header.packet_number : "" );
                        textSpanFront.style.color = "#383d41"; // dark grey
                        textSpanFront.style.backgroundColor = "#d6d8db"; // light grey
                        textSpanFront.style.paddingLeft = "5px";
                        textSpanFront.style.paddingRight = "5px";
                        textSpanFront.style.border = "1px white";
                        textSpanFront.style.borderStyle = "none solid";
                        textSpanFront.style.fontSize = "" + ( Math.floor(textHeight * 0.8) ) + "px";
                        textSpanFront.onclick = (evt_in) => this.onEventClicked(rawEvt, trace.connection, focusInfo);
                        textContainer.appendChild(textSpanFront);

                        if ( evt.data.frames ){

                            let framesToRender:undefined | Array<any> = undefined;

                            // in some cases, we have MANY frames in a single packet (e.g., some tests have 50+, if there are many ACK gaps it can also be dozens)
                            // so, if there are more than 8 (and more than 5 of a particular type) we aggregate them into a single visual entity
                            if ( evt.data.frames.length >= 8 ) {

                                const typeCounter:Map<QUICFrameTypeName, Array<any>> = new Map<QUICFrameTypeName, Array<any>>();

                                // count how many of each type, because we only want to aggregate those of the same type
                                for ( const frameRaw of evt.data.frames ) {
                                    let frames = typeCounter.get( frameRaw.frame_type );
                                    if ( !frames ) {
                                        frames = new Array<any>();
                                        typeCounter.set( frameRaw.frame_type, frames );
                                    }

                                    frames.push(frameRaw)
                                }

                                for ( const [frameTypeName,frames] of typeCounter.entries() ) {

                                    if ( frames.length > 5 ) {
                                        const textSpan = document.createElement("span");
                                        const [bgColor, textColor] = this.frameTypeToColor( frameTypeName );
                                        textSpan.textContent = frames.length + " " + frameTypeName + " frames (click for details)";
                                        textSpan.style.color = textColor;
                                        textSpan.style.backgroundColor = bgColor;
                                        textSpan.style.paddingLeft = "5px";
                                        textSpan.style.paddingRight = "5px";
                                        textSpan.style.border = "1px white";
                                        textSpan.style.borderStyle = "none solid";
                                        textSpan.style.fontSize = "" + ( Math.floor(textHeight * 0.8) ) + "px";
                                        textSpan.onclick = (evt_in) => this.onEventClicked(rawEvt, trace.connection, focusInfo);
                                        if ( directionText === ">" ) {
                                            textContainer.prepend(textSpan);
                                        }
                                        else {
                                            textContainer.appendChild(textSpan);
                                        }
                                    }
                                    else {
                                        // not more than 5, we still want to render individual frames below
                                        if ( !framesToRender ) {
                                            framesToRender = new Array<any>();
                                        }
                                        
                                        framesToRender.push( ...frames );
                                    }
                                }
                            }
                            else { // < 8 overall, just render each frame individually
                                framesToRender = evt.data.frames;
                            }
                            
                            if ( framesToRender ) {

                                for ( const frameRaw of framesToRender ) {

                                    if ( frameRaw.qvis && frameRaw.qvis.sequence && frameRaw.qvis.sequence.hide ) {
                                        continue;
                                    }

                                    const frame = frameRaw as qlog.QuicFrame;

                                    const textSpan = document.createElement("span");
                                    const [bgColor, textColor] = this.frameTypeToColor( frame.frame_type );
                                    textSpan.textContent = this.frameToShortString( frame );
                                    textSpan.style.color = textColor;
                                    textSpan.style.backgroundColor = bgColor;
                                    textSpan.style.paddingLeft = "5px";
                                    textSpan.style.paddingRight = "5px";
                                    textSpan.style.border = "1px white";
                                    textSpan.style.borderStyle = "none solid";
                                    textSpan.style.fontSize = "" + ( Math.floor(textHeight * 0.8) ) + "px";
                                    textSpan.onclick = (evt_in) => this.onEventClicked(rawEvt, trace.connection, focusInfo);
                                    if ( directionText === ">" ) {
                                        textContainer.prepend(textSpan);
                                    }
                                    else {
                                        textContainer.appendChild(textSpan);
                                    }
                                }
                            }
                        }

                        if ( directionText === ">" ){
                            const smallArrowSize = Math.floor(textHeight * 0.30);
                            const directionSpan = document.createElement("span");
                            directionSpan.style.display = "inline-block";
                            directionSpan.style.borderTop = `${smallArrowSize}px solid transparent`;
                            directionSpan.style.borderBottom = `${smallArrowSize}px solid transparent`;
                            directionSpan.style.borderLeft = `${smallArrowSize}px solid ${directionColor}`;
                            directionSpan.style.marginLeft = "1px";
                            textContainer.appendChild(directionSpan);
                        }


                        textForeign.appendChild( textContainer );
                        extentContainer.appendChild( textForeign );



                    }
                    else if ( evt.name !== qlog.TransportEventType.packet_sent &&
                              evt.name !== qlog.TransportEventType.packet_received ) {

                        // if we get here, the event was not a packet_sent or packet_received event, so we want to show what it was on the side 
                        const sideOffset = (timeText.length * 1.3 * 11); // (pixelsPerMillisecond / 2) * (timeText.length * 1.75); // magic numbers, nothing logical about them
                        // const text = document.createElementNS("http://www.w3.org/2000/svg", "text");
                        // text.setAttribute('class', "timestamp");
                        // text.setAttribute('x', "" + (currentX - (pixelsPerMillisecond / 2) + ((i === 0) ? -sideOffset : sideOffset)));
                        // text.setAttribute('y', "" + (currentY));
                        // text.setAttribute('dominant-baseline', "bottom");
                        // text.setAttribute('text-anchor', (i === 0) ? "end" : "start");
                        // text.textContent = "" + evt.name;
                        // extentContainer.appendChild( text );

                        let x = (currentX + (pixelsPerMillisecond / 2) + sideOffset);
                        let width = ((this.bandWidth / 2) * 0.9) * 0.9; // without 0.9, was still too wide in some cases
                        let align = "left";

                        if ( i === 0 ){
                            align = "right";
                            width = ((this.bandWidth / 2) * 0.9) - sideOffset;
                            x = (this.bandWidth / 2) * 0.05;
                        }

                        const textHeight = pixelsPerMillisecond * 0.9;

                        const textForeign = document.createElementNS("http://www.w3.org/2000/svg", "foreignObject");
                        textForeign.setAttribute('x', "" + x);
                        textForeign.setAttribute('y', "" + (currentY - (textHeight / 1.25))); // magic number
                        textForeign.setAttribute('width',  "" + width);
                        textForeign.setAttribute('height', "" + textHeight); 
                        textForeign.style.overflow = "visible";

                        // on the left of the graph, we want to have our text overflowing to the LEFT instead of the right
                        // this is a bit finicky, requiring a float: right inside of an encapsulating div
                        const textContainerOuter = document.createElementNS("http://www.w3.org/1999/xhtml", "div");
                        textContainerOuter.style.width = "" + width;
                        textContainerOuter.style.textAlign = align;

                        // const textContainer = document.createElementNS("http://www.w3.org/1999/xhtml", "div");
                        // textContainer.style.cssFloat = (i === 0) ? "right" : "left";

                        const textSpan = document.createElement("span");
                        const [bgColor, textColor] = this.eventTypeToColor( evt );
                        textSpan.textContent = this.eventToShortString( evt );
                        textSpan.style.color = textColor;
                        textSpan.style.backgroundColor = bgColor;
                        textSpan.style.paddingLeft = "5px";
                        textSpan.style.paddingRight = "5px";
                        textSpan.style.border = "1px white";
                        textSpan.style.borderStyle = "none solid";
                        // textSpan.style.cssFloat = "right";
                        textSpan.style.fontSize = "" + ( Math.floor(textHeight * 0.8) ) + "px";
                        textSpan.onclick = (evt_in) => this.onEventClicked(rawEvt, trace.connection, focusInfo);
                        // textContainer.appendChild(textSpan);
                        
                        textContainerOuter.appendChild(textSpan);
                        textForeign.appendChild( textContainerOuter );
                        extentContainer.appendChild( textForeign );
                    }
                }
            }

            (svg.node()! as HTMLElement).appendChild( extentContainer );
        }
    
        // const DEBUG_renderedRanges = this.renderedRanges.filter( (range) => range.rendered );
        // console.log("Actually rendered ranges at this point: ", DEBUG_renderedRanges.length, DEBUG_renderedRanges);
    }

    protected frameTypeToColor( frameType:qlog.QUICFrameTypeName ) : Array<string>{

        if ( this.frameTypeToColorLUT.size === 0 ){

            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.ack,       ["#03ad25", "#FFFFFF"] ); // green
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.stream,    ["#0468cc", "#FFFFFF"] ); // blue
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.crypto,    ["#0468cc", "#FFFFFF"] ); // blue

            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.padding,   ["#ff69b4", "#FFFFFF"] ); // pink

            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.connection_close,  ["#a80f3a", "#FFFFFF"] ); // dark red
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.reset_stream,      ["#a80f3a", "#FFFFFF"] ); // dark red
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.application_close, ["#a80f3a", "#FFFFFF"] ); // dark red
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.stop_sending,      ["#a80f3a", "#FFFFFF"] ); // dark red

            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.new_connection_id,      ["#068484", "#FFFFFF"] ); // dark green
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.retire_connection_id,   ["#068484", "#FFFFFF"] ); // dark green


            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.ping,              ["#d6dd02", "#000000"] ); // ugly yellow
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.path_challenge,    ["#d6dd02", "#000000"] ); // ugly yellow
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.path_response,     ["#d6dd02", "#000000"] ); // ugly yellow

            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.max_data,              ["#5f0984", "#FFFFFF"] ); // dark purple
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.max_stream_data,       ["#5f0984", "#FFFFFF"] ); // dark purple
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.max_streams,           ["#5f0984", "#FFFFFF"] ); // dark purple
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.data_blocked,          ["#5f0984", "#FFFFFF"] ); // dark purple
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.streams_blocked,       ["#5f0984", "#FFFFFF"] ); // dark purple
            this.frameTypeToColorLUT.set( qlog.QUICFrameTypeName.stream_data_blocked,   ["#5f0984", "#FFFFFF"] ); // dark purple
        }

        if ( this.frameTypeToColorLUT.has( frameType ) ){
            return this.frameTypeToColorLUT.get( frameType )!;
        }
        else {
            return ["#FF0000", "#FFFFFF"];
        }
    }

    protected frameToShortString( frame:qlog.QuicFrame ):string {
        let output = "";
        switch ( frame.frame_type ){
            case qlog.QUICFrameTypeName.ack:
                output = frame.frame_type + " ";
                if ( frame.acked_ranges ){
                    const ranges = frame.acked_ranges;
                    for ( let r = 0; r < ranges.length; ++r  ){

                        const range = ranges[r];

                        if ( (range as any).length === 1 ) {
                            output += range[0];
                        }
                        else if ( range[0] !== range[1] ){
                            output += range[0] + "-" + range[1];
                        }
                        else{
                            output += range[0];
                        }
                        if ( r < ranges.length - 1 ){
                            output += ","
                        }
                    }
                }

                return "" + output;
                break;

            case qlog.QUICFrameTypeName.stream:
                return frame.frame_type + " " + frame.stream_id + ((frame.fin) ? " FIN" : "");
                break;


            case qlog.QUICFrameTypeName.connection_close:
                output = frame.frame_type + " ";
                if (frame.error_code === qlog.TransportError.no_error || frame.error_code === qlog.ApplicationError.http_no_error || ( "" + frame.error_code) === "0" ) {
                    output += ": clean";
                }
                // some implementations don't output .error_code, only raw_error_code... weird
                else if ( frame.raw_error_code && ("" + frame.raw_error_code) === "0" ) {
                    output += ": clean";
                }
                else {
                    if ( frame.error_code ) {
                        output += frame.error_code;
                    }
                    // some implementations don't output .error_code, only raw_error_code... weird
                    else if ( frame.raw_error_code ) {
                        output += frame.raw_error_code;
                    }

                    if ( frame.reason ) {
                        output  += " : " + frame.reason;
                    }
                }
                
                return output;
                break;

            case qlog.QUICFrameTypeName.max_stream_data:
                if ( frame.maximum && frame.stream_id ) {
                    return "max data " + frame.maximum + " (stream " + frame.stream_id + ")";
                }
                else {
                    return "" + qlog.QUICFrameTypeName.max_stream_data;
                }
                break;
            

            case qlog.QUICFrameTypeName.max_data:
                if ( frame.maximum ) {
                    return "max data " + frame.maximum;
                }
                else {
                    return "" + qlog.QUICFrameTypeName.max_data;
                }
                break;


            case qlog.QUICFrameTypeName.max_streams:
                if ( frame.maximum && frame.stream_type ) {
                    return "max " + frame.maximum + " " + frame.stream_type + " streams";
                }
                else {
                    return "" + qlog.QUICFrameTypeName.max_streams;
                }
                break;
            
            case qlog.QUICFrameTypeName.streams_blocked:
                if ( frame.limit && frame.stream_type ) {
                    return "blocked at " + frame.limit + " " + frame.stream_type + " streams";
                }
                else {
                    return "" + qlog.QUICFrameTypeName.streams_blocked;
                }
                break;
            
            case qlog.QUICFrameTypeName.stream_data_blocked:
                if ( frame.limit && frame.stream_id ) {
                    return "stream " + frame.stream_id + "blocked at " + frame.limit;
                }
                else {
                    return "" + qlog.QUICFrameTypeName.stream_data_blocked;
                }
                break;
            
            case qlog.QUICFrameTypeName.data_blocked:
                if ( frame.limit ) {
                    return "connection blocked at " + frame.limit;
                }
                else {
                    return "" + qlog.QUICFrameTypeName.data_blocked;
                }
                break;
            
            case qlog.QUICFrameTypeName.reset_stream:
                if ( frame.stream_id ) {
                    if ( frame.error_code !== undefined ) {
                        return "reset stream " + frame.stream_id + " (" + frame.error_code + ")";
                    }
                    else {
                        return "reset stream " + frame.stream_id;
                    }
                }
                else {
                    return "" + qlog.QUICFrameTypeName.reset_stream;
                }
                break;
            
            case qlog.QUICFrameTypeName.stop_sending:
                if ( frame.stream_id ) {
                    if ( frame.error_code !== undefined ) {
                        return "stop sending " + frame.stream_id + " (" + frame.error_code + ")";
                    }
                    else {
                        return "stop sending " + frame.stream_id;
                    }
                }
                else {
                    return "" + qlog.QUICFrameTypeName.stop_sending;
                }
                break;

            default:
                return frame.frame_type;
                break;
        }
    }

    protected eventTypeToColor( evt:IQlogEventParser ) : Array<string> {

        if ( evt.name === qlog.ConnectivityEventType.connection_id_updated ){
            return this.frameTypeToColor( qlog.QUICFrameTypeName.new_connection_id );
        }
        else if ( evt.name === qlog.ConnectivityEventType.spin_bit_updated ){
            return this.frameTypeToColor( qlog.QUICFrameTypeName.ping );
        }
        else if ( evt.name === qlog.ConnectivityEventType.connection_state_updated ){
            const csuEvent = evt.data as IEventConnectionStateUpdated;

            if ( csuEvent.new === qlog.ConnectionState.closed || csuEvent.new === qlog.ConnectionState.draining ) {
                return this.frameTypeToColor( qlog.QUICFrameTypeName.connection_close );
            }
        }
        else if ( evt.name === qlog.RecoveryEventType.metrics_updated ||
                  evt.name === qlog.TransportEventType.parameters_set ||
                  evt.name === qlog.RecoveryEventType.parameters_set ||
                  evt.name === qlog.HTTP3EventType.parameters_set || 
                  evt.name === "loss_timer_updated" ){ // FIXME: properly link to qlog schema once that's been updated
            return this.frameTypeToColor( qlog.QUICFrameTypeName.max_data );
        }
        else if ( evt.name === qlog.HTTP3EventType.frame_created ||
                  evt.name === qlog.HTTP3EventType.frame_parsed ){
            return this.frameTypeToColor( qlog.QUICFrameTypeName.stream );
        }
        else if ( evt.name === qlog.TransportEventType.datagrams_sent ||
                  evt.name === qlog.TransportEventType.datagrams_received ){
            return ["#FFFFFF", "#000000"];
        }
        else if ( evt.category === "error" ) {
            return ["#FF0000", "#000000"];
        }
        else if ( evt.category === "warning" || evt.category === "simulation" ) {
            return ["#FFA500", "#000000"]; // orange
        }
        else if ( evt.category === "debug" || evt.category === "info" || evt.category === "verbose" ) {
            return ["#D3D3D3", "#000000"]; // lightgrey
        }
        
        return ["#FF0000", "#FFFFFF"];
    }

    protected eventToShortString( evt:IQlogEventParser ) : string {
        
        let output = "";

        switch ( evt.name ){

            case qlog.ConnectivityEventType.spin_bit_updated:
                return "Spin " + ((evt.data as qlog.IEventSpinBitUpdated).state ? "ON" : "OFF");
                break;

            case qlog.RecoveryEventType.metrics_updated:
                const metricNames = Object.keys(evt.data);

                // TODO: when we add filters, allow users to set the parameters to show themselves
                let count = 0;
                if ( metricNames.indexOf("cwnd") >= 0 ) {
                    output += "cwnd: " + evt.data.cwnd;
                    count += 1;
                }
                if ( metricNames.indexOf("smoothed_rtt") >= 0 ) {
                    if ( count > 0 ){
                        output += ", ";
                    }
                    output += "srtt: " + evt.data.smoothed_rtt;
                    count += 1;
                }
                if ( metricNames.indexOf("bytes_in_flight") >= 0 ) {
                    if ( count > 0 ){
                        output += ", ";
                    }
                    output += "in flight: " + evt.data.bytes_in_flight;
                    count += 1;
                }
                if ( metricNames.indexOf("ssthresh") >= 0 ) {
                    if ( count > 0 ){
                        output += ", ";
                    }
                    output += "ssthresh: " + evt.data.ssthresh;
                    count += 1;
                }

                const amountLeftOver = metricNames.length - count;
                if ( count > 0 && amountLeftOver > 0 ) {
                    output += ", ...";
                }
                else if ( count === 0) {
                    for ( let i = 0; i < metricNames.length; ++i  ) {
                        output += "" + metricNames[i] + ": " + evt.data[metricNames[i]];
                        if (i !== metricNames.length - 1 ) {
                            output += ", ";
                        }
                    } 
                }
                // }
                // else {
                //     for ( let i = 0; i < metricNames.length; ++i  ) {
                //         output += "" + metricNames[i] + ": " + evt.data[metricNames[i]];
                //         if (i !== metricNames.length - 1 ) {
                //             output += ", ";
                //         }
                //     }  
                // }

                return "" + output;
                break;

            case qlog.RecoveryEventType.parameters_set:
                if ( evt.category === qlog.EventCategory.recovery ) {
                    return "" + Object.keys(evt.data).length + " recovery parameters set";
                }
                else if ( evt.category === qlog.EventCategory.transport ) {
                    return "" + Object.keys(evt.data).length + " transport parameters set";
                }
                else if ( evt.category === qlog.EventCategory.http ) {
                    return "" + Object.keys(evt.data).length + " HTTP/3 parameters set";
                }
                else {
                    console.error("SequenceDiagramD3Renderer:eventToShortString : unknown category for 'parameters_set' event...", evt.category);

                    return "" + Object.keys(evt.data).length + " UNKNOWN parameters set";
                }
                break;

                // const paramNames = Object.keys(evt.data);
                // for ( let i = 0; i < paramNames.length; ++i  ) {
                //     output += "" + paramNames[i] + ": " + evt.data[paramNames[i]];
                //     if (i !== paramNames.length - 1 ) {
                //         output += ", ";
                //     }
                // }

                // return "" + output;
                // break;

            case qlog.ConnectivityEventType.connection_state_updated:
                return "Connection state: " + evt.data.new; 
                break;

            case "loss_timer_updated": // FIXME: properly link to qlog schema once that's been updated
                const delta = (evt.data.delta !== undefined) ? evt.data.delta : evt.data.timeout; // timeout is old-school, delta should be used now
                let timeString = "";
                if ( evt.data.event_type === "set" ) {
                    timeString = " @ " + (evt.relativeTime + evt.timeToMilliseconds(delta)).toFixed(4); // + " (" + parseFloat(delta).toFixed(2) + ")";
                }
                let pnSpaceString = "";
                if ( evt.data.packet_number_space !== undefined ) {
                    pnSpaceString = evt.data.packet_number_space + " ";
                    if ( evt.data.packet_number_space === "application_data" ) {
                        pnSpaceString = "appdata ";
                    }
                }

                return pnSpaceString + " " + (evt.data.timer_type !== undefined ? ( "" + evt.data.timer_type).toUpperCase() + " " : " ") + "timer " + evt.data.event_type + timeString;
                break;

            case qlog.RecoveryEventType.packet_lost:
                if ( evt.data !== undefined && evt.data.header !== undefined && evt.data.header.packet_number !== undefined ) {
                    let packetType = "";
                    if ( evt.data.header.packet_type !== undefined ) {
                        packetType = this.packetTypeToString( evt.data.header.packet_type ) + " ";
                    }

                    return packetType + "packet lost #" + evt.data.header.packet_number;
                }
                else {
                    return evt.name;
                }
                break;

            case qlog.RecoveryEventType.congestion_state_updated:
                if ( evt.data && evt.data.new !== undefined ) {
                    return "Congestion state: " + ("" + evt.data.new).replace("_", " ");
                }
                else {
                    return evt.name;
                }
                break;
            
            case qlog.HTTP3EventType.frame_parsed:
            case qlog.HTTP3EventType.frame_created:

                let streamID = "";
                if ( evt.data.stream_id !== undefined) {
                    streamID = " (stream " + evt.data.stream_id + ")";
                }

                // TRY to return something like   GET /index.html if possible
                if ( evt.data && evt.data.frame && evt.data.frame.headers ) {
                    let method = undefined;
                    let path = undefined;
                    let authority = undefined;
                    let status = undefined;
                    for ( const header of evt.data.frame.headers ) {
                        if ( header.name === ":method" || header.name === "method" ) {
                            method = header.value;
                        }
                        else if ( header.name === ":path" || header.name === "path" ) {
                            path = header.value;
                        }
                        else if ( header.name === ":authority" || header.name === "authority" ) {
                            authority = header.value;
                        }
                        else if ( header.name === ":status" || header.name === "status" ) {
                            status = header.value;
                        }
                    }

                    // Ideally, we have
                    // status method path (stream id) authority

                    // example:
                    // 200 GET /index.html (stream 4) example.org
                    // (though note that not all these headers will be present for both requests and responses)

                    let shorthand = "";
                    if ( status ) {
                        shorthand += status + " ";
                    }

                    if ( method ) {
                        shorthand += method + " ";
                    }

                    if ( path ) {
                        shorthand += path + " ";
                    }

                    if ( shorthand !== "" ) { // if none of the headers are set, we want to log generic stuff below
                        shorthand += streamID + " ";
                    }

                    if ( authority ) {
                        if ( shorthand === "" ) { // if only authority is set, we still want to show stream ID here
                            shorthand += streamID + " ";
                        }
                        shorthand += authority;
                    }

                    if ( shorthand !== "" ) {
                        return shorthand;
                    }
                }

                let frameType = "";
                if ( evt.data.frame && evt.data.frame.frame_type ) {
                    frameType = evt.data.frame.frame_type + " ";
                }

                let verb = "parsed";
                if ( evt.name ===  qlog.HTTP3EventType.frame_created ) {
                    verb = "created";
                }

                return frameType + " " + verb + streamID;
                break;


            case "info":
            case "debug":
            case "warning":
            case "error":
            case "verbose":
            case "connection_error":
            case "internal_error":
            case "application_error":
            case "internal_warning":
            case "marker":
            case "message":
                if ( evt.data === undefined || evt.data.message === undefined ) {
                    return evt.name;
                }

                return evt.category + ": " + evt.data.message;

                break;

            default:
                return evt.name;
                break;
        }
    }

    protected packetTypeToString( packetType:string ){

        switch ( packetType ){

            case qlog.PacketType.onertt:
            case "onertt":
                return "1RTT";
                break;

            case qlog.PacketType.zerortt:
            case "zerortt":
                return "0RTT";
                break;

            case qlog.PacketType.version_negotiation:
                return "VNEG";
                break;

            default:
                return packetType;
                break;
        }
    }

}


